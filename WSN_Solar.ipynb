{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9b03e-dbac-468a-82a4-fa2bfa0136d4",
   "metadata": {},
   "outputs": [],
   "source": [
    " pip install numpy pandas matplotlib seaborn scikit-learn scipy geopandas rasterio shapely pyproj pycraf pvlib geopy requests joblib plotly contextily pulp ipywidgets ipyleaflet pymoo astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d77e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# TITLE: Wireless Sensor Network Gateway Placement\n",
    "# ===========================================================\n",
    "\n",
    "# 1. ===== GLOBAL IMPORTS, CONFIG, AND SEEDING =====\n",
    "import os, random, warnings, json\n",
    "from typing import List, Tuple, Dict, Optional, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, MultiPoint, Polygon, shape, box\n",
    "from shapely.ops import unary_union\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.mask import mask\n",
    "from pyproj import Geod\n",
    "\n",
    "import pvlib\n",
    "from pvlib.location import Location\n",
    "from pvlib.pvsystem import PVSystem\n",
    "from pvlib.modelchain import ModelChain\n",
    "\n",
    "import pulp\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import contextily as cx\n",
    "\n",
    "from ipyleaflet import Map, DrawControl, basemaps, Marker, GeoJSON, Popup, CircleMarker, Polyline, Circle\n",
    "from ipywidgets import Button, Output, VBox, HBox, HTML, FloatSlider, IntSlider, Dropdown, Layout, Tab, SelectMultiple\n",
    "\n",
    "import requests\n",
    "from astropy import units as u\n",
    "\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'vscode'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print(f\"Random seed set: {RANDOM_SEED}\")\n",
    "\n",
    "@dataclass\n",
    "class NetworkConfig:\n",
    "    MAX_COMM_RANGE_M: float = 2500.0\n",
    "    GATEWAY_HEIGHT: float = 5.0\n",
    "    SENSOR_HEIGHT: float = 5.0\n",
    "\n",
    "@dataclass\n",
    "class OptimizationConfig:\n",
    "    NUM_GATEWAY_CANDIDATES: int = 550\n",
    "    COVERAGE_GRID_SIZE: int = 40\n",
    "    TX_POWER_DBM: float = 10.0           \n",
    "    RX_SENSITIVITY_DBM: float = -125.0   \n",
    "    ANTENNA_GAIN_DBI: float = 10.0       \n",
    "    SYSTEM_MARGIN_DB: float = 10.0       \n",
    "\n",
    "    @property\n",
    "    def MAX_ALLOWABLE_PATH_LOSS_DB(self) -> float:\n",
    "        return (self.TX_POWER_DBM + self.ANTENNA_GAIN_DBI * 2 -\n",
    "                self.RX_SENSITIVITY_DBM - self.SYSTEM_MARGIN_DB)\n",
    "\n",
    "NETWORK = NetworkConfig()\n",
    "OPTIMIZATION = OptimizationConfig()\n",
    "\n",
    "# LoRaWAN budget calculation\n",
    "LORAWAN_BUDGET = OPTIMIZATION.MAX_ALLOWABLE_PATH_LOSS_DB\n",
    "\n",
    "\n",
    "print(f\"LoRaWAN Link Budget: {LORAWAN_BUDGET} dB\")\n",
    "print(f\"Updated MAX_ALLOWABLE_PATH_LOSS_DB: {OPTIMIZATION.MAX_ALLOWABLE_PATH_LOSS_DB} dB\")\n",
    "\n",
    "cachedir = './.wsn_cache'\n",
    "#memory = Memory(cachedir, verbose=0)\n",
    "def clear_all_cache_dirs():\n",
    "    import shutil\n",
    "    cache_dirs = [\n",
    "        './.sensor_cache', './.joblib_cache', './.wsn_cache',\n",
    "        './.phase1_cache', './.phase2_cache', './.dem_cache', './.cache',\n",
    "        './output_cache', './.ipynb_checkpoints', './.pymoo_cache',\n",
    "        './.tmp_cache', './.memory_cache'\n",
    "    ]\n",
    "    for d in cache_dirs:\n",
    "        try:\n",
    "            shutil.rmtree(d)\n",
    "            print(f\"🧹 Cleared {d} directory.\")\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"Could not clear {d}: {e}\")\n",
    "    print(\"All listed cache folders cleared (if they existed).\")\n",
    "\n",
    "clear_all_cache_dirs()\n",
    "\n",
    "try:\n",
    "    memory.clear(warn=False)\n",
    "    print(\"Cleared joblib.Memory cache successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Cache clear failed or not needed:\", e)\n",
    "\n",
    "dem_manager = None\n",
    "aoi_poly: Optional[Polygon] = None\n",
    "drawn_geometry: Dict[str, Any] = {}\n",
    "gateway_candidate_df: Optional[pd.DataFrame] = None\n",
    "saved_solutions = {}\n",
    "solution_counter = 0\n",
    "\n",
    "print(\"All libraries, configs, and globals loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ff8d6",
   "metadata": {},
   "source": [
    "NEW SOLAR FUNCTIONS BELOW. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Solar PV + Load + Battery — Annual Site Simulation \n",
    "# =============================================================\n",
    "# Goal:\n",
    "#   Given a site (lon/lat) and some terrain rasters (DEM/DSM/CHM),\n",
    "#   I want a daily energy story for a tiny PV system powering device:\n",
    "#     1) Pull hour-by-hour irradiance & weather for a chosen year (NSRDB/PSM3 via pvlib)\n",
    "#     2) Adjust irradiance for local terrain/vegetation shading (horizon mask)\n",
    "#     3) Run a PVWatts-style PV model to get AC power each hour\n",
    "#     4) Convert device behavior (boots + standby) into daily Wh load\n",
    "#     5) March the battery state-of-charge day-by-day to catch outages\n",
    "#   The output feeds my gateway/sensor candidate ranking (solar).\n",
    "\n",
    "import os\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pvlib.location import Location\n",
    "from pvlib.pvsystem import PVSystem\n",
    "from pvlib.modelchain import ModelChain\n",
    "from pvlib.solarposition import get_solarposition\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Environment & caching (cache weather pulls to avoid re-hitting API)\n",
    "# -------------------------------------------------------------\n",
    "load_dotenv()  # keep NSRDB_API_KEY and NSRDB_EMAIL in a .env file next to the notebook\n",
    "WEATHER_CACHE: dict[tuple, pd.DataFrame] = {}\n",
    "WEATHER_Q_DEG = 0.01  # I snap lat/lon to 0.05° so nearby sites reuse the same NSRDB fetch\n",
    "\n",
    "\n",
    "# --- SAFE quantizer (handles q<=0) ---\n",
    "def _q(val: float, q: float) -> float:\n",
    "    \"\"\"Quantize val to nearest multiple of q. If q<=0, return val unchanged.\"\"\"\n",
    "    v = float(val)\n",
    "    if not q or q <= 0:\n",
    "        return v\n",
    "    return round(v / q) * q\n",
    "\n",
    "# Sanity-check that my creds are visible to the process\n",
    "api_key = os.getenv(\"NSRDB_API_KEY\")\n",
    "email = os.getenv(\"NSRDB_EMAIL\")\n",
    "print(\"API Key loaded?\", bool(api_key))\n",
    "print(\"Email loaded?\", email)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PV / Load / Battery parameter blocks (my defaults)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class PVParams:\n",
    "    # STC DC rating of my mini panel. If I swap a 10W/20W/25W,\n",
    "    pdc0_w: float = 10.0\n",
    "\n",
    "    # Temperature coefficient for DC power (fraction per °C). \n",
    "    gamma_pdc: float = -0.004\n",
    "\n",
    "    soiling_loss: float = 0.15   # dust/film/bird hits; I assume 2% for maintained field units\n",
    "    wiring_loss: float = 0.03    # cable + connectors; tiny runs but include 3% so I’m not optimistic\n",
    "\n",
    "    # MPPT efficiency: how well the controller tracks the true max power point.\n",
    "    # I set 97% \n",
    "    mppt_eff: float = 0.87\n",
    "\n",
    "    # Sandia Array Performance Model (SAPM) temperature params I'm using with pvlib's SAPM temp model\n",
    "    # These a/b/deltaT are a common generic set; they control how hot the module runs for given POA & wind.\n",
    "    temp_a: float = -3.56\n",
    "    temp_b: float = 0.0594\n",
    "    temp_deltaT: float = 3.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LoadParams:\n",
    "    # These came from Eddy’s device notes \n",
    "    boot_current_a: float = 0.690\n",
    "    per_node_current_a: float = 0.070\n",
    "    num_nodes: int = 6\n",
    "    boot_secs: int = 5\n",
    "\n",
    "    # I encode the worst-case poll cadence here; if I want a day-split schedule later, I’ll extend the model.\n",
    "    check_every_minutes: int = 1\n",
    "\n",
    "    # This 0.0025 A is the *gateway* standby ( 0.0149 sensor standby).\n",
    "    standby_current_a: float = 0.0149\n",
    "\n",
    "    \n",
    "    sleep_current_a: float | None = None\n",
    "\n",
    "    # Nominal bus voltage; my packs are 1S Li-ion-ish (3.6–3.7 V nominal)\n",
    "    system_voltage_v: float = 3.7\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BatteryParams:\n",
    "    # For SLA 12 V × Ah\n",
    "    capacity_wh: float = 18.5\n",
    "\n",
    "    # Charge/discharge path efficiencies; I keep both explicit so I can tweak asymmetrically if needed.\n",
    "    charge_eff: float = 0.95\n",
    "    discharge_eff: float = 0.95\n",
    "\n",
    "    # Ops policy: I don’t want to dip below 10% SOC (reserve for cold days/aging). I start the sim at 80%.\n",
    "    min_soc: float = 0.10\n",
    "    initial_soc: float = 0.80\n",
    "\n",
    "\n",
    "# I cache PV results too because horizon masks & PV runs are moderately expensive per site\n",
    "_PV_CACHE: dict[tuple, tuple[pd.Series, dict]] = {}\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Horizon profile & sky openness (terrain/vegetation shading model)\n",
    "# -------------------------------------------------------------\n",
    "# I ray-cast 0..359° around the site out to ~300–400 m across DEM/DSM/CHM to find the\n",
    "# maximum elevation angle of obstacles in each direction. That becomes my horizon line.\n",
    "# If the sun is below that line in a direction/hour, I zero the direct beam (DNI).\n",
    "# Diffuse is scaled by a crude sky-view factor derived from the mean horizon height.\n",
    "\n",
    "def _horizon_profile_from_dsm(dem_manager, coord, radius_m: int = 400, az_step_deg: int = 1):\n",
    "    \"\"\"\n",
    "    dem_manager must expose:\n",
    "      - get_elevation((lon, lat))  -> bare earth\n",
    "      - get_surface_elevation((lon, lat)) -> DSM (if available)\n",
    "      - get_canopy_height((lon, lat)) -> CHM (if available)\n",
    "      - transform, slope_arr, aspect_arr optionally for orientation\n",
    "\n",
    "    Returns:\n",
    "      az_deg        : np.ndarray of azimuth centers [0..359]\n",
    "      horz_elev_deg : np.ndarray of max elevation angle of obstacles at each azimuth (deg)\n",
    "    \"\"\"\n",
    "    az_deg = np.arange(0, 360, az_step_deg, dtype=float)\n",
    "    horz = np.zeros_like(az_deg, dtype=float)\n",
    "\n",
    "    # Decide which \"surface\" to cast across (I prefer DSM; else DEM+CHM; else DEM only)\n",
    "    def elev_at(lon, lat):\n",
    "        if getattr(dem_manager, 'dsm_array', None) is not None:\n",
    "            return dem_manager.get_surface_elevation((lon, lat))\n",
    "        elif getattr(dem_manager, 'chm_array', None) is not None:\n",
    "            return dem_manager.get_elevation((lon, lat)) + dem_manager.get_canopy_height((lon, lat))\n",
    "        else:\n",
    "            return dem_manager.get_elevation((lon, lat))\n",
    "\n",
    "    lon0, lat0 = coord\n",
    "    steps = max(10, int(radius_m // 10))  # I keep ~10 m step spacing along each spoke\n",
    "\n",
    "    for i, az in enumerate(az_deg):\n",
    "        max_alpha = 0.0\n",
    "        for s in range(1, steps + 1):\n",
    "            frac = s / steps\n",
    "            dist = frac * radius_m\n",
    "\n",
    "            # Flat-earth approximation is fine at <1 km: convert local meters to degrees\n",
    "            dx = dist * math.sin(math.radians(az))\n",
    "            dy = dist * math.cos(math.radians(az))\n",
    "            m_per_deg_lat = 111_000.0\n",
    "            m_per_deg_lon = m_per_deg_lat * math.cos(math.radians(lat0))\n",
    "            lon = lon0 + dx / m_per_deg_lon\n",
    "            lat = lat0 + dy / m_per_deg_lat\n",
    "\n",
    "            z_obs = elev_at(lon0, lat0)\n",
    "            z_pt = elev_at(lon, lat)\n",
    "            dz = (z_pt - z_obs)\n",
    "            alpha = math.degrees(math.atan2(dz, dist))  # elevation angle of that obstacle\n",
    "            if alpha > max_alpha:\n",
    "                max_alpha = alpha\n",
    "        horz[i] = max(0.0, max_alpha)\n",
    "\n",
    "    return az_deg, horz\n",
    "\n",
    "\n",
    "def _sky_view_factor(horizon_elev_deg: np.ndarray) -> float:\n",
    "    \"\"\"Quick-and-dirty SVF proxy in [0,1]. 0=open sky, 1=closed (not physical; I clamp).\n",
    "    I just normalize the mean horizon height over 0..90°.\n",
    "    \"\"\"\n",
    "    mean_h = np.clip(np.mean(horizon_elev_deg), 0, 90)\n",
    "    return float(max(0.0, 1.0 - float(mean_h) / 90.0))\n",
    "\n",
    "\n",
    "def _orient_from_terrain(dem_manager, coord, force_south: bool = True):\n",
    "    \"\"\"Read slope/aspect at the pixel; I cap tilt to 60° and optionally force south-facing.\n",
    "    If I pass force_south=True I ignore natural aspect and lock azimuth=180°.\n",
    "    \"\"\"\n",
    "    col, row = ~dem_manager.transform * coord\n",
    "    row, col = int(row), int(col)\n",
    "    tilt = 30.0\n",
    "    az = 180.0\n",
    "\n",
    "    if dem_manager.slope_arr is not None and 0 <= row < dem_manager.slope_arr.shape[0] and 0 <= col < dem_manager.slope_arr.shape[1]:\n",
    "        tilt = float(np.clip(dem_manager.slope_arr[row, col], 0, 60))\n",
    "\n",
    "    if not force_south and dem_manager.aspect_arr is not None and 0 <= row < dem_manager.aspect_arr.shape[0] and 0 <= col < dem_manager.aspect_arr.shape[1]:\n",
    "        az = float(dem_manager.aspect_arr[row, col] % 360)\n",
    "\n",
    "    return tilt, (180.0 if force_south else az)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Weather ingestion (NSRDB/PSM3 through pvlib) + UTC normalization\n",
    "# -------------------------------------------------------------\n",
    "# I stick to the 1998–2022 availability window in NSRDB PSM3 actual-year data.\n",
    "# I compute a diagnostic cloud_cover_pct as 1 - (GHI_measured / GHI_clearsky) for daylight hours.\n",
    "\n",
    "\n",
    "def _annual_weather(\n",
    "    loc: Location,\n",
    "    year: int = 2022,\n",
    "    nsrdb_api_key: str | None = None,\n",
    "    nsrdb_email: str | None = None,\n",
    "    interval: int = 60,  # 60 or 30 minutes\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a UTC-indexed DataFrame with columns:\n",
    "      ['ghi','dni','dhi','temp_air','wind_speed','clearsky_ghi',\n",
    "       'cloud_cover_pct','cloud_type']\n",
    "    - cloud_cover_pct is a diagnostic derived from GHI/clearsky with a small cushion.\n",
    "    - cloud_type is NSRDB’s categorical cloud field if returned; else NaN.\n",
    "    \"\"\"\n",
    "    from pvlib import iotools\n",
    "    from pvlib.solarposition import get_solarposition\n",
    "    from datetime import timedelta, timezone\n",
    "\n",
    "    if interval not in (30, 60):\n",
    "        raise ValueError(\"NSRDB interval must be 30 or 60 minutes.\")\n",
    "\n",
    "    # Clamp to NSRDB PSM3 historical range\n",
    "    y = int(min(2022, max(1998, year)))\n",
    "\n",
    "    # Quantize to reduce redundant requests for nearby sites\n",
    "    lat, lon = float(loc.latitude), float(loc.longitude)\n",
    "    lat_q, lon_q = _q(lat, WEATHER_Q_DEG), _q(lon, WEATHER_Q_DEG)\n",
    "    cache_key = (lat_q, lon_q, y, interval)\n",
    "    if cache_key in WEATHER_CACHE:\n",
    "        return WEATHER_CACHE[cache_key].copy()\n",
    "\n",
    "    # Creds\n",
    "    nsrdb_api_key = nsrdb_api_key or os.environ.get(\"NSRDB_API_KEY\")\n",
    "    nsrdb_email   = nsrdb_email   or os.environ.get(\"NSRDB_EMAIL\")\n",
    "    if not nsrdb_api_key or not nsrdb_email:\n",
    "        raise RuntimeError(\"Set NSRDB_API_KEY and NSRDB_EMAIL (or pass them to _annual_weather).\")\n",
    "\n",
    "    attrs = [\n",
    "        \"ghi\", \"dhi\", \"dni\",\n",
    "        \"air_temperature\", \"wind_speed\",\n",
    "        \"clearsky_ghi\", \"clearsky_dni\", \"clearsky_dhi\",\n",
    "        \"cloud_type\",\n",
    "    ]\n",
    "\n",
    "    df, meta = iotools.get_psm3(\n",
    "        latitude=float(lat_q),\n",
    "        longitude=float(lon_q),\n",
    "        api_key=nsrdb_api_key,\n",
    "        email=nsrdb_email,\n",
    "        names=str(y),\n",
    "        attributes=attrs,         # LIST, not CSV string\n",
    "        interval=interval,\n",
    "        leap_day=False,\n",
    "        map_variables=True,\n",
    "    )\n",
    "\n",
    "    # Convert to UTC (NSRDB is local-standard-time tz-naive)\n",
    "    tz_hours = None\n",
    "    for k in (\"Time Zone\", \"TimeZone\", \"TZ\", \"tz\", \"timezone\"):\n",
    "        if k in meta:\n",
    "            try:\n",
    "                tz_hours = float(meta[k]); break\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    if df.index.tz is None:\n",
    "        if tz_hours is not None:\n",
    "            fixed = timezone(timedelta(hours=tz_hours))\n",
    "            df.index = df.index.tz_localize(fixed).tz_convert(\"UTC\")\n",
    "        else:\n",
    "            df.index = df.index.tz_localize(\"UTC\")\n",
    "    else:\n",
    "        df.index = df.index.tz_convert(\"UTC\")\n",
    "\n",
    "    # Column cleanup\n",
    "    if \"temp_air\" not in df.columns and \"air_temperature\" in df.columns:\n",
    "        df = df.rename(columns={\"air_temperature\": \"temp_air\"})\n",
    "\n",
    "    for c in (\"ghi\", \"dni\", \"dhi\", \"temp_air\", \"wind_speed\"):\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Ensure we have a clearsky_ghi (fallback if NSRDB omitted it)\n",
    "    if \"clearsky_ghi\" not in df.columns or df[\"clearsky_ghi\"].isna().all():\n",
    "        cs = Location(float(lat_q), float(lon_q)).get_clearsky(df.index, model=\"ineichen\")\n",
    "        df[\"clearsky_ghi\"] = pd.to_numeric(cs[\"ghi\"], errors=\"coerce\")\n",
    "\n",
    "    # --- Cloud cover diagnostic from GHI vs. clearsky ---\n",
    "    cs_ghi = pd.to_numeric(df[\"clearsky_ghi\"], errors=\"coerce\").replace(0, np.nan)\n",
    "    # small cushion (e.g., 8%) so tiny GHI>clearsky doesn’t force 0%\n",
    "    cushion = 1.08\n",
    "    ratio = df[\"ghi\"] / (cushion * cs_ghi)\n",
    "    cloudiness = (1.0 - ratio).clip(lower=0, upper=1)\n",
    "    df[\"cloud_cover_pct\"] = 100.0 * cloudiness\n",
    "\n",
    "    # Nights → NaN (don’t pollute means)\n",
    "    sp = get_solarposition(df.index, float(lat_q), float(lon_q))\n",
    "    daylight = sp[\"apparent_elevation\"] > 0\n",
    "    df.loc[~daylight, \"cloud_cover_pct\"] = np.nan\n",
    "\n",
    "    # Keep cloud_type if present\n",
    "    if \"cloud_type\" not in df.columns:\n",
    "        df[\"cloud_type\"] = np.nan\n",
    "    else:\n",
    "        df[\"cloud_type\"] = pd.to_numeric(df[\"cloud_type\"], errors=\"coerce\")\n",
    "\n",
    "    # Final selection & typing\n",
    "    df = df[~df.index.duplicated(keep=\"first\")].sort_index()\n",
    "    out = df[[\n",
    "        \"ghi\", \"dni\", \"dhi\", \"temp_air\", \"wind_speed\",\n",
    "        \"clearsky_ghi\", \"cloud_cover_pct\", \"cloud_type\"\n",
    "    ]].astype(float)\n",
    "\n",
    "    WEATHER_CACHE[cache_key] = out.copy()\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PV energy with shading (per site) → daily Wh\n",
    "# -------------------------------------------------------------\n",
    "# I compute the horizon, attenuate DNI/DHI accordingly, then run pvlib’s PVWatts DC/AC chain.\n",
    "\n",
    "\n",
    "def _pv_dc_daily_wh(coord: tuple[float, float], dem_manager, pv: PVParams, year: int = 2022, force_south: bool = True):\n",
    "    lon, lat = coord\n",
    "    alt = float(dem_manager.get_elevation(coord))\n",
    "    tilt, az = _orient_from_terrain(dem_manager, coord, force_south=force_south)\n",
    "\n",
    "    # Build the 0..359° horizon once per site\n",
    "    az_bins, horz_elev = _horizon_profile_from_dsm(dem_manager, coord, radius_m=300, az_step_deg=1)\n",
    "    svf = _sky_view_factor(horz_elev)\n",
    "\n",
    "    # Cache key must reflect shading + PV params; that way repeated calls hit memory\n",
    "    key = (\n",
    "        round(lon, 4), round(lat, 4), year,\n",
    "        pv.pdc0_w, pv.gamma_pdc, pv.soiling_loss, pv.wiring_loss,\n",
    "        tilt, az, \"DCpvwatts\",                           # <--- was \"ACpvwatts\"\n",
    "        round(float(np.mean(horz_elev)), 2), round(svf, 3),\n",
    "    )\n",
    "    if key in _PV_CACHE:\n",
    "        return _PV_CACHE[key]\n",
    "\n",
    "    # Weather (UTC-indexed)\n",
    "    loc = Location(lat, lon, tz='UTC', altitude=alt)\n",
    "    wx = _annual_weather(loc, year=year, interval=60)\n",
    "\n",
    "    # Sun geometry at each timestamp\n",
    "    sp = get_solarposition(wx.index, lat, lon, altitude=alt)\n",
    "    sun_az = np.mod(sp['azimuth'].values, 360.0).astype(float)\n",
    "    sun_el = sp['apparent_elevation'].values.astype(float)\n",
    "\n",
    "    # Lookup horizon at each sun azimuth (nearest-degree bin)\n",
    "    bin_idx = np.clip(np.round(sun_az).astype(int), 0, 359)\n",
    "    horz_at_sun = horz_elev[bin_idx]\n",
    "\n",
    "    # Copy arrays for in-place edits\n",
    "    wx = wx.copy()\n",
    "    dni = wx['dni'].to_numpy(dtype=float)\n",
    "    dhi = wx['dhi'].to_numpy(dtype=float)\n",
    "    ghi = wx['ghi'].to_numpy(dtype=float)\n",
    "\n",
    "    # Hard occultation of direct beam when sun is behind the terrain/vegetation\n",
    "    blocked = sun_el <= horz_at_sun\n",
    "    dni[blocked] = 0.0\n",
    "\n",
    "    # Diffuse knocked down by SVF (less open sky → less diffuse light)\n",
    "    dhi *= svf\n",
    "\n",
    "    # Recompose GHI from (DNI, DHI, solar zenith)\n",
    "    cos_theta_z = np.cos(np.radians(90.0 - np.clip(sun_el, -90, 90)))\n",
    "    ghi = dni * np.maximum(cos_theta_z, 0.0) + dhi\n",
    "\n",
    "    wx['dni'] = dni\n",
    "    wx['dhi'] = dhi\n",
    "    wx['ghi'] = ghi\n",
    "\n",
    "    # PV system & model chain\n",
    "    system = PVSystem(\n",
    "        surface_tilt=tilt,\n",
    "        surface_azimuth=az,\n",
    "        module_parameters={'pdc0': pv.pdc0_w, 'gamma_pdc': pv.gamma_pdc},\n",
    "        inverter_parameters={'pdc0': pv.pdc0_w},  # pvwatts AC is ratioed off pdc0\n",
    "        temperature_model_parameters={'a': pv.temp_a, 'b': pv.temp_b, 'deltaT': pv.temp_deltaT},\n",
    "    )\n",
    "\n",
    "    mc = ModelChain(\n",
    "        system, loc,\n",
    "        dc_model='pvwatts', ac_model='pvwatts',\n",
    "        aoi_model='physical', spectral_model='no_loss',\n",
    "        temperature_model='sapm', losses_model='no_loss'\n",
    "    )\n",
    "\n",
    "    mc.run_model(wx)\n",
    "\n",
    "    # AC output with fixed wiring/soiling derates (I already accounted MPPT via pvwatts AC)\n",
    "    mc.run_model(wx)\n",
    "\n",
    "    # Use DC for a DC-coupled system (no inverter)\n",
    "    pdc = mc.results.dc\n",
    "    if isinstance(pdc, pd.DataFrame) and 'pdc' in pdc.columns:\n",
    "        pdc = pdc['pdc']\n",
    "    pdc = pdc.fillna(0.0)\n",
    "\n",
    "    # Apply derates appropriate for DC path\n",
    "    effective_gain = (1.0 - pv.soiling_loss) * (1.0 - pv.wiring_loss) * pv.mppt_eff\n",
    "    pdc_net_w = pdc * effective_gain\n",
    "\n",
    "    # Collapse to daily energy (Wh)\n",
    "    daily_wh = pdc_net_w.resample('1D').sum().rename('pv_dc_Wh')\n",
    "\n",
    "    # keep loss_fraction for metadata if you like\n",
    "    total_loss = float(np.clip(1.0 - effective_gain, 0.0, 0.95))\n",
    "\n",
    "    # Diagnostics I log for ranking & plots\n",
    "    interval_min = int(pd.Series(wx.index).diff().dt.total_seconds().dropna().mode().iloc[0] / 60) if len(wx) > 1 else 60\n",
    "    hours_per_step = interval_min / 60.0\n",
    "\n",
    "    cloud_pct = wx.get('cloud_cover_pct')\n",
    "    cloud_cover_mean_pct = float(np.nanmean(cloud_pct)) if cloud_pct is not None else np.nan\n",
    "\n",
    "    daylight = sun_el > 0.0\n",
    "    cloudy_hours_pct = float(\n",
    "        100.0 * np.nanmean((cloud_pct[daylight] >= 50.0)) if (cloud_pct is not None and np.any(daylight)) else np.nan\n",
    "    )\n",
    "\n",
    "    blocked_sun_hours = float(np.sum(blocked & (sun_el > 0.0)) * hours_per_step)\n",
    "    total_daylight_hours = float(np.sum(sun_el > 0.0) * hours_per_step)\n",
    "    blocked_sun_hours_pct = float(100.0 * blocked_sun_hours / total_daylight_hours) if total_daylight_hours > 0 else np.nan\n",
    "\n",
    "    meta = {\n",
    "        'tilt_deg': float(tilt),\n",
    "        'azimuth_deg': float(az),\n",
    "        'altitude_m': float(alt),\n",
    "        'loss_fraction': total_loss,\n",
    "        'svf': float(svf),\n",
    "        'mean_horizon_deg': float(np.mean(horz_elev)),\n",
    "        'cloud_cover_mean_pct': cloud_cover_mean_pct,\n",
    "        'cloudy_hours_pct': cloudy_hours_pct,\n",
    "        'blocked_sun_hours': blocked_sun_hours,\n",
    "        'blocked_sun_hours_pct': blocked_sun_hours_pct,\n",
    "        'interval_min': interval_min,\n",
    "    }\n",
    "\n",
    "    _PV_CACHE[key] = (daily_wh, meta)\n",
    "    return daily_wh, meta\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert Eddy-style device behavior into daily Wh (load model)\n",
    "# -------------------------------------------------------------\n",
    "# Assume a repeating daily pattern: N short high-current boots at a fixed cadence,\n",
    "# plus standby draw the rest of the day. If I want a day-split (e.g., 16h vs 8h cadence),\n",
    "# I’ll extend this to two segments.\n",
    "\n",
    "\n",
    "def _daily_load_wh(load: LoadParams) -> tuple[float, dict]:\n",
    "    boots = int(24 * 60 / load.check_every_minutes)\n",
    "    boot_I = load.boot_current_a + load.per_node_current_a * load.num_nodes\n",
    "    boot_Ah = boot_I * (load.boot_secs / 3600.0) * boots\n",
    "\n",
    "    standby_h = 24.0 - boots * (load.boot_secs / 3600.0)\n",
    "    standby_Ah = load.standby_current_a * max(standby_h, 0)\n",
    "\n",
    "    total_Ah = boot_Ah + standby_Ah\n",
    "    return total_Ah * load.system_voltage_v, {\n",
    "        'boots_per_day': boots,\n",
    "        'boot_Ah_day': boot_Ah,\n",
    "        'standby_Ah_day': standby_Ah,\n",
    "        'total_Ah_day': total_Ah,\n",
    "    }\n",
    "\n",
    "def recommended_battery_wh(load_wh_day: float, days: int, min_soc: float=0.10) -> tuple[float, float]:\n",
    "    \"\"\"Return (nominal_Wh, usable_Wh) to ride through `days` with min_soc reserve.\"\"\"\n",
    "    usable = load_wh_day * days\n",
    "    nominal = usable / (1.0 - min_soc)\n",
    "    return nominal, usable\n",
    "\n",
    "# Example (3 and 5 days)\n",
    "nom3, _ = recommended_battery_wh(LoadParams().system_voltage_v * (\n",
    "    (LoadParams().boot_current_a + LoadParams().per_node_current_a * LoadParams().num_nodes)\n",
    "    * (LoadParams().boot_secs/3600) * int(24*60/LoadParams().check_every_minutes)\n",
    "    + LoadParams().standby_current_a * (24 - int(24*60/LoadParams().check_every_minutes)*(LoadParams().boot_secs/3600))\n",
    "), days=3, min_soc=BatteryParams().min_soc)\n",
    "\n",
    "print(f\"Suggested nominal capacity for 3-day ride-through ≈ {nom3:.1f} Wh\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Daily SOC march (simple energy bucket with eff & reserve)\n",
    "# -------------------------------------------------------------\n",
    "# I keep it day-resolution on purpose; the PV model is hourly, but decisions (outage/viability)\n",
    "# for this class of device are fine at daily granularity.\n",
    "\n",
    "\n",
    "def _soc_daily(daily_pv_wh: pd.Series, daily_load_wh: float, batt: BatteryParams):\n",
    "    cap = batt.capacity_wh\n",
    "    min_wh = batt.min_soc * cap\n",
    "\n",
    "    soc = np.zeros(len(daily_pv_wh))\n",
    "    soc[0] = np.clip(batt.initial_soc, 0, 1)\n",
    "    outage = None\n",
    "\n",
    "    for i, pv in enumerate(daily_pv_wh.values):\n",
    "        stored = soc[i - 1] * cap if i > 0 else soc[0] * cap\n",
    "        stored = stored + pv * batt.charge_eff - (daily_load_wh / batt.discharge_eff)\n",
    "        stored = float(np.clip(stored, 0, cap))\n",
    "        if outage is None and stored < min_wh:\n",
    "            outage = daily_pv_wh.index[i]\n",
    "        soc[i] = stored / cap\n",
    "\n",
    "    s = pd.Series(soc, index=daily_pv_wh.index, name='soc_frac')\n",
    "    deficit_days = int(((s * cap) < min_wh).sum())\n",
    "    return s, deficit_days, outage\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Feature wrapper used by my candidate ranking (single site)\n",
    "# -------------------------------------------------------------\n",
    "# This bundles PV → load → SOC plus diagnostics I want to plot.\n",
    "\n",
    "def _longest_run_below(series: pd.Series, threshold: float) -> int:\n",
    "    \"\"\"Longest consecutive days where series < threshold.\"\"\"\n",
    "    arr = (series.values < threshold).astype(int)\n",
    "    m = run = 0\n",
    "    for v in arr:\n",
    "        run = run + 1 if v else 0\n",
    "        m = run if run > m else m\n",
    "    return int(m)\n",
    "\n",
    "def _p10(series: pd.Series) -> float:\n",
    "    return float(series.quantile(0.10))\n",
    "\n",
    "def solar_features_for_coord(\n",
    "    coord: tuple[float, float],\n",
    "    dem_manager,\n",
    "    pv: PVParams = PVParams(),\n",
    "    load: LoadParams = LoadParams(),\n",
    "    batt: BatteryParams = BatteryParams(),\n",
    "    year: int = 2022,\n",
    "    force_south: bool = True,\n",
    ") -> dict:\n",
    "    daily_pv_wh, meta = _pv_dc_daily_wh(coord, dem_manager, pv, year=year, force_south=force_south)\n",
    "    load_wh_day, _ = _daily_load_wh(load)\n",
    "    soc, deficit_days, outage = _soc_daily(daily_pv_wh, load_wh_day, batt)\n",
    "    pv_p10_wh = _p10(daily_pv_wh)\n",
    "    longest_deficit_run = _longest_run_below(daily_pv_wh, load_wh_day)\n",
    "\n",
    "    return {\n",
    "        'pv_wh_day_mean': float(daily_pv_wh.mean()),\n",
    "        'pv_p10_wh_day': float(pv_p10_wh),                        \n",
    "        'longest_deficit_run_days': int(longest_deficit_run), \n",
    "        'pv_wh_year': float(daily_pv_wh.sum()),\n",
    "        'load_wh_day': float(load_wh_day),\n",
    "        'energy_margin_wh_day': float(daily_pv_wh.mean() - load_wh_day),\n",
    "        'deficit_days': int(deficit_days),\n",
    "        'first_outage_day': outage,\n",
    "        'tilt_deg': meta.get('tilt_deg'),\n",
    "        'azimuth_deg': meta.get('azimuth_deg'),\n",
    "        'pv_loss_fraction': meta.get('loss_fraction'),\n",
    "        # Diagnostics I find useful for plots and sanity checks\n",
    "        'svf': meta.get('svf'),\n",
    "        'mean_horizon_deg': meta.get('mean_horizon_deg'),\n",
    "        'cloud_cover_mean_pct': meta.get('cloud_cover_mean_pct'),\n",
    "        'cloudy_hours_pct': meta.get('cloudy_hours_pct'),\n",
    "        'blocked_sun_hours': meta.get('blocked_sun_hours'),\n",
    "        'blocked_sun_hours_pct': meta.get('blocked_sun_hours_pct'),\n",
    "        'wx_interval_min': meta.get('interval_min'),\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Map physical energy margin → bounded 0..1 solar score\n",
    "# -------------------------------------------------------------\n",
    "# I use a logistic so 0 Wh/day margin → score ~0.5. Positive margin pushes >0.5; negative <0.5.\n",
    "\n",
    "\n",
    "def solar_score_from_energy_margin(margin_wh_day: float, scale: float = 50.0) -> float:\n",
    "    x = float(margin_wh_day) / (float(scale) if scale else 1.0)\n",
    "    return float(1.0 / (1.0 + np.exp(-x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0faef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER_CACHE.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5fcdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ===== DEM HANDLING & CORE UTILITIES =====\n",
    "from astropy import units as u\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import pycraf\n",
    "import pycraf.utils as pu\n",
    "from pycraf.pathprof import PathProp, loss_freespace\n",
    "\n",
    "class DEMManager:\n",
    "    \"\"\"\n",
    "    Centralized manager for DEM (ground), DSM (surface), CHM (canopy) data and utilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, dem_bytes: bytes):\n",
    "        with MemoryFile(dem_bytes) as memfile:\n",
    "            with memfile.open() as src:\n",
    "                self.dem_array = src.read(1)\n",
    "                self.transform = src.transform\n",
    "                self.bounds = src.bounds\n",
    "                self.profile = src.profile\n",
    "                self.crs = src.crs\n",
    "        self.shape = self.dem_array.shape\n",
    "        self.slope_arr = None\n",
    "        self.aspect_arr = None\n",
    "\n",
    "        # Add new arrays for DSM (LiDAR) and CHM (Canopy Height Model)\n",
    "        self.dsm_array = None\n",
    "        self.dsm_transform = None\n",
    "        self.chm_array = None\n",
    "        self.chm_transform = None\n",
    "\n",
    "        pixel_width = abs(self.transform.a)\n",
    "        pixel_height = abs(self.transform.e)\n",
    "        print(f\"DEM pixel width: {pixel_width}, pixel height: {pixel_height}\")\n",
    "        if pixel_width < 1e-6 or pixel_height < 1e-6:\n",
    "            raise ValueError(\"Invalid DEM: pixel size too small.\")\n",
    "\n",
    "    def set_dsm(self, dsm_array, dsm_transform):\n",
    "        self.dsm_array = dsm_array\n",
    "        self.dsm_transform = dsm_transform\n",
    "\n",
    "    def set_chm(self, chm_array, chm_transform):\n",
    "        self.chm_array = chm_array\n",
    "        self.chm_transform = chm_transform\n",
    "\n",
    "    def calculate_slope_and_aspect(self):\n",
    "        center_col = self.dem_array.shape[1] // 2\n",
    "        center_row = self.dem_array.shape[0] // 2\n",
    "        lon0, lat0 = self.transform * (center_col, center_row)\n",
    "        dx_meter, dy_meter = self.degree_to_meter(lon0, lat0)\n",
    "        gy, gx = np.gradient(self.dem_array.astype(float), dy_meter, dx_meter)\n",
    "        self.slope_arr = np.degrees(np.arctan(np.sqrt(gx**2 + gy**2)))\n",
    "        aspect_rad = np.arctan2(-gx, gy)\n",
    "        self.aspect_arr = np.degrees(aspect_rad)\n",
    "        self.aspect_arr[self.aspect_arr < 0] += 360\n",
    "\n",
    "    def degree_to_meter(self, lon, lat):\n",
    "        geod = Geod(ellps='WGS84')\n",
    "        dx = abs(self.transform.a)\n",
    "        dy = abs(self.transform.e)\n",
    "        _, _, x_meter = geod.inv(lon, lat, lon + dx, lat)\n",
    "        _, _, y_meter = geod.inv(lon, lat, lon, lat + dy)\n",
    "        return abs(x_meter), abs(y_meter)\n",
    "\n",
    "    def get_elevation(self, coord: Tuple[float, float]) -> float:\n",
    "        # Ground elevation (DEM)\n",
    "        col, row = ~self.transform * coord\n",
    "        row, col = int(row), int(col)\n",
    "        if 0 <= row < self.shape[0] and 0 <= col < self.shape[1]:\n",
    "            return float(self.dem_array[row, col])\n",
    "        return 0.0\n",
    "\n",
    "    def get_surface_elevation(self, coord: Tuple[float, float]) -> float:\n",
    "        # Surface elevation (DSM/LiDAR)\n",
    "        if self.dsm_array is None or self.dsm_transform is None:\n",
    "            return self.get_elevation(coord)\n",
    "        col, row = ~self.dsm_transform * coord\n",
    "        row, col = int(row), int(col)\n",
    "        if 0 <= row < self.dsm_array.shape[0] and 0 <= col < self.dsm_array.shape[1]:\n",
    "            return float(self.dsm_array[row, col])\n",
    "        return self.get_elevation(coord)\n",
    "\n",
    "    def lonlat_to_chm_pixel(self, lon, lat):\n",
    "        chm_crs = getattr(self, 'chm_crs', self.crs)\n",
    "        if str(chm_crs) != \"EPSG:4326\":\n",
    "            transformer = Transformer.from_crs(\"EPSG:4326\", chm_crs, always_xy=True)\n",
    "            x, y = transformer.transform(lon, lat)\n",
    "        else:\n",
    "            x, y = lon, lat\n",
    "        col, row = ~self.chm_transform * (x, y)\n",
    "        return int(row), int(col)\n",
    "    def get_canopy_height(self, coord: Tuple[float, float]) -> float:\n",
    "        if self.chm_array is None or self.chm_transform is None:\n",
    "            return 0.0\n",
    "        try:\n",
    "            row, col = self.lonlat_to_chm_pixel(coord[0], coord[1])\n",
    "            if 0 <= row < self.chm_array.shape[0] and 0 <= col < self.chm_array.shape[1]:\n",
    "                return float(self.chm_array[row, col])\n",
    "            else:\n",
    "                return 0.0\n",
    "        except Exception as e:\n",
    "            return 0.0\n",
    "\n",
    "    def get_slope_at_coord(self, coord: Tuple[float, float]) -> float:\n",
    "        # Get slope at a specific coordinate\n",
    "        col, row = ~self.transform * coord\n",
    "        row, col = int(row), int(col)\n",
    "        \n",
    "        if (self.slope_arr is not None and \n",
    "            0 <= row < self.slope_arr.shape[0] and \n",
    "            0 <= col < self.slope_arr.shape[1]):\n",
    "            return float(self.slope_arr[row, col])\n",
    "        else:\n",
    "            return 10.0  # Default moderate slope\n",
    "\n",
    "    def get_terrain_profile(self, p1: Tuple[float, float], p2: Tuple[float, float], num_samples: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        lons = np.linspace(p1[0], p2[0], num_samples)\n",
    "        lats = np.linspace(p1[1], p2[1], num_samples)\n",
    "        elevs = np.array([self.get_elevation((lon, lat)) for lon, lat in zip(lons, lats)])\n",
    "        dist_m = geodesic(p1[::-1], p2[::-1]).meters\n",
    "        dists = np.linspace(0, dist_m, num_samples)\n",
    "        return dists, elevs\n",
    "\n",
    "    def add_lidar_processing_to_demmanager(dem_manager, aoi_poly, lidar_tif):\n",
    "        \"\"\"\n",
    "        Add your LiDAR processing code to the DEMManager\n",
    "        \"\"\"\n",
    "        import pyproj\n",
    "        from shapely.ops import transform as shapely_transform\n",
    "        import rasterio\n",
    "        from rasterio.mask import mask\n",
    "        from rasterio.warp import reproject, Resampling\n",
    "        from shapely.geometry import mapping\n",
    "    \n",
    "        def reproject_aoi_to_raster(aoi_poly, raster_crs):\n",
    "            project = pyproj.Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True).transform\n",
    "            aoi_proj = shapely_transform(project, aoi_poly)\n",
    "            return aoi_proj\n",
    "    \n",
    "        # Load and Mask LiDAR to AOI\n",
    "        with rasterio.open(lidar_tif) as src:\n",
    "            lidar_crs = src.crs\n",
    "            if aoi_poly is not None:\n",
    "                aoi_proj = reproject_aoi_to_raster(aoi_poly, lidar_crs)\n",
    "                out_image, out_transform = mask(src, [mapping(aoi_proj)], crop=True)\n",
    "                lidar_data = out_image[0]\n",
    "                lidar_transform = out_transform\n",
    "                nodata = src.nodata if src.nodata is not None else -999999.0\n",
    "                print(\"Masked LiDAR to AOI bounds.\")\n",
    "            else:\n",
    "                lidar_data = src.read(1)\n",
    "                lidar_transform = src.transform\n",
    "                nodata = src.nodata if src.nodata is not None else -999999.0\n",
    "                print(\"⚠️ AOI not set, showing full raster.\")\n",
    "    \n",
    "        # Mask nodata for display\n",
    "        lidar_masked = np.where((lidar_data == nodata) | (lidar_data < -1000), np.nan, lidar_data)\n",
    "    \n",
    "        # Compute Slope and Aspect from DSM\n",
    "        dy, dx = abs(lidar_transform.e), abs(lidar_transform.a)\n",
    "        gy, gx = np.gradient(lidar_masked.astype(float), dy, dx)\n",
    "        slope = np.degrees(np.arctan(np.sqrt(gx**2 + gy**2)))\n",
    "        aspect = np.degrees(np.arctan2(-gx, gy))\n",
    "        aspect[aspect < 0] += 360\n",
    "    \n",
    "        # Compute Canopy Height Model (CHM)\n",
    "        dem_resampled = np.empty_like(lidar_data, dtype=float)\n",
    "        reproject(\n",
    "            dem_manager.dem_array,\n",
    "            dem_resampled,\n",
    "            src_transform=dem_manager.transform,\n",
    "            src_crs=dem_manager.crs,\n",
    "            dst_transform=lidar_transform,\n",
    "            dst_crs=lidar_crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        chm = lidar_data - dem_resampled\n",
    "        chm[chm < 0] = 0\n",
    "        chm_transform = lidar_transform\n",
    "    \n",
    "        # Set the data in DEMManager\n",
    "        dem_manager.set_dsm(lidar_data, lidar_transform)\n",
    "        dem_manager.set_chm(chm, chm_transform)\n",
    "    \n",
    "        print(\"LiDAR processing complete - DSM and CHM added to DEMManager\")\n",
    "        return dem_manager\n",
    "\n",
    "# --- Sampling, Grid, Path Loss, Solar Utilities (with cache note) ---\n",
    "\n",
    "def reproject_aoi_to_raster(aoi_poly, raster_crs):\n",
    "    \"\"\"Reproject AOI polygon from EPSG:4326 to raster CRS\"\"\"\n",
    "    import pyproj\n",
    "    from shapely.ops import transform as shapely_transform\n",
    "    \n",
    "    project = pyproj.Transformer.from_crs(\"EPSG:4326\", raster_crs, always_xy=True).transform\n",
    "    aoi_proj = shapely_transform(project, aoi_poly)\n",
    "    return aoi_proj\n",
    "\n",
    "\n",
    "def sample_points_in_poly(polygon: Polygon, n_points: int) -> List[Tuple[float, float]]:\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    points = []\n",
    "    while len(points) < n_points:\n",
    "        p = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if polygon.contains(p):\n",
    "            points.append((p.x, p.y))\n",
    "    return points\n",
    "\n",
    "def generate_coverage_grid(polygon: Polygon, grid_size: int) -> List[Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Generate coverage grid points within AOI polygon with elevation validation.\n",
    "    Maintains original function signature for compatibility.\n",
    "    \"\"\"\n",
    "    global dem_manager  # Access the global DEM manager\n",
    "    \n",
    "    min_x, min_y, max_x, max_y = polygon.bounds\n",
    "    \n",
    "    # Calculate grid spacing for debugging\n",
    "    x_spacing_deg = (max_x - min_x) / (grid_size - 1) if grid_size > 1 else max_x - min_x\n",
    "    y_spacing_deg = (max_y - min_y) / (grid_size - 1) if grid_size > 1 else max_y - min_y\n",
    "    \n",
    "    # Calculate approximate spacing in meters\n",
    "    center_lat = (min_y + max_y) / 2\n",
    "    center_lon = (min_x + max_x) / 2\n",
    "    meters_per_deg_lat = 111000\n",
    "    meters_per_deg_lon = 111000 * np.cos(np.radians(center_lat))\n",
    "    x_spacing_m = x_spacing_deg * meters_per_deg_lon\n",
    "    y_spacing_m = y_spacing_deg * meters_per_deg_lat\n",
    "    \n",
    "    print(f\"\\nGenerating Coverage Grid:\")\n",
    "    print(f\"   AOI Bounds: ({min_x:.6f}, {min_y:.6f}) to ({max_x:.6f}, {max_y:.6f})\")\n",
    "    print(f\"   AOI Size: {(max_x-min_x)*meters_per_deg_lon:.0f}m × {(max_y-min_y)*meters_per_deg_lat:.0f}m\")\n",
    "    print(f\"   Grid Configuration: {grid_size}×{grid_size} (max {grid_size*grid_size} points)\")\n",
    "    print(f\"   Grid Spacing: {x_spacing_m:.1f}m × {y_spacing_m:.1f}m\")\n",
    "    \n",
    "    # Generate grid coordinates\n",
    "    x_coords = np.linspace(min_x, max_x, grid_size)\n",
    "    y_coords = np.linspace(min_y, max_y, grid_size)\n",
    "    \n",
    "    # Track statistics\n",
    "    total_attempted = 0\n",
    "    inside_aoi = 0\n",
    "    valid_elevation = 0\n",
    "    elevation_failures = 0\n",
    "    grid_points = []\n",
    "    elevation_stats = []\n",
    "    \n",
    "    # Check each potential grid point\n",
    "    for x in x_coords:\n",
    "        for y in y_coords:\n",
    "            total_attempted += 1\n",
    "            point = Point(x, y)\n",
    "            \n",
    "            # Check if point is inside polygon\n",
    "            if polygon.contains(point):\n",
    "                inside_aoi += 1\n",
    "                coord = (x, y)\n",
    "                \n",
    "                # Validate elevation if DEM manager is available\n",
    "                if dem_manager is not None:\n",
    "                    try:\n",
    "                        # Get elevation for this point\n",
    "                        elevation = dem_manager.get_elevation(coord)\n",
    "                        \n",
    "                        # Check if elevation is valid (not NaN or extreme values)\n",
    "                        if np.isfinite(elevation) and -500 < elevation < 9000:  # Reasonable Earth elevation range\n",
    "                            valid_elevation += 1\n",
    "                            grid_points.append(coord)\n",
    "                            elevation_stats.append(elevation)\n",
    "                        else:\n",
    "                            elevation_failures += 1\n",
    "                            print(f\"   Invalid elevation at {coord}: {elevation}\")\n",
    "                            # Still include the point but note the issue\n",
    "                            grid_points.append(coord)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        elevation_failures += 1\n",
    "                        print(f\"   Could not get elevation for {coord}: {e}\")\n",
    "                        # Include point anyway for robustness\n",
    "                        grid_points.append(coord)\n",
    "                else:\n",
    "                    # No DEM manager available, just add the point\n",
    "                    grid_points.append(coord)\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    print(f\"\\nGrid Generation Results:\")\n",
    "    print(f\"   Total points checked: {total_attempted}\")\n",
    "    print(f\"   Points inside AOI: {inside_aoi} ({100*inside_aoi/total_attempted:.1f}%)\")\n",
    "    \n",
    "    if dem_manager is not None and elevation_stats:\n",
    "        print(f\"   Points with valid elevation: {valid_elevation}\")\n",
    "        if elevation_failures > 0:\n",
    "            print(f\"   Elevation failures: {elevation_failures}\")\n",
    "        print(f\"   Elevation range: {min(elevation_stats):.1f}m to {max(elevation_stats):.1f}m\")\n",
    "        print(f\"   Mean elevation: {np.mean(elevation_stats):.1f}m\")\n",
    "        \n",
    "        # Check data source\n",
    "        if hasattr(dem_manager, 'dsm_array') and dem_manager.dsm_array is not None:\n",
    "            print(f\"   Using DSM/LiDAR data for elevations\")\n",
    "        elif hasattr(dem_manager, 'chm_array') and dem_manager.chm_array is not None:\n",
    "            print(f\"   CHM vegetation data available\")\n",
    "        else:\n",
    "            print(f\"  Using standard DEM elevations\")\n",
    "    \n",
    "    # Coverage density\n",
    "    if polygon.area > 0:\n",
    "        area_km2 = polygon.area * (meters_per_deg_lat * meters_per_deg_lon) / 1e6\n",
    "        density = len(grid_points) / area_km2 if area_km2 > 0 else 0\n",
    "        print(f\"   Coverage density: {density:.1f} points/km²\")\n",
    "    \n",
    "    # Distance analysis from centroid\n",
    "    if grid_points:\n",
    "        centroid = (polygon.centroid.x, polygon.centroid.y)\n",
    "        distances = [geodesic(p[::-1], centroid[::-1]).meters for p in grid_points]\n",
    "        print(f\"   Distance from AOI center:\")\n",
    "        print(f\"     Min: {min(distances):.0f}m\")\n",
    "        print(f\"     Max: {max(distances):.0f}m\") \n",
    "        print(f\"     Mean: {np.mean(distances):.0f}m\")\n",
    "        \n",
    "        # Check distribution within communication ranges\n",
    "        if 'NETWORK' in globals():\n",
    "            comm_range = NETWORK.MAX_COMM_RANGE_M\n",
    "            within_1x = sum(1 for d in distances if d <= comm_range)\n",
    "            within_2x = sum(1 for d in distances if d <= comm_range * 2)\n",
    "            print(f\"   Points within {comm_range:.0f}m: {within_1x} ({100*within_1x/len(grid_points):.1f}%)\")\n",
    "            print(f\"   Points within {comm_range*2:.0f}m: {within_2x} ({100*within_2x/len(grid_points):.1f}%)\")\n",
    "    \n",
    "    print(f\"   Final grid: {len(grid_points)} points\\n\")\n",
    "    \n",
    "    return grid_points\n",
    "\n",
    "# --- Utility: Consistent Gateway Sorting for Plotting ---\n",
    "def sort_gateways(solution, sort_by=\"lon\"):\n",
    "    \"\"\"\n",
    "    Sorts gateways for consistent labeling in plots.\n",
    "    Args:\n",
    "        solution (list): List of gateway dicts, each with 'coord' key (lon, lat)\n",
    "        sort_by (str): Sorting method: 'lon', 'lat', or 'centroid'\n",
    "    Returns:\n",
    "        Sorted list of gateway dicts\n",
    "    \"\"\"\n",
    "    if not solution or not isinstance(solution, list) or 'coord' not in solution[0]:\n",
    "        return solution\n",
    "    if sort_by == \"lon\":\n",
    "        return sorted(solution, key=lambda gw: gw['coord'][0])   # West to East\n",
    "    elif sort_by == \"lat\":\n",
    "        return sorted(solution, key=lambda gw: gw['coord'][1])   # South to North\n",
    "    elif sort_by == \"centroid\":\n",
    "        if 'aoi_poly' in globals() and aoi_poly is not None:\n",
    "            from shapely.geometry import Point\n",
    "            centroid = aoi_poly.centroid\n",
    "            return sorted(solution, key=lambda gw: Point(gw['coord']).distance(centroid))\n",
    "        else:\n",
    "            return solution\n",
    "    else:\n",
    "        return solution\n",
    "    \n",
    "def normalize_df_columns(df, columns):\n",
    "    \"\"\"\n",
    "    Normalize specified columns to 0-1 range using min-max scaling\n",
    "    \"\"\"\n",
    "    df_normalized = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            col_min = df[col].min()\n",
    "            col_max = df[col].max()\n",
    "            if col_max != col_min:  # Avoid division by zero\n",
    "                df_normalized[col] = (df[col] - col_min) / (col_max - col_min)\n",
    "            else:\n",
    "                df_normalized[col] = 0.5  # Set to middle value if all same\n",
    "    return df_normalized\n",
    "\n",
    "\n",
    "def calculate_solar_score(\n",
    "    coord: Tuple[float, float],\n",
    "    dem_manager: DEMManager,\n",
    "    panel_power_watts: float = 50,\n",
    "    gamma_pdc: float = -0.004,\n",
    "    inverter_power_watts: float = 50,\n",
    "    temp_air: float = 20.0,\n",
    "    wind_speed: float = 1.0\n",
    ") -> float:\n",
    "    col, row = ~dem_manager.transform * coord\n",
    "    row, col = int(row), int(col)\n",
    "    if not (0 <= row < dem_manager.shape[0] and 0 <= col < dem_manager.shape[1]):\n",
    "        return 0.0\n",
    "    tilt = float(np.clip(dem_manager.slope_arr[row, col], 0, 90)) if dem_manager.slope_arr is not None else 30.0\n",
    "    azimuth = float(dem_manager.aspect_arr[row, col] % 360) if dem_manager.aspect_arr is not None else 180.0\n",
    "    altitude = float(dem_manager.dem_array[row, col])\n",
    "    lon, lat = coord\n",
    "    loc = Location(lat, lon, tz='UTC', altitude=altitude)\n",
    "    times = pd.date_range('2025-06-21', periods=24, freq='H', tz=loc.tz)\n",
    "    weather = loc.get_clearsky(times, model='ineichen')\n",
    "    weather['temp_air'] = temp_air\n",
    "    weather['wind_speed'] = wind_speed\n",
    "    system = PVSystem(\n",
    "        surface_tilt=tilt,\n",
    "        surface_azimuth=azimuth,\n",
    "        module_parameters={'pdc0': panel_power_watts, 'gamma_pdc': gamma_pdc},\n",
    "        inverter_parameters={'pdc0': inverter_power_watts},\n",
    "        temperature_model_parameters={'a': -3.56, 'b': 0.0594, 'deltaT': 3}\n",
    "    )\n",
    "    mc = ModelChain(system, loc, dc_model='pvwatts', ac_model='pvwatts', aoi_model='physical',\n",
    "                    spectral_model='no_loss', temperature_model='sapm', losses_model='no_loss')\n",
    "    mc.run_model(weather)\n",
    "    return float(mc.results.ac.sum()) / 1000.0 if hasattr(mc.results, 'ac') else 0.0\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# PYCRAF FUNCTIONS WITH INTERNAL IMPORTS (PARALLEL-SAFE)\n",
    "# =================================================================\n",
    "\n",
    "from pycraf import conversions as cnv\n",
    "from pycraf import pathprof as pp\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "import numbers\n",
    "\n",
    "def _get_terrain_profile_for_pycraf(p1, p2, dem_array, dem_transform):\n",
    "    \"\"\"Keep your original function name - just ensure it works properly\"\"\"\n",
    "    dist_m = geodesic(p1[::-1], p2[::-1]).meters\n",
    "    step_m = 10\n",
    "    num_samples = max(2, int(dist_m // step_m) + 1)\n",
    "    lons = np.linspace(p1[0], p2[0], num_samples)\n",
    "    lats = np.linspace(p1[1], p2[1], num_samples)\n",
    "    elev = []\n",
    "    for lon, lat in zip(lons, lats):\n",
    "        col, row = ~dem_transform * (lon, lat)\n",
    "        row, col = int(row), int(col)\n",
    "        if 0 <= row < dem_array.shape[0] and 0 <= col < dem_array.shape[1]:\n",
    "            elev.append(float(dem_array[row, col]))\n",
    "        else:\n",
    "            elev.append(np.nanmean(dem_array))\n",
    "    return np.array(elev), step_m, dist_m\n",
    "\n",
    "def calculate_bearing_array(lons, lats):\n",
    "    \"\"\"Keep your original function - just ensure it returns proper scalar for pycraf\"\"\"\n",
    "    bearings = np.zeros(len(lons), dtype=float)\n",
    "    for i in range(len(lons) - 1):\n",
    "        d_lon = lons[i+1] - lons[i]\n",
    "        d_lat = lats[i+1] - lats[i]\n",
    "        angle = np.arctan2(d_lon, d_lat)\n",
    "        bearings[i] = np.degrees(angle)\n",
    "    bearings[-1] = bearings[-2] if len(bearings) > 1 else 0.0\n",
    "    return bearings\n",
    "\n",
    "def safe_extract_loss(loss_result, loss_name=\"Loss\"):\n",
    "    \"\"\"\n",
    "    NEW FUNCTION - Add this to handle pycraf tuple returns\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if loss_result is None:\n",
    "            return 0.0\n",
    "            \n",
    "        # Handle tuple returns (this fixes your error!)\n",
    "        if isinstance(loss_result, (tuple, list)):\n",
    "            if len(loss_result) == 0:\n",
    "                return 0.0\n",
    "            result = loss_result[0]  # Take first element\n",
    "        else:\n",
    "            result = loss_result\n",
    "            \n",
    "        # Handle astropy units\n",
    "        if hasattr(result, 'to'):\n",
    "            return float(result.to(u.dB).value)\n",
    "        elif hasattr(result, 'value'):\n",
    "            return float(result.value)\n",
    "        else:\n",
    "            return float(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return 0.0  # Safe fallback\n",
    "\n",
    "print(\"Added safe_extract_loss() function to handle tuple returns\")\n",
    "\n",
    "\n",
    "\n",
    "from astropy import units as u\n",
    "from pycraf.pathprof import PathProp, loss_complete\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "\n",
    "def calculate_path_loss_pycraf(\n",
    "    p1: tuple, p2: tuple,\n",
    "    dem_manager,          # DEMManager class\n",
    "    tx_h: float, rx_h: float, freq_mhz: float,\n",
    "    veg_threshold: float, attn_per_meter: float,\n",
    "    max_comm_range: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Most realistic path loss using pycraf's ITU-R P.452-16: terrain+canopy profile and antenna heights.\n",
    "    FIXED: Properly handles tuple return from loss_complete\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Distance check\n",
    "        dist_m = geodesic(p1[::-1], p2[::-1]).meters\n",
    "        if dist_m > max_comm_range or dist_m <= 0:\n",
    "            return np.inf\n",
    "\n",
    "        # Use a reasonable sampling step\n",
    "        step_m = 10\n",
    "        num_samples = max(5, int(dist_m // step_m) + 1)\n",
    "        lons = np.linspace(p1[0], p2[0], num_samples)\n",
    "        lats = np.linspace(p1[1], p2[1], num_samples)\n",
    "\n",
    "        # --- DEM + CHM if possible, else fallback\n",
    "        if hasattr(dem_manager, 'chm_array') and dem_manager.chm_array is not None:\n",
    "            terrain_profile = np.array([\n",
    "                dem_manager.get_elevation((lon, lat)) +\n",
    "                dem_manager.get_canopy_height((lon, lat))\n",
    "                for lon, lat in zip(lons, lats)\n",
    "            ])\n",
    "            using_vegetation = True\n",
    "        elif hasattr(dem_manager, 'dsm_array') and dem_manager.dsm_array is not None:\n",
    "            terrain_profile = np.array([\n",
    "                dem_manager.get_surface_elevation((lon, lat))\n",
    "                for lon, lat in zip(lons, lats)\n",
    "            ])\n",
    "            using_vegetation = True\n",
    "        else:\n",
    "            terrain_profile = np.array([\n",
    "                dem_manager.get_elevation((lon, lat))\n",
    "                for lon, lat in zip(lons, lats)\n",
    "            ])\n",
    "            using_vegetation = False\n",
    "\n",
    "        # Fix for nan/degenerate profile\n",
    "        if len(terrain_profile) < 2 or np.all(np.isnan(terrain_profile)):\n",
    "            return 120.0\n",
    "        terrain_profile = np.nan_to_num(terrain_profile, nan=np.nanmean(terrain_profile))\n",
    "        dists = np.linspace(0, dist_m, len(terrain_profile))\n",
    "\n",
    "        # pycraf needs astropy.units on everything\n",
    "        from pycraf.pathprof import PathProp, loss_complete\n",
    "        from astropy import units as u\n",
    "        \n",
    "        freq = freq_mhz * 1e6 * u.Hz\n",
    "        temperature = 290.0 * u.K\n",
    "        pressure = 1013.0 * u.hPa\n",
    "        lon_t, lat_t = p1[0] * u.deg, p1[1] * u.deg\n",
    "        lon_r, lat_r = p2[0] * u.deg, p2[1] * u.deg\n",
    "        h_tg = tx_h * u.m\n",
    "        h_rg = rx_h * u.m\n",
    "        hprof_step = step_m * u.m\n",
    "        timepercent = 2.0 * u.percent\n",
    "\n",
    "        # Provide the terrain heights, dists, and optional bearings\n",
    "        bearing = np.degrees(np.arctan2(p2[0] - p1[0], p2[1] - p1[1]))\n",
    "        backbearing = (bearing + 180) % 360\n",
    "\n",
    "        pprop = PathProp(\n",
    "            freq, temperature, pressure,\n",
    "            lon_t, lat_t, lon_r, lat_r,\n",
    "            h_tg, h_rg,\n",
    "            hprof_step,\n",
    "            timepercent,\n",
    "            hprof_dists=dists * u.m,\n",
    "            hprof_heights=terrain_profile * u.m,\n",
    "            hprof_bearing=bearing * u.deg,\n",
    "            hprof_backbearing=backbearing * u.deg\n",
    "        )\n",
    "\n",
    "        # Handle tuple return from loss_complete\n",
    "        # loss_complete returns a tuple: (L_b, L_b0p, L_bd, L_bd50, L_bam, L_b0b, L_bs, L_ba, L_dk, L_dh, L)\n",
    "        losses = loss_complete(pprop)\n",
    "        \n",
    "        # The total loss 'L' is the last element of the tuple (index 10 or -1)\n",
    "        if isinstance(losses, tuple):\n",
    "            # Get the total loss (last element)\n",
    "            total_loss_result = losses[-1]  # or losses[10] for L\n",
    "        else:\n",
    "            # Fallback if it's not a tuple (shouldn't happen)\n",
    "            total_loss_result = losses\n",
    "        \n",
    "        # Extract the numeric value\n",
    "        if hasattr(total_loss_result, 'to'):\n",
    "            total_loss = float(total_loss_result.to(u.dB).value)\n",
    "        elif hasattr(total_loss_result, 'value'):\n",
    "            total_loss = float(total_loss_result.value)\n",
    "        else:\n",
    "            total_loss = float(total_loss_result)\n",
    "\n",
    "        # --- Extra vegetation penalty if using CHM/DSM ---\n",
    "        veg_loss_db = 0.0\n",
    "        if using_vegetation and veg_threshold > 0:\n",
    "            dense_veg = [dem_manager.get_canopy_height((lon, lat)) \n",
    "                        for lon, lat in zip(lons, lats) \n",
    "                        if dem_manager.get_canopy_height((lon, lat)) > veg_threshold]\n",
    "            if dense_veg:\n",
    "                veg_loss_db = min(2.0, np.mean(dense_veg) * 0.02)\n",
    "\n",
    "        total_loss += veg_loss_db\n",
    "        return max(60.0, min(total_loss, 200.0))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Path loss error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 120.0\n",
    "\n",
    "\n",
    "def calculate_path_analysis_pycraf(\n",
    "    p1: tuple, p2: tuple,\n",
    "    dem_manager,\n",
    "    tx_h: float, rx_h: float, freq_mhz: float,\n",
    "    veg_threshold: float, attn_per_meter: float,\n",
    "    max_comm_range: float\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Path loss + explicit Fresnel clearance (loss uses full ITU-R P.452 model).\n",
    "    FIXED: Better Fresnel calculation that handles edge cases\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dist_m = geodesic(p1[::-1], p2[::-1]).meters\n",
    "        if dist_m > max_comm_range or dist_m <= 0:\n",
    "            return {'path_loss': np.inf, 'min_clearance': -np.inf, 'percent_clear': 0.0}\n",
    "\n",
    "        step_m = 10\n",
    "        num_samples = max(10, int(dist_m // step_m) + 1)  # More samples for better accuracy\n",
    "        lons = np.linspace(p1[0], p2[0], num_samples)\n",
    "        lats = np.linspace(p1[1], p2[1], num_samples)\n",
    "\n",
    "        # --- Use the same DEM/CHM/DSM fallback logic as in loss function\n",
    "        if hasattr(dem_manager, 'chm_array') and dem_manager.chm_array is not None:\n",
    "            profile = np.array([\n",
    "                dem_manager.get_elevation((lon, lat)) +\n",
    "                dem_manager.get_canopy_height((lon, lat))\n",
    "                for lon, lat in zip(lons, lats)\n",
    "            ])\n",
    "        elif hasattr(dem_manager, 'dsm_array') and dem_manager.dsm_array is not None:\n",
    "            profile = np.array([\n",
    "                dem_manager.get_surface_elevation((lon, lat))\n",
    "                for lon, lat in zip(lons, lats)\n",
    "            ])\n",
    "        else:\n",
    "            profile = np.array([\n",
    "                dem_manager.get_elevation((lon, lat))\n",
    "                for lon, lat in zip(lons, lats)\n",
    "            ])\n",
    "        profile = np.nan_to_num(profile, nan=np.nanmean(profile))\n",
    "\n",
    "        # --- Fresnel clearance calculation\n",
    "        def fresnel_clearance_percent(profile, tx_h, rx_h, dist_m, freq_mhz, clearance_ratio=0.6):\n",
    "            \"\"\"\n",
    "            Calculate Fresnel zone clearance percentage\n",
    "            \"\"\"\n",
    "            c = 3e8\n",
    "            lambda_ = c / (freq_mhz * 1e6)\n",
    "            num_samples = len(profile)\n",
    "            \n",
    "            # Total antenna heights (ground + antenna height)\n",
    "            tx_z = profile[0] + tx_h\n",
    "            rx_z = profile[-1] + rx_h\n",
    "            \n",
    "            # Line of sight between antennas\n",
    "            los_line = np.linspace(tx_z, rx_z, num_samples)\n",
    "            \n",
    "            # Distance from TX to each point\n",
    "            d1 = np.linspace(0, dist_m, num_samples)\n",
    "            d2 = dist_m - d1\n",
    "            \n",
    "            # Calculate Fresnel zone radius at each point\n",
    "            # Avoid division by zero at endpoints\n",
    "            fresnel = np.zeros(num_samples)\n",
    "            for i in range(num_samples):\n",
    "                if d1[i] > 0 and d2[i] > 0:\n",
    "                    fresnel[i] = np.sqrt(lambda_ * d1[i] * d2[i] / dist_m)\n",
    "            \n",
    "            # Clearance from terrain to LOS\n",
    "            clearance = los_line - profile\n",
    "            \n",
    "            # Required clearance (60% of Fresnel zone)\n",
    "            required_clearance = clearance_ratio * fresnel\n",
    "            \n",
    "            # Find minimum clearance (negative means obstruction)\n",
    "            fresnel_clearance = clearance - required_clearance\n",
    "            \n",
    "            # Skip endpoints (TX and RX positions)\n",
    "            if len(fresnel_clearance) > 2:\n",
    "                interior_clearance = fresnel_clearance[1:-1]\n",
    "                min_clear = np.min(interior_clearance)\n",
    "                # Count points that are clear\n",
    "                clear_points = np.sum(interior_clearance >= 0)\n",
    "                total_points = len(interior_clearance)\n",
    "                pct_clear = 100.0 * clear_points / total_points if total_points > 0 else 100.0\n",
    "            else:\n",
    "                min_clear = 0.0\n",
    "                pct_clear = 100.0\n",
    "            \n",
    "            return min_clear, pct_clear\n",
    "\n",
    "        min_clear, pct_clear = -np.inf, 0.0\n",
    "        if len(profile) >= 2 and not np.all(np.isnan(profile)):\n",
    "            min_clear, pct_clear = fresnel_clearance_percent(\n",
    "                profile, tx_h, rx_h, dist_m, freq_mhz, clearance_ratio=0.6\n",
    "            )\n",
    "\n",
    "        # --- Path loss (calls your own function above, so stays in sync)\n",
    "        pl = calculate_path_loss_pycraf(\n",
    "            p1, p2, dem_manager,\n",
    "            tx_h, rx_h, freq_mhz,\n",
    "            veg_threshold, attn_per_meter,\n",
    "            max_comm_range\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'path_loss': pl,\n",
    "            'min_clearance': min_clear,\n",
    "            'percent_clear': pct_clear\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Path analysis failed for {p1} -> {p2}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            'path_loss': np.inf,\n",
    "            'min_clearance': -np.inf,\n",
    "            'percent_clear': 0.0\n",
    "        }\n",
    "\n",
    "import pyproj\n",
    "from shapely.ops import transform as shapely_transform\n",
    "from shapely.geometry import mapping, Point\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def find_chm_dataset_for_aoi(aoi_poly):\n",
    "    \"\"\"Find which CHM dataset (Eaton or Palisades) best covers the AOI - FIXED VERSION\"\"\"\n",
    "    import rasterio\n",
    "    from rasterio.warp import transform_bounds\n",
    "    from shapely.geometry import box\n",
    "    \n",
    "    eaton_files = {\n",
    "        'chm': 'EatonCHM.tif',\n",
    "        'dsm': 'Eatonoutput.dsm.tif', \n",
    "        'dtm': 'Eatonoutput.dtm.tif'\n",
    "    }\n",
    "    \n",
    "    palisades_files = {\n",
    "        'chm': 'palisadesCHM.tif',\n",
    "        'dsm': 'palisadesoutput.dsm.tif',\n",
    "        'dtm': 'palisadesoutput.dtm.tif'\n",
    "    }\n",
    "    \n",
    "    eaton_exists = all(os.path.exists(f) for f in eaton_files.values())\n",
    "    palisades_exists = all(os.path.exists(f) for f in palisades_files.values())\n",
    "    \n",
    "    print(f\"Eaton files available: {eaton_exists}\")\n",
    "    print(f\"Palisades files available: {palisades_exists}\")\n",
    "    \n",
    "    if not eaton_exists and not palisades_exists:\n",
    "        print(\"No CHM datasets found!\")\n",
    "        return None, None\n",
    "    \n",
    "    if aoi_poly is None:\n",
    "        # No AOI provided, return first available dataset\n",
    "        if eaton_exists:\n",
    "            return \"Eaton\", eaton_files\n",
    "        else:\n",
    "            return \"Palisades\", palisades_files\n",
    "    \n",
    "    # AOI provided - ACTUALLY CHECK COVERAGE (this was missing!)\n",
    "    centroid = aoi_poly.centroid\n",
    "    aoi_bounds = aoi_poly.bounds\n",
    "    print(f\"AOI center: {centroid.x:.4f}, {centroid.y:.4f}\")\n",
    "    \n",
    "    coverage_results = {}\n",
    "    \n",
    "    # Check Eaton coverage if files exist\n",
    "    if eaton_exists:\n",
    "        try:\n",
    "            with rasterio.open(eaton_files['chm']) as src:\n",
    "                chm_bounds_4326 = transform_bounds(src.crs, 'EPSG:4326', *src.bounds)\n",
    "                chm_minx, chm_miny, chm_maxx, chm_maxy = chm_bounds_4326\n",
    "                aoi_minx, aoi_miny, aoi_maxx, aoi_maxy = aoi_bounds\n",
    "                \n",
    "                # Check for overlap\n",
    "                overlap_x = not (aoi_maxx < chm_minx or aoi_minx > chm_maxx)\n",
    "                overlap_y = not (aoi_maxy < chm_miny or aoi_miny > chm_maxy)\n",
    "                has_overlap = overlap_x and overlap_y\n",
    "                \n",
    "                if has_overlap:\n",
    "                    overlap_minx = max(aoi_minx, chm_minx)\n",
    "                    overlap_miny = max(aoi_miny, chm_miny)\n",
    "                    overlap_maxx = min(aoi_maxx, chm_maxx)\n",
    "                    overlap_maxy = min(aoi_maxy, chm_maxy)\n",
    "                    overlap_poly = box(overlap_minx, overlap_miny, overlap_maxx, overlap_maxy)\n",
    "                    overlap_percent = (overlap_poly.area / aoi_poly.area) * 100\n",
    "                else:\n",
    "                    overlap_percent = 0\n",
    "                \n",
    "                coverage_results['Eaton'] = {\n",
    "                    'files': eaton_files,\n",
    "                    'coverage': overlap_percent,\n",
    "                    'has_overlap': has_overlap\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Error checking Eaton coverage: {e}\")\n",
    "            coverage_results['Eaton'] = {'files': eaton_files, 'coverage': 0, 'has_overlap': False}\n",
    "    \n",
    "    # Check Palisades coverage if files exist\n",
    "    if palisades_exists:\n",
    "        try:\n",
    "            with rasterio.open(palisades_files['chm']) as src:\n",
    "                chm_bounds_4326 = transform_bounds(src.crs, 'EPSG:4326', *src.bounds)\n",
    "                chm_minx, chm_miny, chm_maxx, chm_maxy = chm_bounds_4326\n",
    "                aoi_minx, aoi_miny, aoi_maxx, aoi_maxy = aoi_bounds\n",
    "                \n",
    "                # Check for overlap\n",
    "                overlap_x = not (aoi_maxx < chm_minx or aoi_minx > chm_maxx)\n",
    "                overlap_y = not (aoi_maxy < chm_miny or aoi_miny > chm_maxy)\n",
    "                has_overlap = overlap_x and overlap_y\n",
    "                \n",
    "                if has_overlap:\n",
    "                    overlap_minx = max(aoi_minx, chm_minx)\n",
    "                    overlap_miny = max(aoi_miny, chm_miny)\n",
    "                    overlap_maxx = min(aoi_maxx, chm_maxx)\n",
    "                    overlap_maxy = min(aoi_maxy, chm_maxy)\n",
    "                    overlap_poly = box(overlap_minx, overlap_miny, overlap_maxx, overlap_maxy)\n",
    "                    overlap_percent = (overlap_poly.area / aoi_poly.area) * 100\n",
    "                else:\n",
    "                    overlap_percent = 0\n",
    "                \n",
    "                coverage_results['Palisades'] = {\n",
    "                    'files': palisades_files,\n",
    "                    'coverage': overlap_percent,\n",
    "                    'has_overlap': has_overlap\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Error checking Palisades coverage: {e}\")\n",
    "            coverage_results['Palisades'] = {'files': palisades_files, 'coverage': 0, 'has_overlap': False}\n",
    "    \n",
    "    # Select the dataset with the best coverage\n",
    "    best_dataset = None\n",
    "    best_coverage = 0\n",
    "    best_files = None\n",
    "    \n",
    "    for dataset_name, result in coverage_results.items():\n",
    "        if result['has_overlap'] and result['coverage'] > best_coverage:\n",
    "            best_coverage = result['coverage']\n",
    "            best_dataset = dataset_name\n",
    "            best_files = result['files']\n",
    "    \n",
    "    if best_dataset:\n",
    "        print(f\"Selected {best_dataset} dataset ({best_coverage:.1f}% coverage)\")\n",
    "        return best_dataset, best_files\n",
    "    else:\n",
    "        # No overlap found, return None to avoid the error\n",
    "        print(\" No datasets overlap with AOI!\")\n",
    "        return None, None\n",
    "\n",
    "def process_opentopo_chm_for_wsn(aoi_poly, dem_manager):\n",
    "    \"\"\"Process OpenTopography CHM data and integrate with DEMManager for WSN analysis\"\"\"\n",
    "    print(\"🔄 Processing OpenTopography CHM data for WSN analysis...\")\n",
    "    \n",
    "    dataset_name, dataset_files = find_chm_dataset_for_aoi(aoi_poly)\n",
    "    \n",
    "    if dataset_files is None:\n",
    "        print(\"No CHM datasets available!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📂 Using {dataset_name} dataset\")\n",
    "    \n",
    "    try:\n",
    "        chm_file = dataset_files['chm']\n",
    "        dsm_file = dataset_files['dsm'] \n",
    "        \n",
    "        print(f\"Loading CHM: {chm_file}\")\n",
    "        print(f\"Loading DSM: {dsm_file}\")\n",
    "        \n",
    "        # Load and Mask CHM to AOI\n",
    "        with rasterio.open(chm_file) as chm_src:\n",
    "            chm_crs = chm_src.crs\n",
    "            print(f\"CHM CRS: {chm_crs}\")\n",
    "            print(f\"CHM resolution: {abs(chm_src.transform.a):.2f}m\")\n",
    "            \n",
    "            if aoi_poly is not None:\n",
    "                print(\"Masking CHM to AOI bounds...\")\n",
    "                aoi_proj = reproject_aoi_to_raster(aoi_poly, chm_crs)\n",
    "                chm_out, chm_transform = mask(chm_src, [mapping(aoi_proj)], crop=True)\n",
    "                chm_data = chm_out[0]\n",
    "                nodata = chm_src.nodata if chm_src.nodata is not None else -999999.0\n",
    "                print(\" Masked CHM to AOI bounds.\")\n",
    "                print(f\"   Cropped CHM shape: {chm_data.shape}\")\n",
    "            else:\n",
    "                chm_data = chm_src.read(1)\n",
    "                chm_transform = chm_src.transform\n",
    "                nodata = chm_src.nodata if chm_src.nodata is not None else -999999.0\n",
    "        \n",
    "        # Load and Mask DSM to AOI\n",
    "        with rasterio.open(dsm_file) as dsm_src:\n",
    "            if aoi_poly is not None:\n",
    "                aoi_proj = reproject_aoi_to_raster(aoi_poly, dsm_src.crs)\n",
    "                dsm_out, dsm_transform = mask(dsm_src, [mapping(aoi_proj)], crop=True)\n",
    "                dsm_data = dsm_out[0]\n",
    "                print(f\"   Cropped DSM shape: {dsm_data.shape}\")\n",
    "            else:\n",
    "                dsm_data = dsm_src.read(1)\n",
    "                dsm_transform = dsm_src.transform\n",
    "        \n",
    "        # Clean up nodata values\n",
    "        chm_masked = np.where((chm_data == nodata) | (chm_data < -1000), np.nan, chm_data)\n",
    "        dsm_masked = np.where((dsm_data == nodata) | (dsm_data < -1000), np.nan, dsm_data)\n",
    "        \n",
    "        print(f\"🌲 CHM range: {np.nanmin(chm_masked):.1f} to {np.nanmax(chm_masked):.1f} m\")\n",
    "        print(f\"📡 DSM range: {np.nanmin(dsm_masked):.1f} to {np.nanmax(dsm_masked):.1f} m\")\n",
    "        \n",
    "        # Compute Slope and Aspect from DSM\n",
    "        print(\"🗻 Computing slope and aspect from DSM...\")\n",
    "        dy, dx = abs(dsm_transform.e), abs(dsm_transform.a)\n",
    "        gy, gx = np.gradient(dsm_masked.astype(float), dy, dx)\n",
    "        slope = np.degrees(np.arctan(np.sqrt(gx**2 + gy**2)))\n",
    "        aspect = np.degrees(np.arctan2(-gx, gy))\n",
    "        aspect[aspect < 0] += 360\n",
    "        \n",
    "        # Update DEMManager with processed data\n",
    "        print(\"🔄 Updating DEMManager with OpenTopography CHM data...\")\n",
    "        dem_manager.set_dsm(dsm_masked, dsm_transform)\n",
    "        dem_manager.set_chm(chm_masked, chm_transform)\n",
    "        dem_manager.chm_crs = chm_crs   \n",
    "        \n",
    "        if not hasattr(dem_manager, 'lidar_slope'):\n",
    "            dem_manager.lidar_slope = slope\n",
    "            dem_manager.lidar_aspect = aspect\n",
    "            dem_manager.lidar_transform = dsm_transform\n",
    "        \n",
    "        dem_manager.chm_dataset = dataset_name\n",
    "        dem_manager.chm_files = dataset_files\n",
    "        \n",
    "        print(\"✅ OpenTopography CHM processing complete!\")\n",
    "        \n",
    "        return {\n",
    "            'dataset_name': dataset_name,\n",
    "            'dsm': dsm_masked,\n",
    "            'chm': chm_masked,\n",
    "            'transform': dsm_transform,\n",
    "            'crs': chm_crs,\n",
    "            'nodata': nodata,\n",
    "            'files': dataset_files\n",
    "        }\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ ERROR: CHM file not found: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR processing OpenTopography CHM: {type(e).__name__}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def integrate_opentopo_chm():\n",
    "    \"\"\"Main integration function - call this after AOI selection\"\"\"\n",
    "    global aoi_poly, dem_manager\n",
    "    \n",
    "    if aoi_poly is not None and dem_manager is not None:\n",
    "        print(\"🚀 Starting OpenTopography CHM integration...\")\n",
    "        chm_results = process_opentopo_chm_for_wsn(aoi_poly, dem_manager)\n",
    "        \n",
    "        if chm_results is not None:\n",
    "            print(\"✅ OpenTopography CHM integration complete!\")\n",
    "            print(f\"   📂 Dataset: {chm_results['dataset_name']}\")\n",
    "            print(f\"   🌲 CHM loaded with vegetation data\")\n",
    "            return chm_results\n",
    "        else:\n",
    "            print(\"CHM processing failed\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\" AOI or DEMManager not loaded. Please run AOI selection first.\")\n",
    "        return None\n",
    "\n",
    "def check_chm_coverage_for_aoi(aoi_poly):\n",
    "    \"\"\"\n",
    "    Check if AOI overlaps with available CHM datasets and show coverage info\n",
    "    \"\"\"\n",
    "    print(\" Checking CHM coverage for your AOI...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if aoi_poly is None:\n",
    "        print(\" No AOI selected yet!\")\n",
    "        return\n",
    "    \n",
    "    # Get AOI bounds\n",
    "    aoi_bounds = aoi_poly.bounds\n",
    "    aoi_minx, aoi_miny, aoi_maxx, aoi_maxy = aoi_bounds\n",
    "    \n",
    "    print(f\"📍 Your AOI bounds:\")\n",
    "    print(f\"   West: {aoi_minx:.6f}, East: {aoi_maxx:.6f}\")\n",
    "    print(f\"   South: {aoi_miny:.6f}, North: {aoi_maxy:.6f}\")\n",
    "    print(f\"   Center: {aoi_poly.centroid.x:.6f}, {aoi_poly.centroid.y:.6f}\")\n",
    "    \n",
    "    # Check available CHM files\n",
    "    chm_files = {\n",
    "        'Eaton': {\n",
    "            'chm': 'EatonCHM.tif',\n",
    "            'dsm': 'Eatonoutput.dsm.tif'\n",
    "        },\n",
    "        'Palisades': {\n",
    "            'chm': 'palisadesCHM.tif', \n",
    "            'dsm': 'palisadesoutput.dsm.tif'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    coverage_results = {}\n",
    "    \n",
    "    for dataset_name, files in chm_files.items():\n",
    "        chm_file = files['chm']\n",
    "        \n",
    "        if not os.path.exists(chm_file):\n",
    "            print(f\"\\n{dataset_name} CHM file not found: {chm_file}\")\n",
    "            coverage_results[dataset_name] = {'available': False, 'overlap': False}\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Read CHM file bounds\n",
    "            with rasterio.open(chm_file) as src:\n",
    "                chm_bounds = src.bounds\n",
    "                chm_crs = src.crs\n",
    "    \n",
    "                # Reproject CHM bounds from its CRS to EPSG:4326 (lat/lon)\n",
    "                from rasterio.warp import transform_bounds\n",
    "                chm_bounds_4326 = transform_bounds(chm_crs, 'EPSG:4326', *chm_bounds)\n",
    "                chm_minx, chm_miny, chm_maxx, chm_maxy = chm_bounds_4326\n",
    "                \n",
    "                print(f\"\\n📂 {dataset_name} CHM bounds:\")\n",
    "                print(f\"   West: {chm_minx:.6f}, East: {chm_maxx:.6f}\")\n",
    "                print(f\"   South: {chm_miny:.6f}, North: {chm_maxy:.6f}\")\n",
    "                print(f\"   Resolution: {abs(src.transform.a):.2f}m\")\n",
    "                print(f\"   Size: {src.width} x {src.height} pixels\")\n",
    "                \n",
    "                # Check for overlap\n",
    "                overlap_x = not (aoi_maxx < chm_minx or aoi_minx > chm_maxx)\n",
    "                overlap_y = not (aoi_maxy < chm_miny or aoi_miny > chm_maxy)\n",
    "                has_overlap = overlap_x and overlap_y\n",
    "                \n",
    "                if has_overlap:\n",
    "                    # Calculate overlap area\n",
    "                    overlap_minx = max(aoi_minx, chm_minx)\n",
    "                    overlap_miny = max(aoi_miny, chm_miny)\n",
    "                    overlap_maxx = min(aoi_maxx, chm_maxx)\n",
    "                    overlap_maxy = min(aoi_maxy, chm_maxy)\n",
    "                    \n",
    "                    from shapely.geometry import box\n",
    "                    overlap_poly = box(overlap_minx, overlap_miny, overlap_maxx, overlap_maxy)\n",
    "                    overlap_area = overlap_poly.area\n",
    "                    aoi_area = aoi_poly.area\n",
    "                    overlap_percent = (overlap_area / aoi_area) * 100\n",
    "                    \n",
    "                    print(f\"   OVERLAP FOUND!\")\n",
    "                    print(f\"   Coverage: {overlap_percent:.1f}% of your AOI\")\n",
    "                    \n",
    "                    if overlap_percent > 90:\n",
    "                        print(f\"   Excellent coverage - this dataset covers almost your entire AOI\")\n",
    "                    elif overlap_percent > 50:\n",
    "                        print(f\"   Good coverage - this dataset covers most of your AOI\")\n",
    "                    else:\n",
    "                        print(f\"   Partial coverage - only part of your AOI is covered\")\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"    NO OVERLAP - This dataset doesn't cover your AOI\")\n",
    "                \n",
    "                coverage_results[dataset_name] = {\n",
    "                    'available': True,\n",
    "                    'overlap': has_overlap,\n",
    "                    'coverage_percent': overlap_percent if has_overlap else 0,\n",
    "                    'bounds': chm_bounds\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Error reading {dataset_name} CHM file: {e}\")\n",
    "            coverage_results[dataset_name] = {'available': False, 'overlap': False}\n",
    "    \n",
    "    # Summary and recommendations\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SUMMARY & RECOMMENDATIONS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    best_dataset = None\n",
    "    best_coverage = 0\n",
    "    \n",
    "    for dataset_name, result in coverage_results.items():\n",
    "        if result.get('overlap', False):\n",
    "            coverage = result.get('coverage_percent', 0)\n",
    "            if coverage > best_coverage:\n",
    "                best_coverage = coverage\n",
    "                best_dataset = dataset_name\n",
    "    \n",
    "    if best_dataset:\n",
    "        print(f\"RECOMMENDED: Use {best_dataset} dataset ({best_coverage:.1f}% coverage)\")\n",
    "        print(f\" Your AOI will have vegetation data from OpenTopography CHM\")\n",
    "    else:\n",
    "        print(\"WARNING: No CHM datasets cover your AOI area!\")\n",
    "        print(\"Suggestions:\")\n",
    "        print(\"   • Try selecting an AOI in the Eaton Canyon or Palisades area\")\n",
    "        print(\"   • Check if your CHM files are in the correct location\")\n",
    "        print(\"   • Your WSN analysis will work but without vegetation data\")\n",
    "    \n",
    "    return coverage_results\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import transform_bounds\n",
    "from ipyleaflet import Map, Rectangle, basemaps\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "\n",
    "def visualize_chm_coverage():\n",
    "    \"\"\"Show the coverage areas of both Palisades and Eaton DSM datasets\"\"\"\n",
    "    \n",
    "    # Dataset files\n",
    "    datasets = {\n",
    "        'Palisades': {\n",
    "            'dsm': 'palisadesoutput.dsm.tif',\n",
    "            'chm': 'palisadesCHM.tif',\n",
    "            'color': 'red'\n",
    "        },\n",
    "        'Eaton': {\n",
    "            'dsm': 'Eatonoutput.dsm.tif', \n",
    "            'chm': 'EatonCHM.tif',\n",
    "            'color': 'blue'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    coverage_info = {}\n",
    "    all_bounds = []\n",
    "    \n",
    "    print(\"CHM/DSM DATASET COVERAGE AREAS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check each dataset\n",
    "    for dataset_name, files in datasets.items():\n",
    "        dsm_file = files['dsm']\n",
    "        \n",
    "        if not os.path.exists(dsm_file):\n",
    "            print(f\"{dataset_name} DSM file not found: {dsm_file}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Read DSM bounds\n",
    "            with rasterio.open(dsm_file) as src:\n",
    "                # Get bounds in the original CRS\n",
    "                bounds_orig = src.bounds\n",
    "                crs_orig = src.crs\n",
    "                \n",
    "                # Transform bounds to lat/lon (EPSG:4326) for mapping\n",
    "                bounds_4326 = transform_bounds(crs_orig, 'EPSG:4326', *bounds_orig)\n",
    "                west, south, east, north = bounds_4326\n",
    "                \n",
    "                coverage_info[dataset_name] = {\n",
    "                    'bounds': bounds_4326,\n",
    "                    'crs': crs_orig,\n",
    "                    'resolution': abs(src.transform.a),\n",
    "                    'size': (src.width, src.height),\n",
    "                    'color': files['color']\n",
    "                }\n",
    "                all_bounds.append(bounds_4326)\n",
    "                \n",
    "                print(f\"\\n{dataset_name.upper()} DATASET:\")\n",
    "                print(f\"   File: {dsm_file}\")\n",
    "                print(f\"   CRS: {crs_orig}\")\n",
    "                print(f\"   Resolution: {abs(src.transform.a):.2f}m\")\n",
    "                print(f\"   Size: {src.width} x {src.height} pixels\")\n",
    "                print(f\"   Bounds: W:{west:.6f}, E:{east:.6f}, S:{south:.6f}, N:{north:.6f}\")\n",
    "                print(f\"   Center: {(west+east)/2:.6f}, {(south+north)/2:.6f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {dataset_name} DSM: {e}\")\n",
    "    \n",
    "    if not coverage_info:\n",
    "        print(\"No datasets found!\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate map center from all datasets\n",
    "    if all_bounds:\n",
    "        all_west = min(b[0] for b in all_bounds)\n",
    "        all_east = max(b[2] for b in all_bounds)\n",
    "        all_south = min(b[1] for b in all_bounds)\n",
    "        all_north = max(b[3] for b in all_bounds)\n",
    "        \n",
    "        center_lat = (all_south + all_north) / 2\n",
    "        center_lon = (all_west + all_east) / 2\n",
    "    else:\n",
    "        center_lat, center_lon = 34.15, -118.1  # Default LA area\n",
    "    \n",
    "    # Create map\n",
    "    m = Map(\n",
    "        center=[center_lat, center_lon], \n",
    "        zoom=11,  # Zoom out a bit to see both areas\n",
    "        basemap=basemaps.Esri.WorldImagery\n",
    "    )\n",
    "    \n",
    "    # Add rectangles for each dataset\n",
    "    for dataset_name, info in coverage_info.items():\n",
    "        west, south, east, north = info['bounds']\n",
    "        \n",
    "        coverage_rect = Rectangle(\n",
    "            bounds=[[south, west], [north, east]],\n",
    "            color=info['color'],\n",
    "            fill_color=info['color'],\n",
    "            fill_opacity=0.2,\n",
    "            weight=3\n",
    "        )\n",
    "        m.add_layer(coverage_rect)\n",
    "    \n",
    "    print(f\"\\nMAP LEGEND:\")\n",
    "    print(\"=\" * 20)\n",
    "    for dataset_name, info in coverage_info.items():\n",
    "        print(f\"🟦 {info['color'].upper()} = {dataset_name} coverage area\")\n",
    "    \n",
    "    print(f\"\\n👉 USAGE TIPS:\")\n",
    "    print(\"• Select your AOI INSIDE one of the colored rectangles\")\n",
    "    print(\"• Red (Palisades) covers western areas\")  \n",
    "    print(\"• Blue (Eaton) covers eastern areas\")\n",
    "    print(\"• Choose the dataset that best covers your area of interest\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Run the visualization\n",
    "chm_coverage_map = visualize_chm_coverage()\n",
    "if chm_coverage_map:\n",
    "    display(chm_coverage_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9faaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ===== AOI SELECTION INTERFACE (USABILITY) =====\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def fix_aoi_bounds(aoi_poly, dem_manager):\n",
    "    aoi_bounds, dem_bounds = aoi_poly.bounds, dem_manager.bounds\n",
    "    if (aoi_bounds[0] < dem_bounds[0] or aoi_bounds[1] < dem_bounds[1] or \n",
    "        aoi_bounds[2] > dem_bounds[2] or aoi_bounds[3] > dem_bounds[3]):\n",
    "        safe_bounds = (\n",
    "            max(aoi_bounds[0], dem_bounds[0] + 0.0001),\n",
    "            max(aoi_bounds[1], dem_bounds[1] + 0.0001),\n",
    "            min(aoi_bounds[2], dem_bounds[2] - 0.0001),\n",
    "            min(aoi_bounds[3], dem_bounds[3] - 0.0001)\n",
    "        )\n",
    "        trimmed_poly = box(*safe_bounds)\n",
    "        print(f\"   Area lost: {100 * (aoi_poly.area - trimmed_poly.area) / aoi_poly.area:.2f}%\")\n",
    "        return trimmed_poly\n",
    "    return aoi_poly\n",
    "\n",
    "def create_aoi_selection_interface(center: Tuple[float, float] = (34.2, -118.16)):\n",
    "    global drawn_geometry, aoi_poly, dem_manager, gateway_candidate_df\n",
    "    m = Map(center=center, zoom=13, basemap=basemaps.Esri.WorldImagery)\n",
    "    draw_control = DrawControl(\n",
    "        circle={'shapeOptions': {'color': '#6bc2e5', 'weight': 3}},\n",
    "        rectangle={'shapeOptions': {'color': '#fca45d', 'weight': 3}},\n",
    "        polygon={'shapeOptions': {'color': '#4bc44b', 'weight': 3}}\n",
    "    )\n",
    "    output = Output()\n",
    "\n",
    "    def handle_draw(self, action, geo_json):\n",
    "        output.clear_output()\n",
    "        global drawn_geometry\n",
    "        with output:\n",
    "            print(f\"✓ Shape drawn: {action}\")\n",
    "            print(f\"  Type: {geo_json['geometry']['type']}\")\n",
    "            drawn_geometry = geo_json\n",
    "\n",
    "    draw_control.on_draw(handle_draw)\n",
    "    m.add_control(draw_control)\n",
    "\n",
    "    btn = Button(description='Complete Selection', button_style='success')\n",
    "    ui = VBox([m, btn, output])\n",
    "\n",
    "    def on_complete_clicked(b):\n",
    "        global aoi_poly, dem_manager, drawn_geometry\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"=\" * 50)\n",
    "            print(\"PROCESSING AOI SELECTION\")\n",
    "            print(\"=\" * 50)\n",
    "            if not drawn_geometry:\n",
    "                print(\"ERROR: No area selected. Please draw a shape on the map.\")\n",
    "                return\n",
    "            try:\n",
    "                aoi_poly = shape(drawn_geometry['geometry'])\n",
    "                bounds = aoi_poly.bounds\n",
    "                print(f\"✓ AOI bounds: {bounds}\")\n",
    "                minx, miny, maxx, maxy = bounds\n",
    "                api_key = os.environ.get('OPENTOPO_API_KEY', None)\n",
    "                url = \"https://portal.opentopography.org/API/globaldem\"\n",
    "                params = {\n",
    "                    \"demtype\": \"SRTMGL1\", \"south\": miny, \"north\": maxy, \"west\": minx, \"east\": maxx,\n",
    "                    \"outputFormat\": \"GTiff\", \"API_Key\": api_key\n",
    "                }\n",
    "                print(\"\\n📡 Requesting DEM data from OpenTopography...\")\n",
    "                response = requests.get(url, params=params, timeout=30)\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"✓ DEM data received: {len(response.content) / 1024:.1f} KB\")\n",
    "                    dem_manager = DEMManager(response.content)\n",
    "                    # ---- EXTENDED DEBUGGING ----\n",
    "                    print(\"\\n--- DEM Debug Info ---\")\n",
    "                    print(\"DEM CRS:\", dem_manager.crs)\n",
    "                    print(\"DEM transform:\", dem_manager.transform)\n",
    "                    print(\"DEM bounds:\", dem_manager.bounds)\n",
    "                    print(\"DEM shape:\", dem_manager.shape)\n",
    "                    pixel_width = abs(dem_manager.transform.a)\n",
    "                    pixel_height = abs(dem_manager.transform.e)\n",
    "                    print(f\"DEM pixel width: {pixel_width}, pixel height: {pixel_height}\")\n",
    "                    print(f\"DEM min/max/mean elevation: {np.min(dem_manager.dem_array):.2f} / {np.max(dem_manager.dem_array):.2f} / {np.mean(dem_manager.dem_array):.2f}\")\n",
    "\n",
    "                    dem_manager.calculate_slope_and_aspect()\n",
    "                    if dem_manager.slope_arr is not None and np.isfinite(dem_manager.slope_arr).any():\n",
    "                        print(\"Slope array min/max/mean:\", \n",
    "                            np.nanmin(dem_manager.slope_arr),\n",
    "                            np.nanmax(dem_manager.slope_arr),\n",
    "                            np.nanmean(dem_manager.slope_arr))\n",
    "                    else:\n",
    "                        print(\"Slope array is empty or contains only NaN values.\")\n",
    "                    print(\"--- End DEM Debug ---\\n\")\n",
    "                    aoi_poly = fix_aoi_bounds(aoi_poly, dem_manager)\n",
    "                    check_chm_coverage_for_aoi(aoi_poly)\n",
    "                    chm_results = integrate_opentopo_chm()\n",
    "                else:\n",
    "                    print(f\"ERROR: DEM request failed (HTTP {response.status_code})\")\n",
    "                    print(f\"  Response: {response.text[:200]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: {type(e).__name__}: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                print(\"👉 AOI and DEM loaded. Please run the next cell ('Gateway Candidate Precomputation').\")\n",
    "                check_chm_coverage_for_aoi(aoi_poly)\n",
    "                chm_results = integrate_opentopo_chm()\n",
    "        \n",
    "\n",
    "\n",
    "    btn.on_click(on_complete_clicked)\n",
    "    return ui\n",
    "\n",
    "aoi_interface = create_aoi_selection_interface()\n",
    "display(aoi_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79ac1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# POSTER-READY CHM/DSM VISUALIZATION (bigger maps + larger labels)\n",
    "# =================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Polygon as MPLPolygon\n",
    "from matplotlib.ticker import ScalarFormatter, FuncFormatter, MaxNLocator\n",
    "import numpy as np\n",
    "\n",
    "# ---- Poster font sizes ----\n",
    "TITLE_FSIZE    = 20   # subplot titles\n",
    "AXIS_FSIZE     = 24   # x/y axis labels\n",
    "TICK_FSIZE     = 20   # tick label size\n",
    "CBAR_FSIZE     = 22   # colorbar label size\n",
    "SUPTITLE_FSIZE = 35   # big title at the top\n",
    "CAPTION_FSIZE  = 15   # fig.text boxes, legends, etc.\n",
    "\n",
    "# ---- Axis formatting helpers (poster-friendly) ----\n",
    "# Kill scientific/offset notation globally\n",
    "mpl.rcParams['axes.formatter.useoffset'] = False\n",
    "mpl.rcParams['axes.formatter.limits'] = (-7, 7)\n",
    "\n",
    "# Thousands separator for big UTM coordinates\n",
    "_thousands_fmt = FuncFormatter(lambda x, pos: f\"{x:,.0f}\")\n",
    "\n",
    "def apply_poster_axis_format(ax, nbins=6, use_thousands=True, equal_aspect=True, tick_size=None):\n",
    "    \"\"\"Clean, poster-friendly axes.\"\"\"\n",
    "    ax.ticklabel_format(axis='both', style='plain', useOffset=False)\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    if use_thousands:\n",
    "        ax.xaxis.set_major_formatter(_thousands_fmt)\n",
    "        ax.yaxis.set_major_formatter(_thousands_fmt)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(nbins=nbins))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=nbins))\n",
    "    if tick_size is not None:\n",
    "        ax.tick_params(axis='both', labelsize=tick_size)\n",
    "    if equal_aspect:\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# =================================================================\n",
    "# CHM VISUALIZATION - Shows your AOI with vegetation height data\n",
    "# =================================================================\n",
    "def visualize_chm_over_aoi():\n",
    "    \"\"\"\n",
    "    Create a visualization showing CHM (vegetation height) data over your AOI\n",
    "    \"\"\"\n",
    "    global aoi_poly, dem_manager\n",
    "    \n",
    "    if aoi_poly is None or dem_manager is None:\n",
    "        print(\"No AOI or DEM data loaded. Please run AOI selection first.\")\n",
    "        return\n",
    "        \n",
    "    if not hasattr(dem_manager, 'chm_array') or dem_manager.chm_array is None:\n",
    "        print(\"No CHM data loaded. Please run CHM integration first.\")\n",
    "        return\n",
    "    \n",
    "    print(\"🎨 Creating CHM visualization...\")\n",
    "    \n",
    "    # Get the data\n",
    "    chm_data = dem_manager.chm_array\n",
    "    chm_transform = dem_manager.chm_transform\n",
    "    dsm_data = dem_manager.dsm_array if dem_manager.dsm_array is not None else dem_manager.dem_array\n",
    "    \n",
    "    # Create figure with subplots (bigger for poster)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(22, 12))  # <— larger maps\n",
    "    \n",
    "    # === LEFT PLOT: CHM (Vegetation Height) ===\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Create extent for plotting (in map coordinates)\n",
    "    height, width = chm_data.shape\n",
    "    west, north = chm_transform * (0, 0)\n",
    "    east, south = chm_transform * (width, height)\n",
    "    extent = [west, east, south, north]\n",
    "    \n",
    "    # Plot CHM with vegetation-appropriate colormap\n",
    "    chm_clean = np.where(np.isnan(chm_data), 0, chm_data)\n",
    "    vegetation_map = ax1.imshow(\n",
    "        chm_clean, \n",
    "        extent=extent, \n",
    "        origin='upper',\n",
    "        cmap='YlGn',\n",
    "        vmin=0, \n",
    "        vmax=np.nanpercentile(chm_clean, 95)\n",
    "    )\n",
    "\n",
    "    # Add AOI boundary\n",
    "    transformed_coords = None\n",
    "    if aoi_poly is not None:\n",
    "        from pyproj import Transformer\n",
    "        transformer = Transformer.from_crs('EPSG:4326', dem_manager.crs if hasattr(dem_manager, 'crs') else 'EPSG:6340', always_xy=True)\n",
    "        aoi_coords = list(aoi_poly.exterior.coords)\n",
    "        transformed_coords = [transformer.transform(lon, lat) for lon, lat in aoi_coords]\n",
    "        aoi_patch = MPLPolygon(transformed_coords, fill=False, edgecolor='red', linewidth=3, alpha=0.8)\n",
    "        ax1.add_patch(aoi_patch)\n",
    "\n",
    "    # Poster axis formatting (fix weird x-axis numbers, add thousands separators)\n",
    "    apply_poster_axis_format(ax1, tick_size=TICK_FSIZE)\n",
    "\n",
    "    ax1.set_title(' Canopy Height Model (CHM)\\nVegetation Height', fontsize=TITLE_FSIZE, fontweight='bold')\n",
    "    ax1.set_xlabel('Easting (m)', fontsize=AXIS_FSIZE)\n",
    "    ax1.set_ylabel('Northing (m)', fontsize=AXIS_FSIZE)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar1 = plt.colorbar(vegetation_map, ax=ax1, shrink=0.8)\n",
    "    cbar1.set_label('Vegetation Height (m)', rotation=270, labelpad=22, fontsize=CBAR_FSIZE)\n",
    "    cbar1.ax.tick_params(labelsize=TICK_FSIZE)\n",
    "    \n",
    "    # === RIGHT PLOT: DSM (Surface Elevation) ===\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    dsm_clean = np.where(np.isnan(dsm_data), np.nanmean(dsm_data), dsm_data)\n",
    "    terrain_map = ax2.imshow(\n",
    "        dsm_clean,\n",
    "        extent=extent,\n",
    "        origin='upper', \n",
    "        cmap='terrain',\n",
    "        vmin=np.nanpercentile(dsm_clean, 5),\n",
    "        vmax=np.nanpercentile(dsm_clean, 95)\n",
    "    )\n",
    "    \n",
    "    if aoi_poly is not None and transformed_coords is not None:\n",
    "        aoi_patch2 = MPLPolygon(transformed_coords, fill=False, edgecolor='red', linewidth=3, alpha=0.8)\n",
    "        ax2.add_patch(aoi_patch2)\n",
    "\n",
    "    # Poster axis formatting\n",
    "    apply_poster_axis_format(ax2, tick_size=TICK_FSIZE)\n",
    "    \n",
    "    ax2.set_title(' Digital Surface Model (DSM)\\nElevation', fontsize=TITLE_FSIZE, fontweight='bold')\n",
    "    ax2.set_xlabel('Easting (m)', fontsize=AXIS_FSIZE)\n",
    "    ax2.set_ylabel('Northing (m)', fontsize=AXIS_FSIZE)\n",
    "    \n",
    "    cbar2 = plt.colorbar(terrain_map, ax=ax2, shrink=0.8)\n",
    "    cbar2.set_label('Elevation (m)', rotation=270, labelpad=22, fontsize=CBAR_FSIZE)\n",
    "    cbar2.ax.tick_params(labelsize=TICK_FSIZE)\n",
    "    \n",
    "    # === Overall title and statistics ===\n",
    "    dataset_name = getattr(dem_manager, 'chm_dataset', 'Unknown')\n",
    "    fig.suptitle(\n",
    "        f'OpenTopography {dataset_name} Dataset - High Resolution Terrain & Vegetation',\n",
    "        fontsize=SUPTITLE_FSIZE, fontweight='bold', y=0.95\n",
    "    )\n",
    "    \n",
    "    stats_text = f\"\"\" DATASET STATISTICS:\n",
    "• Resolution: 0.5m × 0.5m\n",
    "• CHM Range: {np.nanmin(chm_clean):.1f} - {np.nanmax(chm_clean):.1f} m\n",
    "• Mean Vegetation: {np.nanmean(chm_clean[chm_clean > 0.5]):.1f} m  \n",
    "• DSM Range: {np.nanmin(dsm_clean):.1f} - {np.nanmax(dsm_clean):.1f} m\n",
    "• Area: {chm_data.shape[0]} × {chm_data.shape[1]} pixels\"\"\"\n",
    "    \n",
    "    fig.text(0.02, 0.02, stats_text, fontsize=CAPTION_FSIZE,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8),\n",
    "             verticalalignment='bottom')\n",
    "    \n",
    "    fig.text(0.98, 0.02, ' AOI Boundary', fontsize=CAPTION_FSIZE,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "             horizontalalignment='right', verticalalignment='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.15)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"CHM Visualization Complete!\")\n",
    "    print(f\"Your AOI has vegetation ranging from {np.nanmin(chm_clean):.1f}m to {np.nanmax(chm_clean):.1f}m\")\n",
    "    print(f\"Average tree height: {np.nanmean(chm_clean[chm_clean > 0.5]):.1f}m\")\n",
    "    print(f\"Terrain elevation: {np.nanmin(dsm_clean):.1f}m to {np.nanmax(dsm_clean):.1f}m\")\n",
    "\n",
    "\n",
    "def create_vegetation_density_map():\n",
    "    \"\"\"\n",
    "    Create a simplified vegetation density visualization\n",
    "    \"\"\"\n",
    "    global dem_manager, aoi_poly\n",
    "    \n",
    "    if not hasattr(dem_manager, 'chm_array') or dem_manager.chm_array is None:\n",
    "        print(\"No CHM data available for density map\")\n",
    "        return\n",
    "        \n",
    "    print(\"🌳 Creating vegetation density map...\")\n",
    "    \n",
    "    chm_data = dem_manager.chm_array\n",
    "    \n",
    "    # Create vegetation density categories\n",
    "    density_map = np.zeros_like(chm_data)\n",
    "    density_map[chm_data < 1] = 0\n",
    "    density_map[(chm_data >= 1) & (chm_data < 5)] = 1\n",
    "    density_map[(chm_data >= 5) & (chm_data < 15)] = 2\n",
    "    density_map[(chm_data >= 15) & (chm_data < 30)] = 3\n",
    "    density_map[chm_data >= 30] = 4\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))  # slightly bigger\n",
    "    height, width = density_map.shape\n",
    "    west, north = dem_manager.chm_transform * (0, 0)\n",
    "    east, south = dem_manager.chm_transform * (width, height)\n",
    "    extent = [west, east, south, north]\n",
    "    \n",
    "    density_colors = ['lightgray', 'lightgreen', 'green', 'darkgreen', 'forestgreen']\n",
    "    density_cmap = colors.ListedColormap(density_colors)\n",
    "    \n",
    "    im = ax.imshow(density_map, extent=extent, origin='upper', \n",
    "                   cmap=density_cmap, vmin=0, vmax=4)\n",
    "    \n",
    "    # Poster axis formatting\n",
    "    apply_poster_axis_format(ax, tick_size=TICK_FSIZE)\n",
    "    \n",
    "    ax.set_title('Vegetation Density Classification', fontsize=TITLE_FSIZE, fontweight='bold')\n",
    "    ax.set_xlabel('Easting (m)', fontsize=AXIS_FSIZE)\n",
    "    ax.set_ylabel('Northing (m)', fontsize=AXIS_FSIZE)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax, ticks=[0, 1, 2, 3, 4])\n",
    "    cbar.ax.set_yticklabels(['None\\n(0-1m)', 'Low\\n(1-5m)', 'Medium\\n(5-15m)', \n",
    "                             'High\\n(15-30m)', 'Very High\\n(30m+)'])\n",
    "    cbar.set_label('Vegetation Density', rotation=270, labelpad=22, fontsize=CBAR_FSIZE)\n",
    "    cbar.ax.tick_params(labelsize=TICK_FSIZE)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics\n",
    "    total_pixels = density_map.size\n",
    "    for i, category in enumerate(['None', 'Low', 'Medium', 'High', 'Very High']):\n",
    "        count = np.sum(density_map == i)\n",
    "        percentage = (count / total_pixels) * 100\n",
    "        print(f\"🌿 {category:10}: {percentage:5.1f}% ({count:,} pixels)\")\n",
    "\n",
    "# =================================================================\n",
    "# RUN THE VISUALIZATIONS\n",
    "# =================================================================\n",
    "print(\"Creating CHM visualizations for your AOI...\")\n",
    "print(\"=\" * 60)\n",
    "visualize_chm_over_aoi()\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "create_vegetation_density_map()\n",
    "print(\"\\nAll visualizations complete!\")\n",
    "print(\"The red boundary shows your AOI, with high-resolution vegetation data from OpenTopography\")\n",
    "print(\"Left plot: Vegetation height (CHM) | 🗻 Right plot: Surface elevation (DSM)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db44d4-8f5c-4de6-ba2c-aefca972dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8164fc-99a0-4b76-bc3f-4172363f5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# cell.4.GATEWAY PRECOMPUTATION - WITH PARALLEL TQDM PROGRESS BAR (NO OVERRUN)\n",
    "# =================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "# ==== Precomputed artifacts written by Cell 4 and reused by Phase 1 ====\n",
    "if 'PRECOMP_COVERAGE_GRID' not in globals(): PRECOMP_COVERAGE_GRID = None\n",
    "if 'PRECOMP_COVERAGE_MASKS' not in globals(): PRECOMP_COVERAGE_MASKS = None\n",
    "if 'PRECOMP_PAIRWISE_DIST' not in globals(): PRECOMP_PAIRWISE_DIST = None\n",
    "\n",
    "\n",
    "# --- Helper functions ---\n",
    "def build_pairwise_dist_matrix(df_or_coords) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Accepts either:\n",
    "      • a DataFrame with a 'coord' column of (lon, lat) tuples, or\n",
    "      • an iterable of (lon, lat) tuples.\n",
    "    Returns an NxN matrix of geodesic distances in meters.\n",
    "    \"\"\"\n",
    "    if isinstance(df_or_coords, pd.DataFrame):\n",
    "        coords = df_or_coords['coord'].tolist()\n",
    "    else:\n",
    "        coords = list(df_or_coords)\n",
    "\n",
    "    n = len(coords)\n",
    "    D = np.zeros((n, n), dtype=float)\n",
    "    for i in range(n):\n",
    "        lon_i, lat_i = coords[i]\n",
    "        for j in range(i + 1, n):\n",
    "            lon_j, lat_j = coords[j]\n",
    "            d = geodesic((lat_i, lon_i), (lat_j, lon_j)).meters\n",
    "            D[i, j] = D[j, i] = d\n",
    "    return D\n",
    "\n",
    "def coverage_mask_for_candidate(\n",
    "    coord, coverage_grid, dem_manager,\n",
    "    tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter,\n",
    "    max_comm_range, max_path_loss_db, grid_idxs=None\n",
    "):\n",
    "    n = len(coverage_grid)\n",
    "    mask = np.zeros(n, dtype=bool)\n",
    "    idxs = range(n) if grid_idxs is None else grid_idxs\n",
    "    for j in idxs:\n",
    "        p = coverage_grid[j]\n",
    "        try:\n",
    "            # quick range gate\n",
    "            if geodesic(coord[::-1], p[::-1]).meters > max_comm_range:\n",
    "                continue\n",
    "\n",
    "            pl = calculate_path_loss_pycraf(\n",
    "                coord, p, dem_manager,\n",
    "                tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter, max_comm_range\n",
    "            )\n",
    "            if np.isfinite(pl) and pl <= max_path_loss_db:\n",
    "                mask[j] = True\n",
    "        except Exception:\n",
    "            # swallow per-point errors so one bad ray doesn't kill the job\n",
    "            pass\n",
    "    return mask\n",
    "\n",
    "def get_slope_safe(coord, dem_manager):\n",
    "    \"\"\"Get slope at coordinate in degrees\"\"\"\n",
    "    try:\n",
    "        if hasattr(dem_manager, \"get_slope_at_coord\"):\n",
    "            return dem_manager.get_slope_at_coord(coord)\n",
    "        else:\n",
    "            col, row = ~dem_manager.transform * coord\n",
    "            row, col = int(row), int(col)\n",
    "            if (dem_manager.slope_arr is not None and \n",
    "                0 <= row < dem_manager.slope_arr.shape[0] and \n",
    "                0 <= col < dem_manager.slope_arr.shape[1]):\n",
    "                return float(dem_manager.slope_arr[row, col])\n",
    "            else:\n",
    "                return 10.0  # Default moderate slope\n",
    "    except:\n",
    "        return 10.0\n",
    "\n",
    "def get_aspect_safe(coord, dem_manager):\n",
    "    \"\"\"Get aspect (direction of slope) in degrees 0-360\"\"\"\n",
    "    try:\n",
    "        if hasattr(dem_manager, \"get_aspect_at_coord\"):\n",
    "            return dem_manager.get_aspect_at_coord(coord)\n",
    "        # Simple aspect calculation from DEM\n",
    "        col, row = ~dem_manager.transform * coord\n",
    "        row, col = int(row), int(col)\n",
    "        \n",
    "        # Get neighboring elevations for gradient\n",
    "        if hasattr(dem_manager, 'dem_array'):\n",
    "            dem = dem_manager.dem_array\n",
    "            if 1 <= row < dem.shape[0]-1 and 1 <= col < dem.shape[1]-1:\n",
    "                dz_dx = (dem[row, col+1] - dem[row, col-1]) / (2 * dem_manager.resolution)\n",
    "                dz_dy = (dem[row-1, col] - dem[row+1, col]) / (2 * dem_manager.resolution)\n",
    "                aspect = np.degrees(np.arctan2(-dz_dx, dz_dy))\n",
    "                if aspect < 0:\n",
    "                    aspect += 360\n",
    "                return aspect\n",
    "        return 180.0  # Default south-facing\n",
    "    except:\n",
    "        return 180.0\n",
    "\n",
    "def calculate_enhanced_objectives(coord, dem_manager) -> dict:\n",
    "    \"\"\"\n",
    "    Physics-based objective calculations for gateway placement\n",
    "    \"\"\"\n",
    "    try:\n",
    "        elevation = dem_manager.get_elevation(coord)\n",
    "        \n",
    "        # Define elevation bounds for your area - THESE MUST MATCH YOUR ACTUAL TERRAIN\n",
    "        min_elevation = 100.0   # meters\n",
    "        max_elevation = 2800.0  # meters\n",
    "        \n",
    "        # Get slope safely\n",
    "        slope = get_slope_safe(coord, dem_manager)\n",
    "        aspect = get_aspect_safe(coord, dem_manager)\n",
    "        \n",
    "        # 1. ACCESSIBILITY - Fix the calculation\n",
    "        def toblers_hiking_speed(slope_deg):\n",
    "            \"\"\"Returns hiking speed in km/h based on slope\"\"\"\n",
    "            # Avoid extreme tangent values\n",
    "            slope_deg = min(slope_deg, 70.0)  # Cap at 70 degrees\n",
    "            slope_rad = np.radians(slope_deg)\n",
    "            tan_val = np.tan(slope_rad)\n",
    "            speed = 6.0 * np.exp(-3.5 * abs(tan_val + 0.05))\n",
    "            return max(0.5, min(5.0, speed))\n",
    "        \n",
    "        hiking_speed = toblers_hiking_speed(slope)\n",
    "        \n",
    "        # More reasonable elevation penalty\n",
    "        elevation_penalty = max(0.7, 1.0 - (elevation / 10000.0))\n",
    "        \n",
    "        # Seasonal factor\n",
    "        if elevation > 2500:\n",
    "            seasonal_factor = 0.5\n",
    "        elif elevation > 2000:\n",
    "            seasonal_factor = 0.75\n",
    "        else:\n",
    "            seasonal_factor = 1.0\n",
    "            \n",
    "        base_accessibility = hiking_speed / 5.0\n",
    "        accessibility = base_accessibility * elevation_penalty * seasonal_factor\n",
    "        accessibility = max(0.1, min(1.0, accessibility))  # Ensure bounds\n",
    "        \n",
    "        # 2. INSTALLATION COST - Fix normalization\n",
    "        base_cost = 1000.0\n",
    "        \n",
    "        # Drone logistics\n",
    "        drone_trips = 3.0  # Simplified: 3 trips for 80kg equipment\n",
    "        drone_cost_per_trip = 150.0\n",
    "        \n",
    "        if slope < 45:  # Drone accessible\n",
    "            transport_cost = drone_trips * drone_cost_per_trip\n",
    "            weather_factor = 1.0 + min(elevation / 3000.0, 1.0) * 0.5\n",
    "            transport_cost *= weather_factor\n",
    "        else:  # Manual transport\n",
    "            transport_cost = 2000.0  # Fixed high cost for manual\n",
    "            \n",
    "        # Foundation costs\n",
    "        wind_factor = 1.0 + min(elevation / 5000.0, 1.0)\n",
    "        foundation_cost = 2000.0 * (1.0 + min(slope / 30.0, 2.0)) * wind_factor\n",
    "        \n",
    "        total_cost = base_cost + transport_cost + foundation_cost\n",
    "        # Better normalization\n",
    "        min_possible_cost = 1000.0\n",
    "        max_possible_cost = 10000.0\n",
    "        cost_score = 1.0 - ((total_cost - min_possible_cost) / (max_possible_cost - min_possible_cost))\n",
    "        cost_score = max(0.1, min(1.0, cost_score))\n",
    "        \n",
    "        # 3. TERRAIN SUITABILITY - Fix the calculation\n",
    "        suitability = 1.0\n",
    "        \n",
    "        # Slope stability\n",
    "        if slope > 35:\n",
    "            suitability = 0.3\n",
    "        elif slope > 25:\n",
    "            suitability = 0.7\n",
    "        elif slope > 15:\n",
    "            suitability = 1.0\n",
    "        elif slope > 2:\n",
    "            suitability = 0.9\n",
    "        else:  # Too flat\n",
    "            suitability = 0.8\n",
    "            \n",
    "        # Avalanche risk (simplified)\n",
    "        if elevation > 2000 and 30 <= slope <= 45:\n",
    "            if aspect <= 45 or aspect >= 315:  # North-facing\n",
    "                suitability *= 0.6\n",
    "                \n",
    "        # Wind exposure\n",
    "        if elevation > 2500:\n",
    "            suitability *= 0.8\n",
    "        elif elevation > 2000:\n",
    "            suitability *= 0.9\n",
    "            \n",
    "        terrain_score = max(0.1, min(1.0, suitability))\n",
    "        \n",
    "        # 4. VALLEY COVERAGE - Fix calculation\n",
    "        if max_elevation > min_elevation:\n",
    "            relief_position = (elevation - min_elevation) / (max_elevation - min_elevation)\n",
    "        else:\n",
    "            relief_position = 0.5\n",
    "            \n",
    "        # Position score\n",
    "        if 0.2 <= relief_position <= 0.4:\n",
    "            position_score = 1.0\n",
    "        elif relief_position < 0.2:\n",
    "            position_score = 0.5 + 2.5 * relief_position\n",
    "        elif relief_position <= 0.6:\n",
    "            position_score = 1.0 - (relief_position - 0.4) * 2.5\n",
    "        else:\n",
    "            position_score = max(0.1, 0.5 * (1.0 - relief_position))\n",
    "            \n",
    "        # Slope coverage\n",
    "        if 10 <= slope <= 20:\n",
    "            slope_coverage = 1.0\n",
    "        elif slope < 10:\n",
    "            slope_coverage = 0.7 + slope * 0.03\n",
    "        else:\n",
    "            slope_coverage = max(0.4, 1.0 - (slope - 20) * 0.02)\n",
    "            \n",
    "        valley_coverage = position_score * 0.7 + slope_coverage * 0.3\n",
    "        valley_coverage = max(0.1, min(1.0, valley_coverage))\n",
    "        \n",
    "        return {\n",
    "            'accessibility': accessibility,\n",
    "            'installation_cost': cost_score,\n",
    "            'terrain_suitability': terrain_score,\n",
    "            'valley_coverage': valley_coverage\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Enhanced objectives failed for {coord}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Return middle values, not all the same\n",
    "        return {\n",
    "            'accessibility': 0.5,\n",
    "            'installation_cost': 0.5,\n",
    "            'terrain_suitability': 0.5,\n",
    "            'valley_coverage': 0.5\n",
    "        }\n",
    "\n",
    "\n",
    "def filter_candidates_by_criteria(candidates, dem_manager, min_elev=100, max_elev=2800, max_slope=25):\n",
    "    filtered = []\n",
    "    for coord in candidates:\n",
    "        try:\n",
    "            elev = dem_manager.get_elevation(coord)\n",
    "            if hasattr(dem_manager, \"get_slope_at_coord\"):\n",
    "                slope = dem_manager.get_slope_at_coord(coord)\n",
    "            else:\n",
    "                col, row = ~dem_manager.transform * coord\n",
    "                row, col = int(row), int(col)\n",
    "                if (dem_manager.slope_arr is not None and \n",
    "                    0 <= row < dem_manager.slope_arr.shape[0] and \n",
    "                    0 <= col < dem_manager.slope_arr.shape[1]):\n",
    "                    slope = dem_manager.slope_arr[row, col]\n",
    "                else:\n",
    "                    slope = 10.0\n",
    "            if min_elev <= elev <= max_elev and slope <= max_slope:\n",
    "                filtered.append(coord)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    print(f\"Filtered {len(filtered)}/{len(candidates)} candidates as human-accessible.\")\n",
    "    return filtered\n",
    "\n",
    "def coverage_score_for_candidate_lorawan(\n",
    "    coord, coverage_grid, dem_manager,\n",
    "    tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter, max_comm_range, max_path_loss_db\n",
    "):\n",
    "    \"\"\"\n",
    "    Fixed version that properly handles infinite path losses\n",
    "    \"\"\"\n",
    "    if not coverage_grid:\n",
    "        return 0.0\n",
    "    \n",
    "    covered_points = 0\n",
    "    total_points = len(coverage_grid)\n",
    "    finite_path_losses = []  # Only store finite values\n",
    "    infinite_count = 0\n",
    "    error_count = 0\n",
    "    out_of_range_count = 0\n",
    "    lorawan_budget = max_path_loss_db\n",
    "    \n",
    "    for p in coverage_grid:\n",
    "        try:\n",
    "            # Quick distance check first\n",
    "            dist_m = geodesic(coord[::-1], p[::-1]).meters\n",
    "            if dist_m > max_comm_range:\n",
    "                out_of_range_count += 1\n",
    "                infinite_count += 1\n",
    "                # Don't add to path_losses at all\n",
    "                continue\n",
    "                \n",
    "            path_loss = calculate_path_loss_pycraf(\n",
    "                coord, p, dem_manager,\n",
    "                tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter, max_comm_range\n",
    "            )\n",
    "            \n",
    "            # Only store finite values for statistics\n",
    "            if np.isfinite(path_loss):\n",
    "                finite_path_losses.append(path_loss)\n",
    "                if path_loss <= lorawan_budget:\n",
    "                    covered_points += 1\n",
    "            else:\n",
    "                infinite_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            continue\n",
    "    \n",
    "    coverage_pct = (covered_points / total_points) * 100.0 if total_points > 0 else 0.0\n",
    "    \n",
    "    # Only calculate statistics if we have finite values\n",
    "    if finite_path_losses and (coverage_pct < 100 or len(finite_path_losses) <= 20):\n",
    "        avg_loss = np.mean(finite_path_losses)\n",
    "        min_loss = np.min(finite_path_losses)\n",
    "        max_loss = np.max(finite_path_losses)\n",
    "        margin = lorawan_budget - avg_loss\n",
    "        \n",
    "        lidar_status = \"DSM+CHM\" if (hasattr(dem_manager, 'dsm_array') and dem_manager.dsm_array is not None) else \"DEM only\"\n",
    "        \n",
    "        print(f\"🎯 Gateway {coord}: {coverage_pct:.1f}% coverage\")\n",
    "        \n",
    "        # Show finite statistics\n",
    "        if infinite_count > 0:\n",
    "            # Show that some are infinite but stats are for finite only\n",
    "            print(f\"   Path loss (finite): {min_loss:.0f}-{max_loss:.0f} dB (avg: {avg_loss:.0f} dB)\")\n",
    "            print(f\"   Unreachable points: {infinite_count}/{total_points} ({100*infinite_count/total_points:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"   Path loss: {min_loss:.0f}-{max_loss:.0f} dB (avg: {avg_loss:.0f} dB)\")\n",
    "            \n",
    "        print(f\"   Link margin: {margin:.0f} dB (budget: {lorawan_budget:.0f} dB)\")\n",
    "        print(f\"   Data source: {lidar_status}\")\n",
    "        \n",
    "        if out_of_range_count > 0:\n",
    "            print(f\"   Beyond range: {out_of_range_count} points > {max_comm_range}m\")\n",
    "        if error_count > 0:\n",
    "            print(f\"   Errors: {error_count}\")\n",
    "            \n",
    "        # Show distribution of reachable points\n",
    "        if finite_path_losses:\n",
    "            reachable = sum(1 for pl in finite_path_losses if pl <= lorawan_budget)\n",
    "            print(f\"  Reachable: {reachable}/{len(finite_path_losses)} points with finite loss\")\n",
    "    \n",
    "    elif not finite_path_losses:\n",
    "        # All points had infinite loss\n",
    "        print(f\"Gateway {coord}: {coverage_pct:.1f}% coverage\")\n",
    "        print(f\"   No points with finite path loss - gateway may be isolated\")\n",
    "        print(f\"   Unreachable: {infinite_count}/{total_points} points\")\n",
    "    \n",
    "    return coverage_pct\n",
    "\n",
    "# --- MAIN FUNCTION: Precompute Gateway Objectives with Parallel Progress ---\n",
    "def precompute_gateway_objectives_enhanced(\n",
    "    aoi_poly, dem_manager,\n",
    "    tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter, max_comm_range, max_path_loss_db,\n",
    "    num_candidates=1000, export_csv=True, csv_path=\"gateway_candidates.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Enhanced parallelized gateway precomputation with tqdm progress bar (no overrun!).\n",
    "    Writes PRECOMP_COVERAGE_GRID / PRECOMP_COVERAGE_MASKS / PRECOMP_PAIRWISE_DIST for Phase 1 reuse.\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    from tqdm.notebook import tqdm\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        tqdm_bar = None\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            if self.tqdm_bar is not None:\n",
    "                self.tqdm_bar.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "\n",
    "    try:\n",
    "        # 1) Candidates\n",
    "        candidate_points = sample_points_in_poly(aoi_poly, num_candidates)\n",
    "        candidates = list(filter_candidates_by_criteria(candidate_points, dem_manager))\n",
    "        if not candidates:\n",
    "            print(\"No viable candidates after filtering!\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # 2) Coverage grid\n",
    "        coverage_grid = generate_coverage_grid(aoi_poly, OPTIMIZATION.COVERAGE_GRID_SIZE)\n",
    "\n",
    "        # 3) Build boolean coverage masks in parallel (one pass)\n",
    "        print(f\"Building coverage masks for {len(candidates)} candidates …\")\n",
    "        def _mask_job(coord):\n",
    "            return coverage_mask_for_candidate(\n",
    "                coord, coverage_grid, dem_manager,\n",
    "                tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter,\n",
    "                max_comm_range, max_path_loss_db, grid_idxs=None\n",
    "            )\n",
    "\n",
    "        with tqdm(total=len(candidates), desc=\"Mask jobs\", unit=\"cand\") as bar:\n",
    "            TqdmBatchCompletionCallback.tqdm_bar = bar\n",
    "            masks = Parallel(n_jobs=-1, backend='loky', prefer=\"processes\")(\n",
    "                delayed(_mask_job)(coord) for coord in candidates\n",
    "            )\n",
    "            TqdmBatchCompletionCallback.tqdm_bar = None\n",
    "\n",
    "        masks = np.vstack(masks).astype(bool)\n",
    "\n",
    "        # 4) Derive coverage % directly from masks (no second pass)\n",
    "        coverage_scores = masks.mean(axis=1) * 100.0\n",
    "\n",
    "        # 5) Centrality, solar, etc.\n",
    "        aoi_centroid = (aoi_poly.centroid.x, aoi_poly.centroid.y)\n",
    "        distances_to_center = [geodesic(c[::-1], aoi_centroid[::-1]).meters for c in candidates]\n",
    "        max_dist_from_center = max(distances_to_center) if distances_to_center else 1.0\n",
    "\n",
    "        objective_data = []\n",
    "        for i, coord in enumerate(candidates):\n",
    "            try:\n",
    "                elevation = dem_manager.get_elevation(coord)\n",
    "                sf = solar_features_for_coord(coord, dem_manager)   # NEW\n",
    "                solar_score = solar_score_from_energy_margin(sf['energy_margin_wh_day'], scale=50.0)\n",
    "                centrality_score = 1 - (distances_to_center[i] / max_dist_from_center)\n",
    "                enhanced_obj = calculate_enhanced_objectives(coord, dem_manager)\n",
    "                objective_data.append({\n",
    "                    'candidate_index': i,\n",
    "                    'coord': coord,\n",
    "                    'lon': coord[0],\n",
    "                    'lat': coord[1],\n",
    "                    'elevation': elevation,\n",
    "                    'solar': solar_score,\n",
    "                    'coverage': float(coverage_scores[i]),\n",
    "                    'centrality': centrality_score,\n",
    "                    'pv_wh_day_mean': sf['pv_wh_day_mean'],\n",
    "                    'pv_wh_year': sf['pv_wh_year'],\n",
    "                    'load_wh_day': sf['load_wh_day'],\n",
    "                    'energy_margin_wh_day': sf['energy_margin_wh_day'],\n",
    "                    'deficit_days': sf['deficit_days'],\n",
    "                    'tilt_deg': sf['tilt_deg'],\n",
    "                    'azimuth_deg': sf['azimuth_deg'],\n",
    "                    'pv_loss_fraction': sf['pv_loss_fraction'],\n",
    "                    'svf': sf.get('svf'),\n",
    "                    'mean_horizon_deg': sf.get('mean_horizon_deg'),\n",
    "                    'cloud_cover_mean_pct': sf.get('cloud_cover_mean_pct'),\n",
    "                    'cloudy_hours_pct': sf.get('cloudy_hours_pct'),\n",
    "                    'blocked_sun_hours': sf.get('blocked_sun_hours'),\n",
    "                    'blocked_sun_hours_pct': sf.get('blocked_sun_hours_pct'),\n",
    "                    'pv_p10_wh_day': sf.get('pv_p10_wh_day'),\n",
    "                    'longest_deficit_run_days': sf.get('longest_deficit_run_days'),\n",
    "                    **enhanced_obj\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Objective calculation failed for candidate {i}: {e}\")\n",
    "                objective_data.append({\n",
    "                    'candidate_index': i,\n",
    "                    'coord': coord,\n",
    "                    'lon': coord[0],\n",
    "                    'lat': coord[1],\n",
    "                    'elevation': 0.0,\n",
    "                    'solar': 0.0,\n",
    "                    'coverage': 0.0,\n",
    "                    'centrality': 0.5,\n",
    "\n",
    "                    # solar cols present but NaN\n",
    "                    'pv_wh_day_mean': np.nan,\n",
    "                    'pv_wh_year': np.nan,\n",
    "                    'load_wh_day': np.nan,\n",
    "                    'energy_margin_wh_day': np.nan,\n",
    "                    'deficit_days': np.nan,\n",
    "                    'tilt_deg': np.nan,\n",
    "                    'azimuth_deg': np.nan,\n",
    "                    'pv_loss_fraction': np.nan,\n",
    "\n",
    "                    # diagnostics present but NaN\n",
    "                    'svf': np.nan,\n",
    "                    'mean_horizon_deg': np.nan,\n",
    "                    'cloud_cover_mean_pct': np.nan,\n",
    "                    'cloudy_hours_pct': np.nan,\n",
    "                    'blocked_sun_hours': np.nan,\n",
    "                    'blocked_sun_hours_pct': np.nan,\n",
    "\n",
    "                    'accessibility': 0.5,\n",
    "                    'installation_cost': 0.5,\n",
    "                    'terrain_suitability': 0.5,\n",
    "                    'valley_coverage': 0.5\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(objective_data)\n",
    "        if df.empty:\n",
    "            print(\" No valid candidates processed!\")\n",
    "            return df\n",
    "        print(\"Solar sanity:\")\n",
    "        print(df[['pv_wh_day_mean','load_wh_day','energy_margin_wh_day','deficit_days']].describe())\n",
    "        print(\"Sample rows:\")\n",
    "        print(df[['lon','lat','pv_wh_day_mean','load_wh_day','energy_margin_wh_day','deficit_days','solar']].head(5))\n",
    "        print(\"Solar sanity:\")\n",
    "        solar_cols = ['pv_wh_day_mean','load_wh_day','energy_margin_wh_day','deficit_days']\n",
    "        present = [c for c in solar_cols if c in df.columns]\n",
    "        if present:\n",
    "            print(df[present].describe())\n",
    "        else:\n",
    "            print(\"No solar columns present (all candidates failed before PV calc?).\")\n",
    "        diag_cols = [\n",
    "            'cloud_cover_mean_pct','cloudy_hours_pct',\n",
    "            'blocked_sun_hours','blocked_sun_hours_pct',\n",
    "            'svf','mean_horizon_deg'\n",
    "        ]\n",
    "        present = [c for c in diag_cols if c in df.columns]\n",
    "        print(\"\\nDiagnostics summary:\")\n",
    "        if present:\n",
    "            print(df[present].describe())\n",
    "        else:\n",
    "            print(\"No diagnostic columns found – did you replace both `_pv_dc_daily_wh` and `solar_features_for_coord`?\")\n",
    "\n",
    "        # quick sanity plots (feel free to comment out)\n",
    "        ax = df.plot.scatter(x='cloud_cover_mean_pct', y='pv_wh_day_mean', alpha=0.6, title='PV vs Mean Cloud Cover (%)')\n",
    "        ax = df.plot.scatter(x='blocked_sun_hours_pct', y='pv_wh_day_mean', alpha=0.6, title='PV vs Blocked Sun Hours (%)')\n",
    "\n",
    "        # plot raw physical margin\n",
    "        df['energy_margin_wh_day'].hist(bins=30)\n",
    "        plt.xlabel('Energy margin (Wh/day)'); plt.ylabel('Count'); plt.show()\n",
    "\n",
    "        # create the normalized copy used by optimizers/scoring\n",
    "        rng = float(df['energy_margin_wh_day'].max() - df['energy_margin_wh_day'].min())\n",
    "        df['energy_margin_norm'] = (\n",
    "            (df['energy_margin_wh_day'] - df['energy_margin_wh_day'].min()) / (rng if rng else 1.0)\n",
    "        )\n",
    "        # Keep your previously-computed df['solar'] as-is.\n",
    "        # (Optionally fill if missing)\n",
    "        if 'solar' not in df or df['solar'].isna().all():\n",
    "            df['solar'] = df['energy_margin_norm']\n",
    "        \n",
    "        # Normalize and export\n",
    "        gateway_objectives = [\n",
    "            'coverage', 'solar', 'elevation', 'accessibility', 'installation_cost',\n",
    "            'terrain_suitability', 'valley_coverage', 'centrality'\n",
    "        ]\n",
    "        df = normalize_df_columns(df, gateway_objectives)\n",
    "        if export_csv:\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\" Candidate DataFrame exported to {csv_path}\")\n",
    "\n",
    "        # 6) Write precomputed artifacts for Phase 1 reuse\n",
    "        global PRECOMP_COVERAGE_GRID, PRECOMP_COVERAGE_MASKS, PRECOMP_PAIRWISE_DIST\n",
    "        PRECOMP_COVERAGE_GRID = coverage_grid\n",
    "        PRECOMP_COVERAGE_MASKS = masks\n",
    "        PRECOMP_PAIRWISE_DIST = build_pairwise_dist_matrix(pd.DataFrame({'coord': candidates}))\n",
    "        print(f\" Saved PRECOMP_*: grid={len(PRECOMP_COVERAGE_GRID)} cols, masks={PRECOMP_COVERAGE_MASKS.shape}, dist={PRECOMP_PAIRWISE_DIST.shape}\")\n",
    "\n",
    "        # (Optional) quick scatter\n",
    "        try:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            if 'coverage' in df.columns and len(df) > 0:\n",
    "                sc1 = axes[0].scatter(df['lon'], df['lat'], c=df['coverage'], cmap='viridis', s=12, alpha=0.7)\n",
    "                axes[0].set_title('Gateway Candidates - Coverage Score')\n",
    "                axes[0].set_xlabel('Longitude'); axes[0].set_ylabel('Latitude')\n",
    "                plt.colorbar(sc1, ax=axes[0], label='Coverage (%)')\n",
    "            if 'elevation' in df.columns and len(df) > 0:\n",
    "                sc2 = axes[1].scatter(df['lon'], df['lat'], c=df['elevation'], cmap='terrain', s=12, alpha=0.7)\n",
    "                axes[1].set_title('Gateway Candidates - Elevation')\n",
    "                axes[1].set_xlabel('Longitude'); axes[1].set_ylabel('Latitude')\n",
    "                plt.colorbar(sc2, ax=axes[1], label='Elevation (m)')\n",
    "            plt.tight_layout(); plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\" Plotting failed: {e}\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" CRITICAL ERROR in precomputation: {type(e).__name__}: {str(e)}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_callback\n",
    "\n",
    "# =================================================================\n",
    "# USAGE EXAMPLE (for batch/production)\n",
    "# =================================================================\n",
    "\n",
    "gateway_candidate_df = precompute_gateway_objectives_enhanced(\n",
    "    aoi_poly, dem_manager,\n",
    "    NETWORK.GATEWAY_HEIGHT, NETWORK.SENSOR_HEIGHT, 915.0, 2.0, 0.0,\n",
    "    NETWORK.MAX_COMM_RANGE_M, OPTIMIZATION.MAX_ALLOWABLE_PATH_LOSS_DB,\n",
    "    num_candidates=300, export_csv=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1291c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gateway Candidate Interactive Map & Histogram Visualization ---\n",
    "\n",
    "from ipyleaflet import Map, CircleMarker, basemaps\n",
    "from ipywidgets import HTML, VBox, Output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# ----- Choose which objective to color by -----\n",
    "objective_for_color = 'solar'  # Can set to 'coverage', 'elevation', etc.\n",
    "\n",
    "# --- Robust Data/Bounds ---\n",
    "scores = gateway_candidate_df[objective_for_color].values\n",
    "norm = mcolors.Normalize(vmin=np.nanmin(scores), vmax=np.nanmax(scores))\n",
    "cmap = plt.cm.plasma\n",
    "\n",
    "# --- Setup Map ---\n",
    "m = Map(\n",
    "    center=[aoi_poly.centroid.y, aoi_poly.centroid.x],\n",
    "    zoom=13,\n",
    "    basemap=basemaps.Esri.WorldImagery\n",
    ")\n",
    "\n",
    "def safe_fmt(val, fmt):\n",
    "    try:\n",
    "        if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "            return \"NA\"\n",
    "        return format(float(val), fmt)\n",
    "    except Exception:\n",
    "        return \"NA\"\n",
    "\n",
    "# --- Add Candidates as Markers ---\n",
    "for _, row in gateway_candidate_df.iterrows():\n",
    "    lat, lon = row['lat'], row['lon']\n",
    "    val = row[objective_for_color]\n",
    "    color = mcolors.to_hex(cmap(norm(val)))\n",
    "    popup_html = (\n",
    "        f\"<b>Solar:</b> {safe_fmt(row.get('solar'), '.2f')}<br>\"\n",
    "        f\"<b>PV p10 (Wh/day):</b> {safe_fmt(row.get('pv_p10_wh_day'), '.1f')}<br>\"\n",
    "        f\"<b>Load (Wh/day):</b> {safe_fmt(row.get('load_wh_day'), '.1f')}<br>\"\n",
    "        f\"<b>Longest deficit run:</b> {safe_fmt(row.get('longest_deficit_run_days'), '.0f')} d<br>\"\n",
    "        f\"<b>Coverage:</b> {safe_fmt(row.get('coverage'), '.1f')}<br>\"\n",
    "        f\"<b>Elevation:</b> {safe_fmt(row.get('elevation'), '.1f')}<br>\"\n",
    "        f\"<b>Accessibility:</b> {safe_fmt(row.get('accessibility'), '.2f')}<br>\"\n",
    "        f\"<b>Install Cost:</b> {safe_fmt(row.get('installation_cost'), '.2f')}<br>\"\n",
    "        f\"<b>Terrain Suitability:</b> {safe_fmt(row.get('terrain_suitability'), '.2f')}<br>\"\n",
    "        f\"<b>Valley Coverage:</b> {safe_fmt(row.get('valley_coverage'), '.2f')}\"\n",
    "    )\n",
    "    marker = CircleMarker(\n",
    "        location=(lat, lon),\n",
    "        radius=4,\n",
    "        color=color,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7\n",
    "    )\n",
    "    marker.popup = HTML(popup_html)\n",
    "    m.add_layer(marker)\n",
    "\n",
    "# --- Histogram for Chosen Objective ---\n",
    "out = Output()\n",
    "with out:\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    n_vals, bins, patches = ax.hist(scores, bins=30, edgecolor='black')\n",
    "    fracs = (bins[:-1] - bins.min()) / (bins.max() - bins.min() + 1e-8)\n",
    "    for frac, patch in zip(fracs, patches):\n",
    "        patch.set_facecolor(cmap(frac))\n",
    "    ax.set_title(f'Distribution of {objective_for_color.capitalize()}')\n",
    "    ax.set_xlabel(objective_for_color.capitalize())\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Show Map + Histogram Together ---\n",
    "VBox([m, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b020a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 6. ===== PHASE 1: GATEWAY MULTI-OBJECTIVE OPTIMIZATION & UI =====\n",
    "# With precomputed coverage masks (one-time) + fast NSGA-III evaluation\n",
    "# + Dropdown to browse and visualize ALL feasible Pareto solutions\n",
    "# ===========================================================\n",
    "from IPython.display import display\n",
    "from ipywidgets import (\n",
    "    FloatSlider, IntSlider, Dropdown, SelectMultiple, Button, Output,\n",
    "    HBox, VBox, HTML, Layout\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# For the map\n",
    "from ipyleaflet import Map, CircleMarker, GeoJSON, basemaps, LayerGroup\n",
    "\n",
    "# ==============================\n",
    "# Globals / shared precomputes\n",
    "# ==============================\n",
    "# These reuse the candidate DataFrame produced by your Cell 4 precomputation.\n",
    "# Assumes the following exist from earlier cells:\n",
    "#   aoi_poly, dem_manager, gateway_candidate_df, NETWORK, OPTIMIZATION\n",
    "COVERAGE_GRID = None            # list[(lon,lat)]\n",
    "COVERAGE_MASKS = None           # np.ndarray [N_candidates, N_grid] bool\n",
    "PAIRWISE_DIST = None            # np.ndarray [N_candidates, N_candidates] float\n",
    "\n",
    "# Adopted solution for downstream steps (single source of truth)\n",
    "CURRENT_SOLUTION = None\n",
    "CURRENT_SOLUTION_INDEXES = None\n",
    "\n",
    "# State for saving solutions\n",
    "saved_solutions = {} if 'saved_solutions' not in globals() else saved_solutions\n",
    "solution_counter = 0 if 'solution_counter' not in globals() else solution_counter\n",
    "\n",
    "# Store the entire feasible set from the last NSGA run for browsing\n",
    "_last_nsga_store = {\n",
    "    \"idxs_list\": None,         # list of arrays of candidate indices\n",
    "    \"F\": None,                 # objective matrix for feasible solutions\n",
    "    \"rank_order\": None,        # order to browse (best -> worst by dist to ideal)\n",
    "    \"objective_names\": None,   # tuple/list of objective names used\n",
    "    \"num_gateways\": None,      # k\n",
    "    \"min_sep\": None,           # min separation\n",
    "    \"selected_objs\": None      # same as objective_names\n",
    "}\n",
    "\n",
    "# Helper to enforce single source of truth in downstream cells\n",
    "def get_current_solution_or_raise():\n",
    "    global CURRENT_SOLUTION\n",
    "    if CURRENT_SOLUTION is None:\n",
    "        raise RuntimeError(\"No CURRENT_SOLUTION set. Adopt a solution above (MIP or NSGA) first.\")\n",
    "    return CURRENT_SOLUTION\n",
    "\n",
    "# ==============================\n",
    "# Utilities\n",
    "# ==============================\n",
    "def safe_fmt(val, fmt):\n",
    "    try:\n",
    "        if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "            return \"NA\"\n",
    "        return format(float(val), fmt)\n",
    "    except Exception:\n",
    "        return \"NA\"\n",
    "\n",
    "def normalize_objective(df, col):\n",
    "    vals = df[col].values\n",
    "    min_val, max_val = np.min(vals), np.max(vals)\n",
    "    if max_val > min_val:\n",
    "        return (vals - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        return np.zeros_like(vals)\n",
    "\n",
    "def get_objective_presets():\n",
    "    return {\n",
    "        'balanced': {\n",
    "            'coverage': 0.22, 'solar': 0.13, 'accessibility': 0.13,\n",
    "            'installation_cost': 0.10, 'terrain_suitability': 0.10, 'valley_coverage': 0.10,\n",
    "            'elevation': 0.11, 'centrality': 0.11\n",
    "        },\n",
    "        'coverage_focused': {\n",
    "            'coverage': 0.48, 'solar': 0.13, 'accessibility': 0.07,\n",
    "            'installation_cost': 0.05, 'terrain_suitability': 0.05, 'valley_coverage': 0.0,\n",
    "            'elevation': 0.11, 'centrality': 0.11\n",
    "        },\n",
    "        'accessibility_focused': {\n",
    "            'coverage': 0.11, 'solar': 0.07, 'accessibility': 0.44,\n",
    "            'installation_cost': 0.18, 'terrain_suitability': 0.10, 'valley_coverage': 0.0,\n",
    "            'elevation': 0.05, 'centrality': 0.05\n",
    "        },\n",
    "        'valley_monitoring': {\n",
    "            'coverage': 0.18, 'solar': 0.10, 'accessibility': 0.10,\n",
    "            'installation_cost': 0.09, 'terrain_suitability': 0.10, 'valley_coverage': 0.22,\n",
    "            'elevation': 0.11, 'centrality': 0.10\n",
    "        },\n",
    "        'cost_optimized': {\n",
    "            'coverage': 0.22, 'solar': 0.07, 'accessibility': 0.14,\n",
    "            'installation_cost': 0.32, 'terrain_suitability': 0.10, 'valley_coverage': 0.0,\n",
    "            'elevation': 0.07, 'centrality': 0.08\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Fallback for sort_gateways if not defined elsewhere\n",
    "if 'sort_gateways' not in globals():\n",
    "    def sort_gateways(solution, sort_by=\"lon\"):\n",
    "        if not solution or not isinstance(solution, list) or 'coord' not in solution[0]:\n",
    "            return solution\n",
    "        if sort_by == \"lon\":\n",
    "            return sorted(solution, key=lambda gw: gw['coord'][0])\n",
    "        elif sort_by == \"lat\":\n",
    "            return sorted(solution, key=lambda gw: gw['coord'][1])\n",
    "        else:\n",
    "            return solution\n",
    "\n",
    "# ========= MIP Solver (unchanged) =========\n",
    "def solve_gateway_placement_mip(candidate_df, num_gateways, weights, min_separation_m=800.0, solver=None):\n",
    "    import pulp\n",
    "    from itertools import combinations\n",
    "    from geopy.distance import geodesic\n",
    "\n",
    "    if solver is None:\n",
    "        solver = pulp.PULP_CBC_CMD(msg=0)\n",
    "    if candidate_df is None or candidate_df.empty:\n",
    "        return None\n",
    "    df = candidate_df.copy()\n",
    "    indices = df.index.tolist()\n",
    "    all_objectives = ['coverage', 'solar', 'accessibility', 'installation_cost', 'terrain_suitability', 'valley_coverage', 'elevation', 'centrality']\n",
    "    used_objectives = [obj for obj in all_objectives if obj in df.columns]\n",
    "    # Weighted composite score\n",
    "    df['weighted_score'] = 0.0\n",
    "    for obj, weight in weights.items():\n",
    "        if obj in df.columns and weight > 0:\n",
    "            normed = normalize_objective(df, obj)\n",
    "            df['weighted_score'] += weight * normed\n",
    "\n",
    "    prob = pulp.LpProblem(\"GatewayPlacement\", pulp.LpMaximize)\n",
    "    x = pulp.LpVariable.dicts(\"gateway\", indices, cat='Binary')\n",
    "    prob += pulp.lpSum([df.loc[i, 'weighted_score'] * x[i] for i in indices]), \"Total_Weighted_Score\"\n",
    "    prob += pulp.lpSum([x[i] for i in indices]) == num_gateways, \"Select_N_Gateways\"\n",
    "\n",
    "    if num_gateways > 1 and min_separation_m > 0:\n",
    "        for i, j in combinations(indices, 2):\n",
    "            coord_i, coord_j = df.loc[i, 'coord'], df.loc[j, 'coord']\n",
    "            if geodesic(coord_i[::-1], coord_j[::-1]).meters < min_separation_m:\n",
    "                prob += x[i] + x[j] <= 1, f\"Separation_{i}_{j}\"\n",
    "\n",
    "    prob.solve(solver)\n",
    "    if prob.status == pulp.LpStatusOptimal:\n",
    "        selected_indices = [i for i in indices if x[i].varValue == 1]\n",
    "        solution_gateways = df.loc[selected_indices].to_dict('records')\n",
    "        objective_totals = {obj: sum(gw.get(obj, 0) for gw in solution_gateways) for obj in used_objectives}\n",
    "        return {\n",
    "            'solution': solution_gateways,\n",
    "            'status': 'optimal',\n",
    "            'objective_totals': objective_totals,\n",
    "            'num_gateways': num_gateways,\n",
    "            'weights': weights.copy(),\n",
    "            'solver_used': str(solver)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'solution': None,\n",
    "            'status': pulp.LpStatus[prob.status],\n",
    "            'error': f\"Optimization failed with status: {pulp.LpStatus[prob.status]}\"\n",
    "        }\n",
    "\n",
    "def get_solver():\n",
    "    import pulp\n",
    "    return pulp.PULP_CBC_CMD(msg=0)\n",
    "\n",
    "# ==============================\n",
    "# Fast coverage + distance helpers\n",
    "# ==============================\n",
    "def build_pairwise_dist_matrix(candidate_df: pd.DataFrame) -> np.ndarray:\n",
    "    coords = candidate_df['coord'].tolist()\n",
    "    n = len(coords)\n",
    "    D = np.zeros((n, n), dtype=float)\n",
    "    for i in range(n):\n",
    "        lon_i, lat_i = coords[i]\n",
    "        for j in range(i+1, n):\n",
    "            lon_j, lat_j = coords[j]\n",
    "            d = geodesic((lat_i, lon_i), (lat_j, lon_j)).meters\n",
    "            D[i, j] = D[j, i] = d\n",
    "    return D\n",
    "\n",
    "def coverage_mask_for_candidate(coord, coverage_grid, dem_manager,\n",
    "    tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter, max_comm_range, max_path_loss_db,\n",
    "    grid_idxs=None):\n",
    "    n = len(coverage_grid)\n",
    "    mask = np.zeros(n, dtype=bool)\n",
    "    idxs = range(n) if grid_idxs is None else grid_idxs\n",
    "    for j in idxs:\n",
    "        p = coverage_grid[j]\n",
    "        try:\n",
    "            if geodesic(coord[::-1], p[::-1]).meters > max_comm_range:\n",
    "                continue\n",
    "            pl = calculate_path_loss_pycraf(\n",
    "                coord, p, dem_manager,\n",
    "                tx_h, rx_h, freq_mhz, veg_threshold, attn_per_meter, max_comm_range\n",
    "            )\n",
    "            if np.isfinite(pl) and pl <= max_path_loss_db:\n",
    "                mask[j] = True\n",
    "        except Exception:\n",
    "            pass\n",
    "    return mask\n",
    "\n",
    "def ensure_precomputed_masks(\n",
    "    candidate_cap=None,\n",
    "    grid_every=1,\n",
    "    n_jobs=-1,\n",
    "    backend='threading'\n",
    "):\n",
    "    \"\"\"\n",
    "    Build COVERAGE_GRID, COVERAGE_MASKS, PAIRWISE_DIST with progress + subsampling.\n",
    "    Call with grid_every>1 first to get to NSGA quickly, then switch to 1 for full fidelity.\n",
    "    \"\"\"\n",
    "    global COVERAGE_GRID, COVERAGE_MASKS, PAIRWISE_DIST\n",
    "\n",
    "    # Reuse precomputed values from Cell 4 if available\n",
    "    if COVERAGE_GRID is None and 'PRECOMP_COVERAGE_GRID' in globals() and PRECOMP_COVERAGE_GRID is not None:\n",
    "        COVERAGE_GRID = PRECOMP_COVERAGE_GRID\n",
    "    if COVERAGE_MASKS is None and 'PRECOMP_COVERAGE_MASKS' in globals() and PRECOMP_COVERAGE_MASKS is not None:\n",
    "        COVERAGE_MASKS = PRECOMP_COVERAGE_MASKS\n",
    "    if PAIRWISE_DIST is None and 'PRECOMP_PAIRWISE_DIST' in globals() and PRECOMP_PAIRWISE_DIST is not None:\n",
    "        PAIRWISE_DIST = PRECOMP_PAIRWISE_DIST\n",
    "\n",
    "    # If everything is present, skip rebuild\n",
    "    if (COVERAGE_GRID is not None) and (COVERAGE_MASKS is not None) and (PAIRWISE_DIST is not None):\n",
    "        print(\" Using precomputed masks/grid/dist from Cell 4\")\n",
    "        return\n",
    "\n",
    "    print(\" Building precomputed coverage masks & distances (one-time)...\")\n",
    "\n",
    "    # 1) Grid (reuse existing generator + optional subsample view)\n",
    "    COVERAGE_GRID = generate_coverage_grid(aoi_poly, OPTIMIZATION.COVERAGE_GRID_SIZE)\n",
    "    n_grid = len(COVERAGE_GRID)\n",
    "    if n_grid == 0:\n",
    "        raise RuntimeError(\"Coverage grid is empty.\")\n",
    "\n",
    "    if grid_every > 1:\n",
    "        grid_idxs = np.arange(0, n_grid, grid_every, dtype=int)\n",
    "        print(f\"Using grid subsample: every {grid_every}th point → {len(grid_idxs)}/{n_grid}\")\n",
    "    else:\n",
    "        grid_idxs = None\n",
    "        print(f\"Using full grid: {n_grid} points\")\n",
    "\n",
    "    # 2) Candidates (optional cap while testing)\n",
    "    base_coords = gateway_candidate_df['coord'].tolist()\n",
    "    if candidate_cap is not None and candidate_cap < len(base_coords):\n",
    "        print(f\"🎯 Candidate cap active: {candidate_cap}/{len(base_coords)} (for faster first build)\")\n",
    "        coords = base_coords[:candidate_cap]\n",
    "    else:\n",
    "        coords = base_coords\n",
    "\n",
    "    # 3) Parallel mask build with tqdm\n",
    "    print(f\" Building masks for {len(coords)} candidates …\")\n",
    "    def _job(coord):\n",
    "        return coverage_mask_for_candidate(\n",
    "            coord, COVERAGE_GRID, dem_manager,\n",
    "            NETWORK.GATEWAY_HEIGHT, NETWORK.SENSOR_HEIGHT, 915.0, 2.0, 0.0,\n",
    "            NETWORK.MAX_COMM_RANGE_M, OPTIMIZATION.MAX_ALLOWABLE_PATH_LOSS_DB,\n",
    "            grid_idxs=grid_idxs\n",
    "        )\n",
    "\n",
    "    masks = Parallel(n_jobs=n_jobs, backend=backend)(\n",
    "        delayed(_job)(coord) for coord in tqdm(coords, desc=\"Mask jobs\", unit=\"cand\")\n",
    "    )\n",
    "    masks = np.vstack(masks).astype(bool)\n",
    "\n",
    "    # 4) Candidate padding if capped\n",
    "    if len(coords) < len(base_coords):\n",
    "        pad = np.zeros((len(base_coords) - len(coords), masks.shape[1]), dtype=bool)\n",
    "        COVERAGE_MASKS = np.vstack([masks, pad])\n",
    "        print(\" Remaining (uncapped) candidates default to no coverage until you rebuild with full set.\")\n",
    "    else:\n",
    "        COVERAGE_MASKS = masks\n",
    "\n",
    "    # 5) Pairwise distances\n",
    "    PAIRWISE_DIST = build_pairwise_dist_matrix(gateway_candidate_df)\n",
    "\n",
    "    print(f\"Masks ready: candidates={COVERAGE_MASKS.shape[0]}, grid_cols={COVERAGE_MASKS.shape[1]}\")\n",
    "    if grid_every > 1:\n",
    "        print(\" You are using a subsampled grid for speed. For final results, rebuild with grid_every=1.\")\n",
    "\n",
    "# ==============================\n",
    "# UI Controls\n",
    "# ==============================\n",
    "nsga_objective_options = [\n",
    "    ('Coverage', 'coverage'),\n",
    "    ('Solar', 'solar'),\n",
    "    ('Accessibility', 'accessibility'),\n",
    "    ('Elevation', 'elevation'),\n",
    "    ('Installation Cost', 'installation_cost'),\n",
    "    ('Terrain Suitability', 'terrain_suitability'),\n",
    "    ('Valley Coverage', 'valley_coverage'),\n",
    "    ('Centrality', 'centrality')\n",
    "]\n",
    "nsga_obj_select = SelectMultiple(\n",
    "    options=[('Coverage', 'coverage')] + nsga_objective_options[1:],\n",
    "    value=('coverage', 'solar', 'accessibility'),\n",
    "    description='NSGA-III Objectives',\n",
    "    layout=Layout(width='300px', height='110px'),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "preset_dropdown = Dropdown(options=[('Custom', 'custom')] + [(k.replace('_', ' ').title(), k) for k in get_objective_presets().keys()],\n",
    "                           value='balanced', description='Preset:', style=style)\n",
    "w_coverage = FloatSlider(value=0.22, min=0, max=1, step=0.05, description='Coverage:', style=style)\n",
    "w_solar = FloatSlider(value=0.13, min=0, max=1, step=0.05, description='Solar:', style=style)\n",
    "w_accessibility = FloatSlider(value=0.13, min=0, max=1, step=0.05, description='Accessibility:', style=style)\n",
    "w_install_cost = FloatSlider(value=0.10, min=0, max=1, step=0.05, description='Install Cost:', style=style)\n",
    "w_terrain = FloatSlider(value=0.10, min=0, max=1, step=0.05, description='Terrain Suitability:', style=style)\n",
    "w_valley = FloatSlider(value=0.10, min=0, max=1, step=0.05, description='Valley Coverage:', style=style)\n",
    "w_elevation = FloatSlider(value=0.11, min=0, max=1, step=0.05, description='Elevation:', style=style)\n",
    "w_centrality = FloatSlider(value=0.11, min=0, max=1, step=0.05, description='Centrality:', style=style)\n",
    "\n",
    "min_separation = IntSlider(value=300, min=50, max=1000, step=50, description='Min Separation (m):', style=style)\n",
    "num_gateways_slider = IntSlider(value=2, min=1, max=5, step=1, description='Gateways:', style=style)\n",
    "optimization_method = Dropdown(options=[('Weighted (MIP)', 'mip'), ('Pareto (NSGA-III)', 'nsga3')],\n",
    "                               value='mip', description='Method:', style=style)\n",
    "\n",
    "def get_current_weights():\n",
    "    return {\n",
    "        'coverage': w_coverage.value,\n",
    "        'solar': w_solar.value,\n",
    "        'accessibility': w_accessibility.value,\n",
    "        'installation_cost': w_install_cost.value,\n",
    "        'terrain_suitability': w_terrain.value,\n",
    "        'valley_coverage': w_valley.value,\n",
    "        'elevation': w_elevation.value,\n",
    "        'centrality': w_centrality.value\n",
    "    }\n",
    "\n",
    "def apply_preset(preset_name):\n",
    "    presets = get_objective_presets()\n",
    "    if preset_name in presets:\n",
    "        weights = presets[preset_name]\n",
    "        w_coverage.value = weights.get('coverage', 0.0)\n",
    "        w_solar.value = weights.get('solar', 0.0)\n",
    "        w_accessibility.value = weights.get('accessibility', 0.0)\n",
    "        w_install_cost.value = weights.get('installation_cost', 0.0)\n",
    "        w_terrain.value = weights.get('terrain_suitability', 0.0)\n",
    "        w_valley.value = weights.get('valley_coverage', 0.0)\n",
    "        w_elevation.value = weights.get('elevation', 0.0)\n",
    "        w_centrality.value = weights.get('centrality', 0.0)\n",
    "\n",
    "preset_dropdown.observe(lambda c: apply_preset(c['new']) if c['name']=='value' else None)\n",
    "\n",
    "# ==============================\n",
    "# Map viz helpers\n",
    "# ==============================\n",
    "def plot_gateways_on_map(aoi_poly, gateway_solution, label_prefix=\"Gateway\", color='red'):\n",
    "    \"\"\"\n",
    "    Visualize selected gateway locations on an ipyleaflet map.\n",
    "    gateway_solution: list of dicts, each with at least {'coord': (lon, lat)}\n",
    "    \"\"\"\n",
    "    m = Map(\n",
    "        center=(aoi_poly.centroid.y, aoi_poly.centroid.x),\n",
    "        zoom=13,\n",
    "        basemap=basemaps.Esri.WorldImagery\n",
    "    )\n",
    "    m.add_layer(GeoJSON(data=aoi_poly.__geo_interface__, style={\n",
    "        'color': 'yellow', 'fillOpacity': 0.1, 'weight': 3\n",
    "    }))\n",
    "    solution_sorted = sort_gateways(gateway_solution, sort_by=\"lon\")\n",
    "    for idx, gw in enumerate(solution_sorted):\n",
    "        lat, lon = gw['coord'][1], gw['coord'][0]\n",
    "        popup_html = f\"<b>{label_prefix} {idx+1}</b><br>Lon: {lon:.5f}<br>Lat: {lat:.5f}\"\n",
    "        for k in ['coverage','elevation','solar','accessibility','installation_cost','terrain_suitability','valley_coverage','centrality']:\n",
    "            if k in gw:\n",
    "                v = gw[k]\n",
    "                if isinstance(v, (int,float)):\n",
    "                    popup_html += f\"<br>{k.replace('_',' ').title()}: {v:.2f}\"\n",
    "                else:\n",
    "                    popup_html += f\"<br>{k.replace('_',' ').title()}: {v}\"\n",
    "        marker = CircleMarker(\n",
    "            location=(lat, lon),\n",
    "            radius=8,\n",
    "            color=color,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.8,\n",
    "            popup=HTML(popup_html)\n",
    "        )\n",
    "        m.add_layer(marker)\n",
    "    return m\n",
    "\n",
    "def _solution_records_from_idxs(idxs):\n",
    "    \"\"\"Build gateway record dicts from candidate_df rows + attach objective columns if present.\"\"\"\n",
    "    rows = gateway_candidate_df.iloc[list(idxs)]\n",
    "    return rows.to_dict('records')\n",
    "\n",
    "# ==============================\n",
    "# Main Optimization Handler + Feasible Browser\n",
    "# ==============================\n",
    "output = Output()\n",
    "map_out = Output()          # where we draw the map\n",
    "\n",
    "feasible_dropdown = Dropdown(\n",
    "    options=[(\"— run NSGA-III to populate —\", -1)],\n",
    "    value=-1,\n",
    "    description='Feasible:',\n",
    "    layout=Layout(width='400px')\n",
    ")\n",
    "\n",
    "# NSGA adopt button\n",
    "adopt_btn = Button(description=\"Adopt Selected Feasible\", button_style='info')\n",
    "\n",
    "# MIP adopt button & state\n",
    "adopt_mip_btn = Button(description=\"Adopt MIP Result\", button_style='info', disabled=True, layout=Layout(width='160px'))\n",
    "_last_mip_records = None\n",
    "\n",
    "adopt_msg = Output()\n",
    "\n",
    "def _adopt_clicked(_):\n",
    "    adopt_msg.clear_output()\n",
    "    with adopt_msg:\n",
    "        store = _last_nsga_store\n",
    "        if store[\"idxs_list\"] is None or feasible_dropdown.value == -1:\n",
    "            print(\"No feasible set selected.\")\n",
    "            return\n",
    "        idx_in_feasible = int(feasible_dropdown.value)\n",
    "        idxs = store[\"idxs_list\"][idx_in_feasible]\n",
    "        records = gateway_candidate_df.iloc[list(map(int, idxs))].to_dict('records')\n",
    "\n",
    "        # Stash globally for downstream cells\n",
    "        global CURRENT_SOLUTION, CURRENT_SOLUTION_INDEXES\n",
    "        CURRENT_SOLUTION, CURRENT_SOLUTION_INDEXES = records, idxs\n",
    "\n",
    "        rank_1 = int(np.where(store[\"rank_order\"] == idx_in_feasible)[0][0]) + 1\n",
    "        name = f\"Chosen_FeasibleRank_{rank_1}_{store['num_gateways']}GW_NSGA3\"\n",
    "        saved_solutions[name] = {\"solution\": records, \"meta\": {\n",
    "            \"rank\": rank_1,\n",
    "            \"objectives\": store[\"objective_names\"],\n",
    "            \"k\": store[\"num_gateways\"],\n",
    "            \"min_sep\": store[\"min_sep\"],\n",
    "            \"method\": \"NSGA-III\"\n",
    "        }}\n",
    "        print(f\"Adopted: {name} → CURRENT_SOLUTION set ({len(records)} gateways).\")\n",
    "\n",
    "adopt_btn.on_click(_adopt_clicked)\n",
    "\n",
    "def _adopt_mip_clicked(_):\n",
    "    adopt_msg.clear_output()\n",
    "    with adopt_msg:\n",
    "        global CURRENT_SOLUTION, CURRENT_SOLUTION_INDEXES, _last_mip_records\n",
    "        if _last_mip_records is None:\n",
    "            print(\"No MIP result to adopt.\")\n",
    "            return\n",
    "        CURRENT_SOLUTION = _last_mip_records\n",
    "        # Best-effort indexes if present\n",
    "        CURRENT_SOLUTION_INDEXES = [r.get('candidate_index', None) for r in CURRENT_SOLUTION]\n",
    "        name = f\"Chosen_MIP_{len(CURRENT_SOLUTION)}GW\"\n",
    "        saved_solutions[name] = {\"solution\": CURRENT_SOLUTION, \"meta\": {\"method\": \"MIP\", \"k\": len(CURRENT_SOLUTION)}}\n",
    "        print(f\"Adopted: {name} → CURRENT_SOLUTION set ({len(CURRENT_SOLUTION)} gateways).\")\n",
    "\n",
    "adopt_mip_btn.on_click(_adopt_mip_clicked)\n",
    "\n",
    "run_btn = Button(description='Run Optimization', button_style='success')\n",
    "\n",
    "def _rank_feasible(feasible_F):\n",
    "    \"\"\"Return indices 0..(m-1) sorted by distance to ideal (best -> worst).\"\"\"\n",
    "    ideal = feasible_F.min(axis=0)\n",
    "    nadir = feasible_F.max(axis=0)\n",
    "    norm = (feasible_F - ideal) / (nadir - ideal + 1e-12)\n",
    "    d = np.linalg.norm(norm, axis=1)\n",
    "    return np.argsort(d), d\n",
    "\n",
    "def _format_dropdown_label(rank, F_row, obj_names):\n",
    "    parts = [f\"{i+1}:{n}={(-F_row[i] if n!='installation_cost' else F_row[i]):.2f}\" if n!='coverage' else f\"{i+1}:{n}={-F_row[i]:.2f}\" for i,n in enumerate(obj_names)]\n",
    "    return f\"{rank:>3d} | \" + \" | \".join(parts)\n",
    "\n",
    "def _refresh_feasible_dropdown():\n",
    "    if _last_nsga_store[\"idxs_list\"] is None:\n",
    "        feasible_dropdown.options = [(\"— run NSGA-III to populate —\", -1)]\n",
    "        feasible_dropdown.value = -1\n",
    "        return\n",
    "    order = _last_nsga_store[\"rank_order\"]\n",
    "    F = _last_nsga_store[\"F\"]\n",
    "    names = _last_nsga_store[\"objective_names\"]\n",
    "    opts = []\n",
    "    for r, idx_in_feasible in enumerate(order, start=1):\n",
    "        label = _format_dropdown_label(r, F[idx_in_feasible], names)\n",
    "        opts.append((label, int(idx_in_feasible)))\n",
    "    feasible_dropdown.options = opts\n",
    "    feasible_dropdown.value = order[0] if len(order) > 0 else -1\n",
    "\n",
    "def _draw_solution_by_feasible_index(idx_in_feasible):\n",
    "    map_out.clear_output()\n",
    "    if _last_nsga_store[\"idxs_list\"] is None or idx_in_feasible is None or idx_in_feasible == -1:\n",
    "        return\n",
    "    idxs = _last_nsga_store[\"idxs_list\"][idx_in_feasible]\n",
    "    records = _solution_records_from_idxs(idxs)\n",
    "    with map_out:\n",
    "        display(HTML(f\"<b>Preview (NSGA feasible #{_last_nsga_store['rank_order'].tolist().index(idx_in_feasible)+1}) — not adopted</b>\"))\n",
    "        display(plot_gateways_on_map(aoi_poly, records, color=\"lime\"))\n",
    "\n",
    "def _on_dropdown_change(change):\n",
    "    if change['name'] == 'value':\n",
    "        _draw_solution_by_feasible_index(change['new'])\n",
    "\n",
    "feasible_dropdown.observe(_on_dropdown_change, names='value')\n",
    "\n",
    "def on_run_clicked(b):\n",
    "    global saved_solutions, solution_counter, _last_nsga_store, _last_mip_records\n",
    "    output.clear_output()\n",
    "    map_out.clear_output()\n",
    "    adopt_mip_btn.disabled = True\n",
    "    _last_mip_records = None\n",
    "\n",
    "    with output:\n",
    "        method = optimization_method.value\n",
    "        weights = get_current_weights()\n",
    "        num_gateways = num_gateways_slider.value\n",
    "        min_sep = float(min_separation.value)\n",
    "\n",
    "        if gateway_candidate_df is None or gateway_candidate_df.empty:\n",
    "            print(\" Candidate DataFrame not loaded. Run precomputation first.\")\n",
    "            return\n",
    "\n",
    "        print(f\" Running optimization: method={method}, gateways={num_gateways}, min_separation={int(min_sep)}m\")\n",
    "\n",
    "        if method == 'mip':\n",
    "            res = solve_gateway_placement_mip(\n",
    "                gateway_candidate_df, num_gateways, weights, min_separation_m=min_sep, solver=get_solver()\n",
    "            )\n",
    "            if res and res['solution']:\n",
    "                solution_counter += 1\n",
    "                solution_name = f\"Solution_{solution_counter}_{num_gateways}GW\"\n",
    "                saved_solutions[solution_name] = res\n",
    "                print(f\" Solution saved: {solution_name}\")\n",
    "                dfsol = pd.DataFrame(res['solution'])\n",
    "                display(dfsol)\n",
    "\n",
    "                # Preview map (NOT adopted)\n",
    "                map_out.clear_output()\n",
    "                with map_out:\n",
    "                    display(HTML(\"<b>Preview (MIP): not adopted</b>\"))\n",
    "                    display(plot_gateways_on_map(aoi_poly, res['solution'], color=\"orange\"))\n",
    "\n",
    "                # Enable adopt\n",
    "                _last_mip_records = res['solution']\n",
    "                adopt_mip_btn.disabled = False\n",
    "\n",
    "                # Clear NSGA browser since we didn't run it\n",
    "                _last_nsga_store = {k: None for k in _last_nsga_store}\n",
    "                _refresh_feasible_dropdown()\n",
    "            else:\n",
    "                print(f\"Optimization failed: {res.get('status')}\")\n",
    "            return\n",
    "\n",
    "        # ===== NSGA-III path (fast with masks) =====\n",
    "        from pymoo.core.problem import Problem\n",
    "        from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "        from pymoo.util.ref_dirs import get_reference_directions\n",
    "        from pymoo.optimize import minimize\n",
    "        from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "        import time\n",
    "\n",
    "        selected_objs = list(nsga_obj_select.value)\n",
    "        if len(selected_objs) < 2:\n",
    "            print(\" Please select at least 2 objectives for multi-objective optimization\")\n",
    "            return\n",
    "\n",
    "        print(f\"📊 Selected objectives: {', '.join(selected_objs)}\")\n",
    "\n",
    "        # Ensure masks & distances exist (one-time build)\n",
    "        ensure_precomputed_masks()\n",
    "\n",
    "        # Configure NSGA-III params\n",
    "        if len(selected_objs) == 2:\n",
    "            n_partitions = 12\n",
    "        elif len(selected_objs) == 3:\n",
    "            n_partitions = 8\n",
    "        else:\n",
    "            n_partitions = 5\n",
    "\n",
    "        ref_dirs = get_reference_directions(\"das-dennis\", len(selected_objs), n_partitions=n_partitions)\n",
    "        print(f\"🔧 NSGA-III Configuration:\")\n",
    "        print(f\"   Reference directions: {len(ref_dirs)}\")\n",
    "        print(f\"   Population size: {len(ref_dirs)}\")\n",
    "\n",
    "        class GatewayPlacementProblem(Problem):\n",
    "            def __init__(self, candidate_df, n_gateways, min_separation_m,\n",
    "                         objectives, coverage_masks, pairwise_dist):\n",
    "                self.candidate_df = candidate_df.reset_index(drop=True)\n",
    "                self.n_gateways = n_gateways\n",
    "                self.min_separation_m = float(min_separation_m)\n",
    "                self.objectives = objectives\n",
    "                self.coverage_masks = coverage_masks      # [N, G] bool\n",
    "                self.pairwise_dist = pairwise_dist        # [N, N] float\n",
    "\n",
    "                n_constraints = int(n_gateways * (n_gateways - 1) / 2) if n_gateways > 1 else 1\n",
    "                super().__init__(n_var=n_gateways, n_obj=len(objectives), n_constr=n_constraints,\n",
    "                                 xl=0, xu=len(self.candidate_df) - 1, elementwise_evaluation=False, vtype=int)\n",
    "\n",
    "            def compute_union_coverage(self, idxs):\n",
    "                union = self.coverage_masks[idxs].any(axis=0)\n",
    "                return float(union.mean() * 100.0)\n",
    "\n",
    "            def _evaluate(self, X, out, *args, **kwargs):\n",
    "                n_solutions = X.shape[0]\n",
    "                F = np.zeros((n_solutions, len(self.objectives)))\n",
    "                G = []\n",
    "\n",
    "                for i in range(n_solutions):\n",
    "                    idxs = [int(k) for k in X[i]]\n",
    "\n",
    "                    # duplicates → hard penalty\n",
    "                    if len(set(idxs)) != len(idxs):\n",
    "                        F[i, :] = 1e10\n",
    "                        G.append([1e10] * self.n_constr)\n",
    "                        continue\n",
    "\n",
    "                    gw = self.candidate_df.iloc[idxs]\n",
    "\n",
    "                    # objectives\n",
    "                    for j, obj in enumerate(self.objectives):\n",
    "                        if obj == 'coverage':\n",
    "                            cov = self.compute_union_coverage(idxs)\n",
    "                            F[i, j] = -cov                        # maximize\n",
    "                        elif obj == 'installation_cost':\n",
    "                            F[i, j] = float(np.sum(gw[obj])) if obj in gw.columns else 0.0  # minimize\n",
    "                        elif obj in gw.columns:\n",
    "                            F[i, j] = -float(np.mean(gw[obj]))     # maximize others\n",
    "                        else:\n",
    "                            F[i, j] = 0.0\n",
    "\n",
    "                    # min-sep constraints via precomputed distances\n",
    "                    if self.n_gateways > 1:\n",
    "                        cons = []\n",
    "                        for a in range(len(idxs)):\n",
    "                            for b in range(a+1, len(idxs)):\n",
    "                                d = self.pairwise_dist[idxs[a], idxs[b]]\n",
    "                                cons.append(max(0.0, self.min_separation_m - d))\n",
    "                        G.append(cons)\n",
    "                    else:\n",
    "                        G.append([0.0])\n",
    "\n",
    "                out[\"F\"] = F\n",
    "                out[\"G\"] = np.array(G)\n",
    "\n",
    "        # Build problem\n",
    "        problem = GatewayPlacementProblem(\n",
    "            candidate_df=gateway_candidate_df,\n",
    "            n_gateways=num_gateways,\n",
    "            min_separation_m=min_sep,\n",
    "            objectives=selected_objs,\n",
    "            coverage_masks=COVERAGE_MASKS,\n",
    "            pairwise_dist=PAIRWISE_DIST\n",
    "        )\n",
    "\n",
    "        # Algorithm/termination (lean while testing; you can scale back up)\n",
    "        algorithm = NSGA3(\n",
    "            ref_dirs=ref_dirs,\n",
    "            pop_size=len(ref_dirs),\n",
    "            eliminate_duplicates=True\n",
    "        )\n",
    "        termination = DefaultMultiObjectiveTermination(\n",
    "            xtol=1e-8, cvtol=1e-6, ftol=0.005, period=20, n_max_gen=100\n",
    "        )\n",
    "\n",
    "        # Run\n",
    "        print(\"🏃 Running NSGA-III optimization...\")\n",
    "        start_time = time.time()\n",
    "        res = minimize(problem, algorithm, termination=termination,\n",
    "                       seed=42, verbose=True, save_history=True)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\" Optimization completed in {elapsed:.1f} seconds\")\n",
    "\n",
    "        # Feasible set by constraint violation\n",
    "        if res.G is not None:\n",
    "            max_violation = np.max(res.G, axis=1)\n",
    "            feasible_idx = np.where(max_violation <= 1.0)[0]\n",
    "            if len(feasible_idx) == 0:\n",
    "                print(\"No feasible solutions found. Relaxing constraints (10% violation)...\")\n",
    "                feasible_idx = np.where(max_violation <= min_sep * 0.1)[0]\n",
    "                if len(feasible_idx) == 0:\n",
    "                    print(\"Still no feasible solutions. Try reducing min separation or adjusting objectives.\")\n",
    "                    _last_nsga_store = {k: None for k in _last_nsga_store}\n",
    "                    _refresh_feasible_dropdown()\n",
    "                    return\n",
    "        else:\n",
    "            feasible_idx = np.arange(len(res.X))\n",
    "\n",
    "        print(f\"✅ Found {len(feasible_idx)} feasible solutions\")\n",
    "\n",
    "        feasible_F = res.F[feasible_idx]\n",
    "        feasible_X = res.X[feasible_idx]\n",
    "\n",
    "        # Rank feasible solutions by distance to ideal (normalized)\n",
    "        rank_order, dvals = _rank_feasible(feasible_F)\n",
    "\n",
    "        # Store for browser (preview via dropdown, no auto-adopt/auto-map)\n",
    "        _last_nsga_store = {\n",
    "            \"idxs_list\": [feasible_X[i] for i in range(len(feasible_X))],\n",
    "            \"F\": feasible_F,\n",
    "            \"rank_order\": rank_order,\n",
    "            \"objective_names\": tuple(selected_objs),\n",
    "            \"num_gateways\": num_gateways,\n",
    "            \"min_sep\": min_sep,\n",
    "            \"selected_objs\": tuple(selected_objs)\n",
    "        }\n",
    "        # Reset CURRENT_* until user adopts\n",
    "        global CURRENT_SOLUTION, CURRENT_SOLUTION_INDEXES\n",
    "        CURRENT_SOLUTION = None\n",
    "        CURRENT_SOLUTION_INDEXES = None\n",
    "\n",
    "        _refresh_feasible_dropdown()\n",
    "\n",
    "        # Save the \"closest to ideal\" into saved_solutions (for record), but DO NOT adopt/plot automatically\n",
    "        best_idx_in_feasible = rank_order[0] if len(rank_order) > 0 else 0\n",
    "        best_X = feasible_X[best_idx_in_feasible]\n",
    "        best_F = feasible_F[best_idx_in_feasible]\n",
    "        idxs = [int(i) for i in best_X]\n",
    "        solution_gateways = gateway_candidate_df.iloc[idxs].to_dict('records')\n",
    "\n",
    "        def union_cov_from_idxs(idxs):\n",
    "            return float(COVERAGE_MASKS[idxs].any(axis=0).mean() * 100.0)\n",
    "        actual_coverage = union_cov_from_idxs(idxs)\n",
    "\n",
    "        solution_summary = {\n",
    "            'solution': solution_gateways,\n",
    "            'method': 'NSGA-III',\n",
    "            'selected_objectives': selected_objs,\n",
    "            'num_gateways': num_gateways,\n",
    "            'actual_coverage': actual_coverage,\n",
    "            'objective_values': {}\n",
    "        }\n",
    "        for i, obj in enumerate(selected_objs):\n",
    "            if obj == 'coverage':\n",
    "                solution_summary['objective_values'][obj] = actual_coverage\n",
    "            else:\n",
    "                solution_summary['objective_values'][obj] = -best_F[i] if best_F[i] < 0 else best_F[i]\n",
    "\n",
    "        solution_counter += 1\n",
    "        solution_name = f\"Solution_{solution_counter}_{num_gateways}GW_NSGA3\"\n",
    "        saved_solutions[solution_name] = solution_summary\n",
    "\n",
    "        print(f\"\\nNSGA-III run complete. Browse the feasible dropdown above, then click 'Adopt Selected Feasible' to set CURRENT_SOLUTION.\")\n",
    "        display(pd.DataFrame(solution_gateways)[['coord', 'elevation', 'coverage', 'solar']])\n",
    "\n",
    "# Wire up button\n",
    "run_btn.on_click(on_run_clicked)\n",
    "\n",
    "# ======== Compose UI =========\n",
    "print(\"Candidate DataFrame size:\", 0 if gateway_candidate_df is None else len(gateway_candidate_df))\n",
    "if gateway_candidate_df is not None and not gateway_candidate_df.empty:\n",
    "    cols_to_show = [c for c in ['coverage','solar','elevation','centrality','accessibility','installation_cost','terrain_suitability','valley_coverage'] if c in gateway_candidate_df.columns]\n",
    "    if cols_to_show:\n",
    "        print(gateway_candidate_df[cols_to_show].describe())\n",
    "\n",
    "ui = VBox([\n",
    "    HBox([preset_dropdown, optimization_method]),\n",
    "    HBox([w_coverage, w_solar, w_accessibility, w_install_cost]),\n",
    "    HBox([w_terrain, w_valley, w_elevation, w_centrality]),\n",
    "    HBox([num_gateways_slider, min_separation, run_btn]),\n",
    "    HBox([nsga_obj_select]),\n",
    "    Output(),                                # spacer\n",
    "    HBox([feasible_dropdown, adopt_btn, adopt_mip_btn]),  # both adopt buttons\n",
    "    adopt_msg,\n",
    "    map_out,                                 # map area (single place to preview)\n",
    "    output                                   # logs\n",
    "])\n",
    "display(HTML(\"<h3>Phase 1: Gateway Multi-Objective Optimization</h3>\"))\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab367827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Poster tradeoffs (Coverage, Solar, Elevation) — separate figs\n",
    "# - Uses _last_nsga_store (feasible solutions) + gateway_candidate_df\n",
    "# - Computes pairwise Pareto fronts (max/max) and draws a connected curve\n",
    "# - Highlights CURRENT_SOLUTION if adopted; otherwise closest-to-ideal\n",
    "# - Legends sit inside each axis \n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 15,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 19,\n",
    "    \"legend.fontsize\": 13,\n",
    "    \"figure.figsize\": (9.5, 7),\n",
    "    \"axes.titlepad\": 15\n",
    "})\n",
    "\n",
    "def _infer_selected_index_from_current_store(store, current_idxs):\n",
    "    if not store or store.get(\"idxs_list\") is None or current_idxs is None:\n",
    "        return None\n",
    "    target = tuple(sorted(map(int, current_idxs)))\n",
    "    for i, xs in enumerate(store[\"idxs_list\"]):\n",
    "        try:\n",
    "            if tuple(sorted(map(int, xs))) == target:\n",
    "                return i\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def _safe_mkdir(path):\n",
    "    try:\n",
    "        if path:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            return path\n",
    "    except OSError:\n",
    "        pass\n",
    "    return \".\"\n",
    "\n",
    "def _safe_savefig(path, dpi=300):\n",
    "    try:\n",
    "        plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(f\"saved: {path}\")\n",
    "    except OSError:\n",
    "        # fallback to cwd\n",
    "        fname = os.path.basename(path)\n",
    "        alt = os.path.join(\".\", fname)\n",
    "        plt.savefig(alt, dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(f\"saved (fallback): {alt}\")\n",
    "\n",
    "def _pareto_front_2d(x, y):\n",
    "    \"\"\"Indices of 2D Pareto front for maximize/maximize.\"\"\"\n",
    "    # Sort by x descending, then keep running max of y\n",
    "    order = np.argsort(-x, kind=\"mergesort\")\n",
    "    best_y = -np.inf\n",
    "    front = []\n",
    "    for i in order:\n",
    "        if y[i] >= best_y - 1e-12:\n",
    "            front.append(i)\n",
    "            best_y = max(best_y, y[i])\n",
    "    # sort the front by x ascending for a nice left→right curve\n",
    "    front = np.array(front, dtype=int)\n",
    "    return front[np.argsort(x[front])]\n",
    "\n",
    "def _closest_to_ideal(xcols):\n",
    "    \"\"\"Return index of point closest to ideal (all columns max), after [0,1] norm.\"\"\"\n",
    "    X = np.column_stack(xcols).astype(float)\n",
    "    # normalize each column 0..1 (avoid div/0)\n",
    "    mins = X.min(axis=0)\n",
    "    maxs = X.max(axis=0)\n",
    "    rng  = np.maximum(maxs - mins, 1e-12)\n",
    "    Xn   = (X - mins) / rng\n",
    "    d    = np.linalg.norm(1.0 - Xn, axis=1)\n",
    "    return int(np.argmin(d))\n",
    "\n",
    "def _get_feasible_summaries():\n",
    "    \"\"\"\n",
    "    Build a DataFrame with one row per feasible solution:\n",
    "      coverage_pct, solar_mean, elevation_mean\n",
    "    coverage uses COVERAGE_MASKS union; solar/elevation are means of gateways in that solution.\n",
    "    \"\"\"\n",
    "    if \"_last_nsga_store\" not in globals() or _last_nsga_store.get(\"idxs_list\") is None:\n",
    "        raise RuntimeError(\"No NSGA results in _last_nsga_store. Run Phase 1 first.\")\n",
    "    if \"gateway_candidate_df\" not in globals():\n",
    "        raise RuntimeError(\"gateway_candidate_df is missing.\")\n",
    "\n",
    "    idxs_list = _last_nsga_store[\"idxs_list\"]\n",
    "    cand = gateway_candidate_df  # precomputed per-candidate metrics\n",
    "\n",
    "    # Coverage via masks if available; else try to reconstruct from F if present\n",
    "    masks = globals().get(\"COVERAGE_MASKS\", None)\n",
    "    have_masks = isinstance(masks, np.ndarray)\n",
    "\n",
    "    rows = []\n",
    "    for i, idxs in enumerate(idxs_list):\n",
    "        idxs = list(map(int, idxs))\n",
    "        # coverage\n",
    "        if have_masks:\n",
    "            cov = float(masks[idxs].any(axis=0).mean() * 100.0)\n",
    "        else:\n",
    "            # fallback: if coverage objective was used in F, recover it\n",
    "            cov = None\n",
    "            names = _last_nsga_store.get(\"objective_names\", [])\n",
    "            if names and \"coverage\" in names:\n",
    "                j = list(names).index(\"coverage\")\n",
    "                cov = -float(_last_nsga_store[\"F\"][i, j])  # stored negative for max\n",
    "        # solar/elevation means\n",
    "        sol = float(cand.iloc[idxs][\"solar\"].mean()) if \"solar\" in cand.columns else np.nan\n",
    "        elev = float(cand.iloc[idxs][\"elevation\"].mean()) if \"elevation\" in cand.columns else np.nan\n",
    "        rows.append({\"coverage_pct\": cov, \"solar_mean\": sol, \"elevation_mean\": elev})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # normalize solar & elevation for clean axes\n",
    "    for col in [\"solar_mean\", \"elevation_mean\"]:\n",
    "        v = df[col].to_numpy(dtype=float)\n",
    "        vmin, vmax = np.nanmin(v), np.nanmax(v)\n",
    "        df[col + \"_norm\"] = (v - vmin) / max(vmax - vmin, 1e-12)\n",
    "    return df\n",
    "\n",
    "def _selected_feasible_index(df):\n",
    "    \"\"\"Prefer the adopted feasible; otherwise, closest to ideal across the three metrics.\"\"\"\n",
    "    # try adopted\n",
    "    sel = _infer_selected_index_from_current_store(_last_nsga_store, globals().get(\"CURRENT_SOLUTION_INDEXES\", None))\n",
    "    if sel is not None:\n",
    "        return int(sel)\n",
    "    # else closest-to-ideal using normalized triplet\n",
    "    return _closest_to_ideal([df[\"coverage_pct\"].to_numpy(),\n",
    "                              df[\"solar_mean_norm\"].to_numpy(),\n",
    "                              df[\"elevation_mean_norm\"].to_numpy()])\n",
    "\n",
    "def _plot_pair(fig_title, x, y, xlab, ylab, selected_idx, save_path=None, dpi=300):\n",
    "    \"\"\"Single poster-ready chart with dominated vs Pareto, curve, and star.\"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    # pareto front for this pair (max/max)\n",
    "    pf_idx = _pareto_front_2d(x, y)\n",
    "    dom_mask = np.ones_like(x, dtype=bool)\n",
    "    dom_mask[pf_idx] = False\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9.5, 7))\n",
    "\n",
    "    # dominated points\n",
    "    ax.scatter(x[dom_mask], y[dom_mask],\n",
    "               s=50, c=\"#3b66b2\", edgecolors=\"#3B75AE\", linewidth=0.6, label=\"Dominated\", zorder=1)\n",
    "\n",
    "    # pareto points\n",
    "    ax.scatter(x[pf_idx], y[pf_idx],\n",
    "               s=90, c=\"#d21f3c\", marker=\"D\", edgecolors=\"#7a0f22\", linewidth=1.2, label=f\"Pareto ({len(pf_idx)})\", zorder=3)\n",
    "\n",
    "    # connected pareto curve (sorted by x)\n",
    "    order = np.argsort(x[pf_idx])\n",
    "    ax.plot(x[pf_idx][order], y[pf_idx][order], \"-\", lw=2.0, color=\"#8b192e\", alpha=0.9, label=\"Pareto curve\", zorder=2)\n",
    "\n",
    "    # selected solution\n",
    "    ax.scatter(x[selected_idx], y[selected_idx],\n",
    "               s=300, marker=\"*\", c=\"#ffcc00\", edgecolors=\"#333\", linewidth=1.2, label=\"Selected\", zorder=4)\n",
    "\n",
    "    # cosmetics\n",
    "    ax.set_title(fig_title, pad=14, fontweight=\"bold\")\n",
    "    ax.set_xlabel(xlab, fontweight=\"bold\")\n",
    "    ax.set_ylabel(ylab, fontweight=\"bold\")\n",
    "    ax.grid(True, alpha=0.25, ls=\"--\", lw=0.7)\n",
    "\n",
    "    # legend inside axis to avoid title overlap\n",
    "    ax.legend(loc=\"lower right\", framealpha=0.96)\n",
    "\n",
    "    # padded limits\n",
    "    xm, xM = np.nanmin(x), np.nanmax(x)\n",
    "    ym, yM = np.nanmin(y), np.nanmax(y)\n",
    "    ax.set_xlim(xm - 0.05*(xM - xm + 1e-9), xM + 0.05*(xM - xm + 1e-9))\n",
    "    ax.set_ylim(ym - 0.05*(yM - ym + 1e-9), yM + 0.05*(yM - ym + 1e-9))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        _safe_savefig(save_path, dpi=dpi)\n",
    "    plt.show()\n",
    "\n",
    "def poster_tradeoffs_coverage_solar_elev(save_dir=\"./figs\", dpi=300):\n",
    "    # build the summaries\n",
    "    df = _get_feasible_summaries()\n",
    "    if df.empty:\n",
    "        print(\"No feasible solutions to plot.\")\n",
    "        return\n",
    "\n",
    "    # pick the point to star\n",
    "    selected_idx = _selected_feasible_index(df)\n",
    "    print(f\"⭐ selected feasible index: {selected_idx}\")\n",
    "\n",
    "    # ensure writable directory (fallback handled inside)\n",
    "    save_dir = _safe_mkdir(save_dir)\n",
    "\n",
    "    # 1) Coverage vs Solar\n",
    "    _plot_pair(\n",
    "        fig_title=\"Coverage vs Solar (NSGA-III Feasible Set)\",\n",
    "        x=df[\"coverage_pct\"].to_numpy(),\n",
    "        y=df[\"solar_mean_norm\"].to_numpy(),\n",
    "        xlab=\"Coverage (%)\",\n",
    "        ylab=\"Solar (normalized 0–1)\",\n",
    "        selected_idx=selected_idx,\n",
    "        save_path=os.path.join(save_dir, \"poster_tradeoff_coverage_vs_solar.png\"),\n",
    "        dpi=dpi\n",
    "    )\n",
    "\n",
    "    # 2) Coverage vs Elevation\n",
    "    _plot_pair(\n",
    "        fig_title=\"Coverage vs Elevation (NSGA-III Feasible Set)\",\n",
    "        x=df[\"coverage_pct\"].to_numpy(),\n",
    "        y=df[\"elevation_mean_norm\"].to_numpy(),\n",
    "        xlab=\"Coverage (%)\",\n",
    "        ylab=\"Elevation (normalized 0–1)\",\n",
    "        selected_idx=selected_idx,\n",
    "        save_path=os.path.join(save_dir, \"poster_tradeoff_coverage_vs_elevation.png\"),\n",
    "        dpi=dpi\n",
    "    )\n",
    "\n",
    "    # 3) Solar vs Elevation\n",
    "    _plot_pair(\n",
    "        fig_title=\"Solar vs Elevation (NSGA-III Feasible Set)\",\n",
    "        x=df[\"solar_mean_norm\"].to_numpy(),\n",
    "        y=df[\"elevation_mean_norm\"].to_numpy(),\n",
    "        xlab=\"Solar (normalized 0–1)\",\n",
    "        ylab=\"Elevation (normalized 0–1)\",\n",
    "        selected_idx=selected_idx,\n",
    "        save_path=os.path.join(save_dir, \"poster_tradeoff_solar_vs_elevation.png\"),\n",
    "        dpi=dpi\n",
    "    )\n",
    "\n",
    "# ---- Run it (creates ./figs and saves PNGs there) ----\n",
    "poster_tradeoffs_coverage_solar_elev(save_dir=\"./figs\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79348611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, CircleMarker, GeoJSON, basemaps, LayerGroup\n",
    "from ipywidgets import HTML, VBox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gateways_on_map(aoi_poly, gateway_solution, label_prefix=\"Gateway\", color='red'):\n",
    "    \"\"\"\n",
    "    Visualize selected gateway locations on an ipyleaflet map.\n",
    "    Args:\n",
    "        aoi_poly: Shapely Polygon (AOI boundary)\n",
    "        gateway_solution: list of dicts, each with at least {'coord': (lon, lat)}\n",
    "        label_prefix: Marker label prefix (default \"Gateway\")\n",
    "        color: Marker color (default 'red')\n",
    "    Returns:\n",
    "        ipyleaflet Map widget\n",
    "    \"\"\"\n",
    "    m = Map(\n",
    "        center=(aoi_poly.centroid.y, aoi_poly.centroid.x),\n",
    "        zoom=13,\n",
    "        basemap=basemaps.Esri.WorldImagery\n",
    "    )\n",
    "    m.add_layer(GeoJSON(data=aoi_poly.__geo_interface__, style={\n",
    "        'color': 'yellow', 'fillOpacity': 0.1, 'weight': 3\n",
    "    }))\n",
    "\n",
    "    # Add gateway markers\n",
    "    solution_sorted = sort_gateways(gateway_solution, sort_by=\"lon\")\n",
    "    for idx, gw in enumerate(solution_sorted):\n",
    "        lat, lon = gw['coord'][1], gw['coord'][0]\n",
    "        popup_html = f\"<b>{label_prefix} {idx+1}</b><br>Lon: {lon:.5f}<br>Lat: {lat:.5f}\"\n",
    "        # Add more attributes from gw as needed, e.g., coverage, elevation, solar, accessibility, installation cost, terrain suitability, valley coverage, centrality\n",
    "        if 'coverage' in gw: popup_html += f\"<br>Coverage: {gw['coverage']:.1f}%\"\n",
    "        if 'elevation' in gw: popup_html += f\"<br>Elevation: {gw['elevation']:.1f}m\"\n",
    "        if 'solar' in gw: popup_html += f\"<br>Solar: {gw['solar']:.2f}\"\n",
    "        if 'accessibility' in gw: popup_html += f\"<br>Accessibility: {gw['accessibility']:.2f}\"\n",
    "        if 'installation_cost' in gw: popup_html += f\"<br>Install Cost: {gw['installation_cost']:.2f}\"\n",
    "        if 'terrain_suitability' in gw: popup_html += f\"<br>Terrain Suitability: {gw['terrain_suitability']:.2f}\"\n",
    "        if 'valley_coverage' in gw: popup_html += f\"<br>Valley Coverage: {gw['valley_coverage']:.2f}\"\n",
    "        if 'centrality' in gw: popup_html += f\"<br>Centrality: {gw['centrality']:.2f}\"\n",
    "        marker = CircleMarker(\n",
    "            location=(lat, lon),\n",
    "            radius=8,\n",
    "            color=color,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.8,\n",
    "            popup=HTML(popup_html)\n",
    "        )\n",
    "        m.add_layer(marker)\n",
    "    return m\n",
    "\n",
    "# --- Usage Example ---\n",
    "solution = get_current_solution_or_raise()  # or use your actual variable from optimization\n",
    "solution_sorted = sort_gateways(solution, sort_by=\"lat\")\n",
    "display(plot_gateways_on_map(aoi_poly, solution, color=\"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd110a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from pyproj import Transformer\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import numpy as np\n",
    "\n",
    "# --- DEM grid creation ---\n",
    "dem_arr = dem_manager.dem_array\n",
    "nrows, ncols = dem_arr.shape\n",
    "minx, miny, maxx, maxy = dem_manager.bounds\n",
    "\n",
    "# Grid in lon, lat (as per DEM pixel organization)\n",
    "lons = np.linspace(minx, maxx, ncols)\n",
    "lats = np.linspace(miny, maxy, nrows)\n",
    "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "\n",
    "# Project grid to UTM\n",
    "utm_crs = \"EPSG:32611\"  # Use your zone!\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", utm_crs, always_xy=True)\n",
    "x_grid, y_grid = transformer.transform(lon_grid, lat_grid)\n",
    "\n",
    "# --- No flip for DEM or grid: Keep \"origin\" lower left (as expected by Plotly) ---\n",
    "# Plotly expects x/y axes to be increasing as in meshgrid (origin lower left).\n",
    "# So, do not flip the axes; just flip the DEM if your DEM is indexed from top.\n",
    "\n",
    "dem_arr_plot = np.flipud(dem_arr)   # This flip aligns DEM with meshgrid origin\n",
    "\n",
    "# --- Build axes for interpolator ---\n",
    "x_axis = x_grid[0, :]  # UTM X\n",
    "y_axis = y_grid[:, 0]  # UTM Y\n",
    "\n",
    "interp = RegularGridInterpolator(\n",
    "    (y_axis, x_axis),\n",
    "    dem_arr_plot,\n",
    "    bounds_error=False,\n",
    "    fill_value=None\n",
    ")\n",
    "\n",
    "# --- Prepare Gateway Points ---\n",
    "solution_sorted = sort_gateways(solution, sort_by=\"lat\")\n",
    "gw_xs, gw_ys, gw_zs = [], [], []\n",
    "for gw in solution_sorted:\n",
    "    lon, lat = gw['coord']\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "    gw_xs.append(x)\n",
    "    gw_ys.append(y)\n",
    "    gw_zs.append(interp((y, x)))\n",
    "\n",
    "# --- Plot 3D Surface ---\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid, y=y_grid, z=dem_arr_plot,\n",
    "    colorscale='earth', colorbar=dict(title=\"Elevation (m)\"),\n",
    "    showscale=True, opacity=0.96\n",
    "))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=gw_xs, y=gw_ys, z=np.array(gw_zs) + 15,  # Offset for visibility\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=10, color='red', symbol='circle'),\n",
    "    text=[f\"GW {i+1}\" for i in range(len(gw_xs))],\n",
    "    textposition='top center'\n",
    "))\n",
    "# Mark SW and NE corners\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[x_grid[0,0], x_grid[-1,-1]],\n",
    "    y=[y_grid[0,0], y_grid[-1,-1]],\n",
    "    z=[dem_arr_plot[0,0]+30, dem_arr_plot[-1,-1]+30],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=10, color=['green','blue']),\n",
    "    text=['SW', 'NE'],\n",
    "    textposition='bottom center'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"3D Gateway Placement on Terrain (UTM, North-Up, East Right, FINAL ORIENTATION)\",\n",
    "    scene=dict(\n",
    "        xaxis_title='UTM X (m)',\n",
    "        yaxis_title='UTM Y (m)',\n",
    "        zaxis_title='Elevation (m, exaggerated)',\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6954e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from pyproj import Transformer\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import numpy as np\n",
    "\n",
    "# --- DEM grid creation (as you had) ---\n",
    "dem_arr = dem_manager.dem_array\n",
    "nrows, ncols = dem_arr.shape\n",
    "minx, miny, maxx, maxy = dem_manager.bounds\n",
    "\n",
    "lons = np.linspace(minx, maxx, ncols)\n",
    "lats = np.linspace(miny, maxy, nrows)\n",
    "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "\n",
    "utm_crs = \"EPSG:32611\"\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", utm_crs, always_xy=True)\n",
    "x_grid, y_grid = transformer.transform(lon_grid, lat_grid)\n",
    "\n",
    "# Align DEM with mesh origin (lower-left)\n",
    "dem_arr_plot = np.flipud(dem_arr)\n",
    "\n",
    "# Axes for interpolation\n",
    "x_axis = x_grid[0, :]\n",
    "y_axis = y_grid[:, 0]\n",
    "\n",
    "interp = RegularGridInterpolator(\n",
    "    (y_axis, x_axis), dem_arr_plot, bounds_error=False, fill_value=None\n",
    ")\n",
    "\n",
    "# ---- Sanity printouts\n",
    "print(\"DEM elevation stats (m):\",\n",
    "      f\"min={np.nanmin(dem_arr):.1f}, max={np.nanmax(dem_arr):.1f}, \"\n",
    "      f\"range={np.nanmax(dem_arr)-np.nanmin(dem_arr):.1f}\")\n",
    "print(\"XY span (m):\",\n",
    "      f\"ΔE={x_axis[-1]-x_axis[0]:.0f}, ΔN={y_axis[-1]-y_axis[0]:.0f}\")\n",
    "\n",
    "# --- Gateways\n",
    "solution_sorted = sort_gateways(solution, sort_by=\"lat\")\n",
    "gw_xs, gw_ys, gw_zs = [], [], []\n",
    "for gw in solution_sorted:\n",
    "    lon, lat = gw['coord']\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "    gw_xs.append(x); gw_ys.append(y); gw_zs.append(interp((y, x)))\n",
    "\n",
    "gw_names = [f\"GW {i+1}\" for i in range(len(gw_xs))]\n",
    "\n",
    "# ---- Vertical exaggeration control (1.0 = true-to-scale)\n",
    "VE = 1.0\n",
    "Zsurf = dem_arr_plot * VE\n",
    "Zgw   = (np.array(gw_zs) + 10.0) * VE    # small lift for visibility\n",
    "\n",
    "# ---- Aspect ratio from data ranges (meters)\n",
    "xR = float(x_axis[-1] - x_axis[0])\n",
    "yR = float(y_axis[-1] - y_axis[0])\n",
    "zR = float(np.nanmax(dem_arr_plot) - np.nanmin(dem_arr_plot))\n",
    "maxR = max(xR, yR, zR if zR>0 else 1.0)\n",
    "aspect = dict(x=xR/maxR, y=yR/maxR, z=(zR*VE)/maxR)\n",
    "\n",
    "# ---- Figure\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid, y=y_grid, z=Zsurf,\n",
    "    colorscale='earth',\n",
    "    showscale=True,\n",
    "    colorbar=dict(title=\"Elevation (m)\", x=1.04, len=0.90, y=0.5),\n",
    "    opacity=0.98,\n",
    "    contours = dict(z=dict(show=True, width=1, color=\"rgba(255,255,255,0.6)\",\n",
    "                           highlight=True, project_z=True))\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=gw_xs, y=gw_ys, z=Zgw,\n",
    "    mode='markers+text',\n",
    "    name='Gateways',\n",
    "    marker=dict(size=8, color='crimson', symbol='circle', line=dict(width=1,color=\"#222\")),\n",
    "    text=gw_names,\n",
    "    textposition='top center',\n",
    "    textfont=dict(color='#111', size=11, family='Arial')\n",
    "))\n",
    "\n",
    "# Mark corners for orientation (optional, no legend)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=[x_grid[0,0], x_grid[-1,-1]],\n",
    "    y=[y_grid[0,0], y_grid[-1,-1]],\n",
    "    z=[Zsurf[0,0]+20*VE, Zsurf[-1,-1]+20*VE],\n",
    "    mode='markers+text',\n",
    "    showlegend=False,\n",
    "    marker=dict(size=6, color=['#2ecc71','#3498db']),\n",
    "    text=['SW','NE'],\n",
    "    textposition='bottom center'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"3D Gateway Placement on Terrain (UTM) — VE ×{VE:g}\",\n",
    "    margin=dict(l=10, r=80, b=10, t=60),\n",
    "    legend=dict(x=0.01, y=0.99, bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "                bordercolor=\"rgba(0,0,0,0.2)\", borderwidth=1),\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='UTM Easting (m)',  tickformat=',.0f'),\n",
    "        yaxis=dict(title='UTM Northing (m)', tickformat=',.0f'),\n",
    "        zaxis=dict(title=f'Elevation (m) · VE×{VE:g}', tickformat=',.0f'),\n",
    "        aspectmode='manual',\n",
    "        aspectratio=aspect,\n",
    "        camera=dict(eye=dict(x=1.6, y=1.9, z=0.7))  # natural oblique view\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb178116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DRAPE PATH-LOSS COVERAGE OVER *YOUR* 3D TERRAIN PLOT ===\n",
    "# Assumes the variables in your cell exist:\n",
    "#   dem_manager, x_grid, y_grid, lon_grid, lat_grid, dem_arr_plot,\n",
    "#   transformer, solution (list of {'coord': (lon,lat)}),\n",
    "#   COVERAGE_GRID (list of (lon,lat)), COVERAGE_MASKS (Ncandidates x Ngrid bool/0/1),\n",
    "#   CURRENT_SOLUTION_INDEXES (indexes of the chosen feasible gateways)\n",
    "#\n",
    "# If you don't have CURRENT_SOLUTION_INDEXES handy, see the fallback near the bottom.\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---------- 1) Build the same terrain figure you already use ----------\n",
    "solution_sorted = sort_gateways(solution, sort_by=\"lat\")\n",
    "\n",
    "# (gateway z's sampled from your DEM interpolator)\n",
    "gw_xs, gw_ys, gw_zs = [], [], []\n",
    "for gw in solution_sorted:\n",
    "    lon, lat = gw['coord']\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "    gw_xs.append(x)\n",
    "    gw_ys.append(y)\n",
    "    gw_zs.append(interp((y, x)))   # <- your RegularGridInterpolator on (y_axis, x_axis)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid, y=y_grid, z=dem_arr_plot,\n",
    "    colorscale='Earth', colorbar=dict(title=\"Elevation (m)\"),\n",
    "    showscale=True, opacity=0.96, name=\"Terrain\"\n",
    "))\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=np.array(gw_xs), y=np.array(gw_ys), z=np.array(gw_zs) + 15.0,\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=10, color='red', symbol='diamond'),\n",
    "    text=[f\"GW {i+1}\" for i in range(len(gw_xs))],\n",
    "    textposition='top center',\n",
    "    name=\"Gateways\"\n",
    "))\n",
    "\n",
    "# ---------- 2) Turn your coverage masks into a raster on (lon_grid, lat_grid) ----------\n",
    "# Pick which gateways define coverage: use the adopted NSGA-III indices if available\n",
    "try:\n",
    "    gw_idxs = np.asarray(CURRENT_SOLUTION_INDEXES, dtype=int)\n",
    "except NameError:\n",
    "    # Fallback: if you can map 'solution' rows to candidate indices, do that here.\n",
    "    # For now, use all masks as a harmless default (still produces a picture).\n",
    "    gw_idxs = np.arange(COVERAGE_MASKS.shape[0], dtype=int)\n",
    "\n",
    "# Per-grid-point coverage count from the chosen gateways\n",
    "counts = COVERAGE_MASKS[gw_idxs].sum(axis=0).astype(float)   # shape: [N_grid_points]\n",
    "cov_vals = counts / max(counts.max(), 1.0)                   # normalize 0..1\n",
    "\n",
    "# Coordinates of each coverage-sample point (lon/lat)\n",
    "cov_lon = np.array([p[0] for p in COVERAGE_GRID])\n",
    "cov_lat = np.array([p[1] for p in COVERAGE_GRID])\n",
    "\n",
    "# Rasterize the scattered coverage samples onto YOUR lon/lat grid\n",
    "cov_raster = griddata(\n",
    "    points=np.column_stack([cov_lon, cov_lat]),\n",
    "    values=cov_vals,\n",
    "    xi=(lon_grid, lat_grid),          # <- your existing lon/lat mesh\n",
    "    method=\"linear\",\n",
    "    fill_value=0.0\n",
    ")\n",
    "\n",
    "# Optional cosmetic blur so the drape looks smooth (does NOT change numbers)\n",
    "cov_raster = gaussian_filter(cov_raster, sigma=1.3)\n",
    "# Re-normalize to 0..1 for a clean colorbar\n",
    "mn, mx = float(np.nanmin(cov_raster)), float(np.nanmax(cov_raster))\n",
    "if mx > mn:\n",
    "    cov_raster = (cov_raster - mn) / (mx - mn)\n",
    "\n",
    "# ---------- 3) Add the coverage drape as a second surface (lifted slightly) ----------\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid, y=y_grid, z=dem_arr_plot + 0.6,          # small lift to avoid z-fighting\n",
    "    surfacecolor=cov_raster,\n",
    "    colorscale=\"Plasma\", cmin=0.0, cmax=1.0,\n",
    "    opacity=0.95, showscale=True,\n",
    "    colorbar=dict(title=\"Gateway Coverage (0–1)\"),\n",
    "    name=\"Coverage\"\n",
    "))\n",
    "\n",
    "# Optional subtle contours for shape cues (no hover)\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid, y=y_grid, z=dem_arr_plot + 0.2,\n",
    "    showscale=False, opacity=0.08, colorscale=\"Greys\",\n",
    "    contours=dict(z=dict(show=True, size=50, color=\"black\")),\n",
    "    hoverinfo=\"skip\",\n",
    "    name=\"Contours\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Terrain with Path-Loss Coverage Drape\",\n",
    "    scene=dict(\n",
    "        xaxis_title='UTM X (m)',\n",
    "        yaxis_title='UTM Y (m)',\n",
    "        zaxis_title='Elevation (m)',\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=48)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37318b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Per-Gateway / UNION Coverage Drape on YOUR 3D Terrain (with legend & tidy colorbars) ===\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import Dropdown, HBox\n",
    "from IPython.display import display\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "SHOW_TERRAIN_COLORBAR = False   # set True to show both colorbars (non-overlapping)\n",
    "\n",
    "def _mask_to_raster(mask_bool, lon_grid, lat_grid):\n",
    "    cov_lon = np.array([p[0] for p in COVERAGE_GRID])\n",
    "    cov_lat = np.array([p[1] for p in COVERAGE_GRID])\n",
    "    raster = griddata(\n",
    "        points=np.column_stack([cov_lon, cov_lat]),\n",
    "        values=mask_bool.astype(float),\n",
    "        xi=(lon_grid, lat_grid),\n",
    "        method=\"linear\",\n",
    "        fill_value=0.0\n",
    "    )\n",
    "    raster = gaussian_filter(raster, sigma=1.0)\n",
    "    mn, mx = float(np.nanmin(raster)), float(np.nanmax(raster))\n",
    "    if mx > mn:\n",
    "        raster = (raster - mn) / (mx - mn)\n",
    "    return raster\n",
    "\n",
    "if CURRENT_SOLUTION_INDEXES is None:\n",
    "    raise RuntimeError(\"Adopt a feasible solution first so CURRENT_SOLUTION_INDEXES is set.\")\n",
    "\n",
    "gw_candidate_idxs = list(map(int, CURRENT_SOLUTION_INDEXES))\n",
    "num_gw = len(gw_candidate_idxs)\n",
    "\n",
    "view_dd = Dropdown(\n",
    "    options=[(\"Single (binary)\", \"single\"),\n",
    "             (\"Single (exclusive)\", \"exclusive\"),\n",
    "             (\"All (union)\", \"union\")],\n",
    "    value=\"single\", description=\"View:\"\n",
    ")\n",
    "gw_dd = Dropdown(\n",
    "    options=[(f\"GW {i+1}\", i) for i in range(num_gw)],\n",
    "    value=0, description=\"Gateway:\"\n",
    ")\n",
    "\n",
    "def render(*_):\n",
    "    mode = view_dd.value\n",
    "\n",
    "    if mode == \"union\":\n",
    "        mask_union = COVERAGE_MASKS[gw_candidate_idxs].any(axis=0)\n",
    "        cov_pct = float(mask_union.mean() * 100.0)\n",
    "        cov_raster = _mask_to_raster(mask_union, lon_grid, lat_grid)\n",
    "        title_extra = f\"All GWs — union coverage: {cov_pct:.1f}%\"\n",
    "        sel_idx = None\n",
    "        mode_label = \"All (union)\"\n",
    "    else:\n",
    "        i_sel = gw_dd.value\n",
    "        sel_idx = i_sel\n",
    "        cand_idx = gw_candidate_idxs[i_sel]\n",
    "        mask_sel = COVERAGE_MASKS[cand_idx].astype(bool)\n",
    "\n",
    "        if mode == \"exclusive\" and num_gw > 1:\n",
    "            others = [idx for k, idx in enumerate(gw_candidate_idxs) if k != i_sel]\n",
    "            mask_others_any = COVERAGE_MASKS[others].any(axis=0)\n",
    "            mask_final = np.logical_and(mask_sel, np.logical_not(mask_others_any))\n",
    "            mode_suffix = \"exclusive\"\n",
    "        else:\n",
    "            mask_final = mask_sel\n",
    "            mode_suffix = \"binary\"\n",
    "\n",
    "        cov_pct = float(mask_sel.mean() * 100.0)\n",
    "        cov_excl_pct = float(mask_final.mean() * 100.0)\n",
    "        cov_raster = _mask_to_raster(mask_final, lon_grid, lat_grid)\n",
    "        title_extra = (f\"GW {i_sel+1} — covered: {cov_pct:.1f}%\"\n",
    "                       + (f\" | exclusive: {cov_excl_pct:.1f}%\" if mode_suffix == \"exclusive\" else \"\"))\n",
    "        mode_label = f\"GW {i_sel+1} ({mode_suffix})\"\n",
    "\n",
    "    # gateway marker coords (same DEM interp you used)\n",
    "    gw_xs, gw_ys, gw_zs = [], [], []\n",
    "    for gw in solution:\n",
    "        lon, lat = gw['coord']\n",
    "        x, y = transformer.transform(lon, lat)\n",
    "        gw_xs.append(x); gw_ys.append(y)\n",
    "        gw_zs.append(float(interp((y, x))) + 15.0)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # --- Terrain underlay ---\n",
    "    terrain_kwargs = dict(\n",
    "        x=x_grid, y=y_grid, z=dem_arr_plot,\n",
    "        colorscale='Earth', opacity=0.96, name=\"Terrain\",\n",
    "        showscale=SHOW_TERRAIN_COLORBAR\n",
    "    )\n",
    "    if SHOW_TERRAIN_COLORBAR:\n",
    "        terrain_kwargs[\"colorbar\"] = dict(title=\"Elevation (m)\", x=1.12, len=0.6)\n",
    "    fig.add_trace(go.Surface(**terrain_kwargs))\n",
    "\n",
    "    # --- Coverage drape ---\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=x_grid, y=y_grid, z=dem_arr_plot + 0.6,\n",
    "        surfacecolor=cov_raster,\n",
    "        colorscale=\"Plasma\", cmin=0.0, cmax=1.0,\n",
    "        opacity=0.95, showscale=True,\n",
    "        colorbar=dict(title=\"Coverage (0–1)\", x=1.0, len=0.6),\n",
    "        name=f\"Coverage — {mode_label}\"\n",
    "    ))\n",
    "\n",
    "    # --- Subtle contours for shape ---\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=x_grid, y=y_grid, z=dem_arr_plot + 0.2,\n",
    "        showscale=False, opacity=0.08, colorscale=\"Greys\",\n",
    "        contours=dict(z=dict(show=True, size=50, color=\"black\")),\n",
    "        hoverinfo=\"skip\", name=\"Contours\"\n",
    "    ))\n",
    "\n",
    "    # --- Legend: split gateways into 'Selected' and 'Others' ---\n",
    "    if sel_idx is not None:\n",
    "        # selected\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[gw_xs[sel_idx]], y=[gw_ys[sel_idx]], z=[gw_zs[sel_idx]],\n",
    "            mode=\"markers+text\",\n",
    "            marker=dict(size=10, color=\"red\", symbol=\"diamond\"),\n",
    "            text=[f\"GW {sel_idx+1}\"], textposition=\"top center\",\n",
    "            name=\"Selected GW\", showlegend=True\n",
    "        ))\n",
    "        # others\n",
    "        other_mask = [i for i in range(len(gw_xs)) if i != sel_idx]\n",
    "        if other_mask:\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=np.array(gw_xs)[other_mask], y=np.array(gw_ys)[other_mask], z=np.array(gw_zs)[other_mask],\n",
    "                mode=\"markers+text\",\n",
    "                marker=dict(size=10, color=\"rgba(100,100,100,0.9)\", symbol=\"diamond\"),\n",
    "                text=[f\"GW {i+1}\" for i in other_mask], textposition=\"top center\",\n",
    "                name=\"Other GWs\", showlegend=True\n",
    "            ))\n",
    "    else:\n",
    "        # union view: show all as red, one legend item\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=np.array(gw_xs), y=np.array(gw_ys), z=np.array(gw_zs),\n",
    "            mode=\"markers+text\",\n",
    "            marker=dict(size=10, color=\"red\", symbol=\"diamond\"),\n",
    "            text=[f\"GW {i+1}\" for i in range(len(gw_xs))], textposition=\"top center\",\n",
    "            name=\"Gateways (union)\", showlegend=True\n",
    "        ))\n",
    "\n",
    "    # --- Layout / legend / badge ---\n",
    "    fig.update_layout(\n",
    "        title=f\"Coverage Drape on Terrain — {title_extra}\",\n",
    "        scene=dict(\n",
    "            xaxis_title='UTM X (m)',\n",
    "            yaxis_title='UTM Y (m)',\n",
    "            zaxis_title='Elevation (m)',\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=60),\n",
    "        legend=dict(orientation=\"h\", x=0.02, y=0.02, bgcolor=\"rgba(255,255,255,0.6)\")\n",
    "    )\n",
    "\n",
    "    # small mode badge in the top-left\n",
    "    fig.add_annotation(\n",
    "        xref=\"paper\", yref=\"paper\", x=0.01, y=0.98,\n",
    "        text=f\"View: {mode_label}\", showarrow=False,\n",
    "        bgcolor=\"rgba(255,255,255,0.6)\", bordercolor=\"rgba(0,0,0,0.2)\", borderwidth=1\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def _toggle_vis(*_):\n",
    "    gw_dd.layout.display = \"none\" if view_dd.value == \"union\" else \"\"\n",
    "\n",
    "view_dd.observe(render, names=\"value\")\n",
    "gw_dd.observe(render, names=\"value\")\n",
    "view_dd.observe(_toggle_vis, names=\"value\")\n",
    "_toggle_vis()\n",
    "\n",
    "display(HBox([view_dd, gw_dd]))\n",
    "render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4797b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Per-Gateway / UNION Coverage Drape on YOUR 3D Terrain ===\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import Dropdown, Checkbox, HBox, VBox, HTML\n",
    "from IPython.display import display\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# --- helper: rasterize a boolean mask (at COVERAGE_GRID points) onto your lon/lat mesh\n",
    "def _mask_to_raster(mask_bool, lon_grid, lat_grid):\n",
    "    cov_lon = np.array([p[0] for p in COVERAGE_GRID])\n",
    "    cov_lat = np.array([p[1] for p in COVERAGE_GRID])\n",
    "    raster = griddata(\n",
    "        points=np.column_stack([cov_lon, cov_lat]),\n",
    "        values=mask_bool.astype(float),\n",
    "        xi=(lon_grid, lat_grid),\n",
    "        method=\"linear\",\n",
    "        fill_value=0.0\n",
    "    )\n",
    "    # cosmetic smoothing for nicer visuals (does not change “which cells”)\n",
    "    raster = gaussian_filter(raster, sigma=1.0)\n",
    "    # keep 0..1\n",
    "    mn, mx = float(np.nanmin(raster)), float(np.nanmax(raster))\n",
    "    if mx > mn:\n",
    "        raster = (raster - mn) / (mx - mn)\n",
    "    return raster\n",
    "\n",
    "if CURRENT_SOLUTION_INDEXES is None:\n",
    "    raise RuntimeError(\"Adopt a feasible solution first so CURRENT_SOLUTION_INDEXES is set.\")\n",
    "\n",
    "gw_candidate_idxs = list(map(int, CURRENT_SOLUTION_INDEXES))\n",
    "num_gw = len(gw_candidate_idxs)\n",
    "\n",
    "# --- widgets ---\n",
    "view_dd = Dropdown(\n",
    "    options=[(\"Single (binary)\", \"single\"),\n",
    "             (\"Single (exclusive)\", \"exclusive\"),\n",
    "             (\"All (union)\", \"union\")],\n",
    "    value=\"single\", description=\"View:\"\n",
    ")\n",
    "gw_dd = Dropdown(\n",
    "    options=[(f\"GW {i+1}\", i) for i in range(num_gw)],\n",
    "    value=0, description=\"Gateway:\"\n",
    ")\n",
    "\n",
    "def render(*_):\n",
    "    mode = view_dd.value\n",
    "\n",
    "    if mode == \"union\":\n",
    "        # union over all selected gateways\n",
    "        mask_union = COVERAGE_MASKS[gw_candidate_idxs].any(axis=0)\n",
    "        cov_pct = float(mask_union.mean() * 100.0)\n",
    "        cov_raster = _mask_to_raster(mask_union, lon_grid, lat_grid)\n",
    "        title_extra = f\"All GWs — union coverage: {cov_pct:.1f}%\"\n",
    "        # all markers red in union view\n",
    "        colors = [\"red\"] * len(solution)\n",
    "        sel_label = \"All (union)\"\n",
    "    else:\n",
    "        # single-GW views\n",
    "        i_sel = gw_dd.value  # 0..num_gw-1\n",
    "        cand_idx = gw_candidate_idxs[i_sel]\n",
    "        mask_sel = COVERAGE_MASKS[cand_idx].astype(bool)\n",
    "\n",
    "        if mode == \"exclusive\" and num_gw > 1:\n",
    "            others = [idx for k, idx in enumerate(gw_candidate_idxs) if k != i_sel]\n",
    "            mask_others_any = COVERAGE_MASKS[others].any(axis=0)\n",
    "            mask_final = np.logical_and(mask_sel, np.logical_not(mask_others_any))\n",
    "            mode_label = \"exclusive\"\n",
    "        else:\n",
    "            mask_final = mask_sel\n",
    "            mode_label = \"binary\"\n",
    "\n",
    "        cov_pct = float(mask_sel.mean() * 100.0)\n",
    "        cov_excl_pct = float(mask_final.mean() * 100.0)\n",
    "        cov_raster = _mask_to_raster(mask_final, lon_grid, lat_grid)\n",
    "        title_extra = (f\"GW {i_sel+1} — covered: {cov_pct:.1f}%\"\n",
    "                       + (f\" | exclusive: {cov_excl_pct:.1f}%\" if mode_label == \"exclusive\" else \"\"))\n",
    "        # highlight selected in red, others gray\n",
    "        colors = [\"rgba(100,100,100,0.9)\"] * len(solution)\n",
    "        colors[i_sel] = \"red\"\n",
    "        sel_label = f\"GW {i_sel+1} ({mode_label})\"\n",
    "\n",
    "    # --- build your terrain base & markers exactly like your elevation figure ---\n",
    "    gw_xs, gw_ys, gw_zs, labels = [], [], [], []\n",
    "    for k, gw in enumerate(solution):\n",
    "        lon, lat = gw['coord']\n",
    "        x, y = transformer.transform(lon, lat)\n",
    "        gw_xs.append(x); gw_ys.append(y)\n",
    "        gw_zs.append(float(interp((y, x))) + 15.0)  # your DEM interp + offset\n",
    "        labels.append(f\"GW {k+1}\")\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # terrain\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=x_grid, y=y_grid, z=dem_arr_plot,\n",
    "        colorscale='Earth', showscale=True,\n",
    "        colorbar=dict(title=\"Elevation (m)\"),\n",
    "        opacity=0.96, name=\"Terrain\"\n",
    "    ))\n",
    "\n",
    "    # coverage drape (union or single mask)\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=x_grid, y=y_grid, z=dem_arr_plot + 0.6,\n",
    "        surfacecolor=cov_raster,\n",
    "        colorscale=\"Plasma\", cmin=0.0, cmax=1.0,\n",
    "        opacity=0.95, showscale=True,\n",
    "        colorbar=dict(title=\"Coverage (0–1)\"),\n",
    "        name=f\"Coverage — {sel_label}\"\n",
    "    ))\n",
    "\n",
    "    # subtle contours\n",
    "    fig.add_trace(go.Surface(\n",
    "        x=x_grid, y=y_grid, z=dem_arr_plot + 0.2,\n",
    "        showscale=False, opacity=0.08, colorscale=\"Greys\",\n",
    "        contours=dict(z=dict(show=True, size=50, color=\"black\")),\n",
    "        hoverinfo=\"skip\", name=\"Contours\"\n",
    "    ))\n",
    "\n",
    "    # gateways\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=np.array(gw_xs), y=np.array(gw_ys), z=np.array(gw_zs),\n",
    "        mode=\"markers+text\",\n",
    "        marker=dict(size=10, color=colors, symbol=\"diamond\"),\n",
    "        text=labels, textposition=\"top center\",\n",
    "        name=\"Gateways\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Coverage Drape on Terrain — {title_extra}\",\n",
    "        scene=dict(\n",
    "            xaxis_title='UTM X (m)',\n",
    "            yaxis_title='UTM Y (m)',\n",
    "            zaxis_title='Elevation (m)',\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=60)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# wire up\n",
    "view_dd.observe(render, names=\"value\")\n",
    "gw_dd.observe(render, names=\"value\")\n",
    "\n",
    "# show controls (GW chooser hidden when union is selected—optional UX)\n",
    "def _toggle_vis(*_):\n",
    "    gw_dd.layout.display = \"none\" if view_dd.value == \"union\" else \"\"\n",
    "view_dd.observe(_toggle_vis, names=\"value\")\n",
    "_toggle_vis()\n",
    "\n",
    "display(HBox([view_dd, gw_dd]))\n",
    "render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import geodesic\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib\n",
    "\n",
    "# ===== Parameters =====\n",
    "NUM_CANDIDATES = 800\n",
    "SENSOR_HEIGHT = NETWORK.SENSOR_HEIGHT\n",
    "GATEWAY_HEIGHT = NETWORK.GATEWAY_HEIGHT\n",
    "PATHLOSS_THRESHOLD = OPTIMIZATION.MAX_ALLOWABLE_PATH_LOSS_DB\n",
    "\n",
    "# ===== Prepare Gateways =====\n",
    "try:\n",
    "    solution = get_current_solution_or_raise()  \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ {e}\")\n",
    "    raise\n",
    "\n",
    "solution_sorted = sort_gateways(solution, sort_by=\"lat\")\n",
    "gateways = [tuple(gw['coord']) for gw in solution_sorted]\n",
    "print(f\"Analyzing sensor connectivity to {len(gateways)} selected gateways.\")\n",
    "print(f\"Using pycraf loss_complete (ITU-R P.452-16) for accurate propagation modeling\")\n",
    "print(f\"Path loss threshold: {PATHLOSS_THRESHOLD} dB\")\n",
    "\n",
    "# ===== Random Points in AOI =====\n",
    "minx, miny, maxx, maxy = aoi_poly.bounds\n",
    "random_pts = []\n",
    "while len(random_pts) < NUM_CANDIDATES:\n",
    "    x, y = random.uniform(minx, maxx), random.uniform(miny, maxy)\n",
    "    if aoi_poly.contains(Point(x, y)):\n",
    "        random_pts.append((x, y))\n",
    "\n",
    "# ===== Helper: Sensor Candidate Analysis =====\n",
    "def analyze_sensor_candidate(\n",
    "    P, gateways, dem_manager, SENSOR_HEIGHT, GATEWAY_HEIGHT, PATHLOSS_THRESHOLD, NETWORK, pt_idx=None\n",
    "):\n",
    "    gateway_data = []\n",
    "    connectable_gateways = []\n",
    "    best = {\"gw\": -1, \"path_loss\": np.inf, \"dist\": None}\n",
    "    for idx, gw in enumerate(gateways):\n",
    "        pl = calculate_path_loss_pycraf(\n",
    "            p1=P, p2=gw,\n",
    "            dem_manager=dem_manager,\n",
    "            tx_h=SENSOR_HEIGHT,\n",
    "            rx_h=GATEWAY_HEIGHT,\n",
    "            freq_mhz=915.0,\n",
    "            veg_threshold=2.0,\n",
    "            attn_per_meter=0.0,\n",
    "            max_comm_range=NETWORK.MAX_COMM_RANGE_M\n",
    "        )\n",
    "        dist_m = geodesic(P[::-1], gw[::-1]).meters\n",
    "        # Debug for first 5 sensors (if requested)\n",
    "        if pt_idx is not None and pt_idx < 5:\n",
    "            print(f\"[S{pt_idx}→GW{idx}] PL={pl:.1f}dB, Dist={dist_m:.0f}m, \" +\n",
    "                  (\"✓ CONNECTED\" if pl <= PATHLOSS_THRESHOLD else \"✗ blocked\"))\n",
    "        gateway_data.append({\n",
    "            \"idx\": idx,\n",
    "            \"path_loss\": pl,\n",
    "            \"distance_m\": dist_m,\n",
    "            \"connectable\": pl <= PATHLOSS_THRESHOLD\n",
    "        })\n",
    "        if pl <= PATHLOSS_THRESHOLD:\n",
    "            connectable_gateways.append(idx)\n",
    "            if pl < best['path_loss']:\n",
    "                best = {\"gw\": idx, \"path_loss\": pl, \"dist\": dist_m}\n",
    "    elevation = dem_manager.get_elevation(P)\n",
    "    solar = calculate_solar_score(P, dem_manager)\n",
    "    return {\n",
    "        'Longitude': P[0], \n",
    "        'Latitude': P[1], \n",
    "        'Best_Gateway': best['gw'],\n",
    "        'Best_PathLoss_dB': best['path_loss'],\n",
    "        'Distance_m': best['dist'],\n",
    "        'Gateways_Details': gateway_data,\n",
    "        'Connectable_Gateways': connectable_gateways,\n",
    "        'Num_Connectable': len(connectable_gateways),\n",
    "        'Multi_Connected': len(connectable_gateways) > 1,\n",
    "        'Elevation': elevation,\n",
    "        'Solar': solar\n",
    "    }\n",
    "\n",
    "# ===== Debug: Serial for first 5 =====\n",
    "for pt_idx in range(min(5, NUM_CANDIDATES)):\n",
    "    _ = analyze_sensor_candidate(\n",
    "        random_pts[pt_idx],\n",
    "        gateways,\n",
    "        dem_manager,\n",
    "        SENSOR_HEIGHT,\n",
    "        GATEWAY_HEIGHT,\n",
    "        PATHLOSS_THRESHOLD,\n",
    "        NETWORK,\n",
    "        pt_idx\n",
    "    )\n",
    "\n",
    "# ======= PARALLELIZED SENSOR CANDIDATE ANALYSIS WITH TQDM PROGRESS BAR =======\n",
    "class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "    tqdm_bar = None\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if self.tqdm_bar is not None:\n",
    "            self.tqdm_bar.update(n=self.batch_size)\n",
    "        return super().__call__(*args, **kwargs)\n",
    "\n",
    "old_callback = joblib.parallel.BatchCompletionCallBack\n",
    "joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "\n",
    "try:\n",
    "    with tqdm(total=len(random_pts), desc=\"Sensor Candidates\", unit=\"sensor\") as bar:\n",
    "        TqdmBatchCompletionCallback.tqdm_bar = bar\n",
    "        results = Parallel(n_jobs=-1, backend='loky')(\n",
    "            delayed(analyze_sensor_candidate)(\n",
    "                P,\n",
    "                gateways,\n",
    "                dem_manager,\n",
    "                SENSOR_HEIGHT,\n",
    "                GATEWAY_HEIGHT,\n",
    "                PATHLOSS_THRESHOLD,\n",
    "                NETWORK\n",
    "                # pt_idx is not passed here to avoid print spam\n",
    "            )\n",
    "            for P in random_pts\n",
    "        )\n",
    "        TqdmBatchCompletionCallback.tqdm_bar = None\n",
    "finally:\n",
    "    joblib.parallel.BatchCompletionCallBack = old_callback\n",
    "\n",
    "print(\"\\nPath loss analysis complete using pycraf ITU-R P.452-16 model\")\n",
    "\n",
    "# ===== DATAFRAME + REPORT =====\n",
    "df = pd.DataFrame(results)\n",
    "df['Is_Connected'] = df['Num_Connectable'] > 0\n",
    "\n",
    "connected_sensors = df[df['Is_Connected']]\n",
    "multi_connected = df[df['Multi_Connected']]\n",
    "\n",
    "print(f\"\\nSensor Connectivity Report (using loss_complete):\")\n",
    "print(f\"   - Total candidates analyzed: {len(df)}\")\n",
    "print(f\"   - Connectable to at least one gateway: {len(connected_sensors)} ({len(connected_sensors)/len(df):.1%})\")\n",
    "print(f\"   - Multi-connected (redundant): {len(multi_connected)} ({len(multi_connected)/len(df):.1%})\")\n",
    "print(f\"   - Average path loss for connected: {connected_sensors['Best_PathLoss_dB'].mean():.1f} dB\")\n",
    "print(f\"   - Path loss range: {connected_sensors['Best_PathLoss_dB'].min():.1f} - {connected_sensors['Best_PathLoss_dB'].max():.1f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4131f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= FIXED SENSOR CONNECTIVITY VISUALIZATION =======\n",
    "# Run this cell after your sensor connectivity analysis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from ipyleaflet import Map, CircleMarker, Popup, GeoJSON, basemaps\n",
    "from ipywidgets import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "print(\"CREATING SENSOR CONNECTIVITY VISUALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if we have the required data\n",
    "if 'df' not in globals() or df.empty:\n",
    "    print(\"ERROR: Sensor connectivity results (df) not found!\")\n",
    "    print(\"   Please run the sensor connectivity analysis first.\")\n",
    "else:\n",
    "    print(f\"Found sensor connectivity results: {len(df)} sensors analyzed\")\n",
    "\n",
    "# Function to get distinct colors for gateways\n",
    "def get_distinct_colors(n):\n",
    "    \"\"\"Generate distinct colors for n gateways\"\"\"\n",
    "    if n <= 10:\n",
    "        return plt.get_cmap('tab10').colors[:n]\n",
    "    else:\n",
    "        return plt.cm.hsv(np.linspace(0, 1, n))\n",
    "\n",
    "# ===== FIXED DATA ACCESS =====\n",
    "if 'solution' not in globals() and 'saved_solutions' in globals() and saved_solutions:\n",
    "    latest_solution_key = sorted(saved_solutions.keys())[-1]\n",
    "    solution = saved_solutions[latest_solution_key]['solution']\n",
    "elif 'solution' not in globals():\n",
    "    print(\"ERROR: No gateway solution found!\")\n",
    "    solution = []\n",
    "\n",
    "solution_sorted = sort_gateways(solution, sort_by=\"lat\")\n",
    "gateways = [tuple(gw['coord']) for gw in solution_sorted]\n",
    "\n",
    "print(f\"Visualizing {len(gateways)} gateways:\")\n",
    "for i, gw_coord in enumerate(gateways):\n",
    "    print(f\"   GW{i}: ({gw_coord[0]:.6f}, {gw_coord[1]:.6f})\")\n",
    "\n",
    "# ===== GENERATE GATEWAY COLORS =====\n",
    "connected_sensors = df[df['Is_Connected']]\n",
    "if len(connected_sensors) > 0:\n",
    "    gateway_indices = sorted([idx for idx in connected_sensors['Best_Gateway'].unique() if idx >= 0])\n",
    "else:\n",
    "    gateway_indices = list(range(len(gateways)))  # Default to all gateways\n",
    "\n",
    "gateway_colors = {}\n",
    "if len(gateway_indices) > 0:\n",
    "    colors = get_distinct_colors(len(gateway_indices))\n",
    "    for i, gw_idx in enumerate(gateway_indices):\n",
    "        gateway_colors[gw_idx] = mcolors.to_hex(colors[i])\n",
    "else:\n",
    "    for i in range(len(gateways)):\n",
    "        gateway_colors[i] = '#ff0000'  # Red for all gateways\n",
    "\n",
    "# ===== CREATE MAP =====\n",
    "center = (aoi_poly.centroid.y, aoi_poly.centroid.x)\n",
    "print(f\"Creating map centered at: ({center[0]:.6f}, {center[1]:.6f})\")\n",
    "\n",
    "m = Map(center=center, zoom=13, basemap=basemaps.Esri.WorldImagery)\n",
    "m.add_layer(GeoJSON(\n",
    "    data=aoi_poly.__geo_interface__, \n",
    "    style={'color': 'yellow', 'fillOpacity': 0.02, 'weight': 3}\n",
    "))\n",
    "\n",
    "# ===== ADD GATEWAYS =====\n",
    "print(\"Adding gateways to map...\")\n",
    "for idx, gw in enumerate(solution_sorted):\n",
    "    coord = gw['coord']\n",
    "    lat, lon = coord[1], coord[0]  # Note: leaflet uses (lat, lon)\n",
    "    gateway_color = gateway_colors.get(idx, '#ff0000')\n",
    "    sensors_on_this_gw = len(df[df['Best_Gateway'] == idx])\n",
    "    connected_on_this_gw = len(df[(df['Best_Gateway'] == idx) & (df['Is_Connected'])])\n",
    "    popup_html = f\"\"\"\n",
    "    <div style='font-family: Arial; font-size: 12px;'>\n",
    "        <h4 style='margin: 0 0 8px 0; color: {gateway_color};'>🏗️ Gateway {idx}</h4>\n",
    "        <b>Location:</b><br>\n",
    "        Lon: {lon:.6f}<br>\n",
    "        Lat: {lat:.6f}<br>\n",
    "        <b>Performance:</b><br>\n",
    "        Assigned sensors: {sensors_on_this_gw}<br>\n",
    "        Connected sensors: {connected_on_this_gw}<br>\n",
    "        Connection rate: {connected_on_this_gw/sensors_on_this_gw*100 if sensors_on_this_gw > 0 else 0:.1f}%\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    popup = HTML(popup_html)\n",
    "    marker = CircleMarker(\n",
    "        location=(lat, lon),\n",
    "        radius=12,\n",
    "        color='black',\n",
    "        fill_color=gateway_color,\n",
    "        fill_opacity=0.9,\n",
    "        weight=2,\n",
    "        popup=popup\n",
    "    )\n",
    "    m.add_layer(marker)\n",
    "\n",
    "# ===== ADD CONNECTED SENSORS =====\n",
    "print(\"Adding connected sensors to map...\")\n",
    "connected_count = 0\n",
    "multi_connected_count = 0\n",
    "\n",
    "for _, row in connected_sensors.iterrows():\n",
    "    gw_idx = row['Best_Gateway']\n",
    "    if gw_idx < 0 or gw_idx >= len(gateways):\n",
    "        continue\n",
    "    color = gateway_colors.get(gw_idx, '#ff0000')\n",
    "    multi_conn = row.get('Multi_Connected', False)\n",
    "    if multi_conn:\n",
    "        marker_color = \"#ffff00\"  # Yellow for multi-connected\n",
    "        marker_radius = 7\n",
    "        border_color = color\n",
    "        border_width = 3\n",
    "        multi_connected_count += 1\n",
    "    else:\n",
    "        marker_color = color\n",
    "        marker_radius = 4\n",
    "        border_color = 'black'\n",
    "        border_width = 1\n",
    "    connected_count += 1\n",
    "    popup_html = f\"\"\"\n",
    "    <div style='font-family: Arial; font-size: 11px; max-width: 250px;'>\n",
    "        <h4 style='margin: 0 0 8px 0; color: {color};'>📡 Sensor Candidate</h4>\n",
    "        <b>Location:</b><br>\n",
    "        Lon: {row['Longitude']:.6f}<br>\n",
    "        Lat: {row['Latitude']:.6f}<br>\n",
    "        <b>Best Gateway:</b> GW{gw_idx}<br>\n",
    "        <b>Multi-Connected:</b> {'✅ Yes' if multi_conn else '❌ No'}<br>\n",
    "        <b>Elevation:</b> {row.get('Elevation', 0):.1f}m<br>\n",
    "    \"\"\"\n",
    "    if 'Connectable_Gateways' in row and row['Connectable_Gateways']:\n",
    "        popup_html += f\"<b>Connected Gateways ({len(row['Connectable_Gateways'])}):</b><br>\"\n",
    "        for conn_gw in row['Connectable_Gateways'][:3]:  # Show max 3 to avoid huge popups\n",
    "            gw_detail = None\n",
    "            for detail in row['Gateways_Details']:\n",
    "                if detail['idx'] == conn_gw:\n",
    "                    gw_detail = detail\n",
    "                    break\n",
    "            if gw_detail and 'percent_clear' in gw_detail:\n",
    "                percent_clear = gw_detail['percent_clear']\n",
    "            else:\n",
    "                percent_clear = 0\n",
    "            if gw_detail:\n",
    "                popup_html += f\"\"\"\n",
    "                <span style='color: {gateway_colors.get(conn_gw, \"#000000\")};'>🏗️ GW{conn_gw}:</span> \n",
    "                PL={gw_detail['path_loss']:.0f}dB, \n",
    "                Clear={percent_clear:.0f}%<br>\n",
    "                \"\"\"\n",
    "        if len(row['Connectable_Gateways']) > 3:\n",
    "            popup_html += f\"... and {len(row['Connectable_Gateways']) - 3} more<br>\"\n",
    "    popup_html += \"</div>\"\n",
    "    popup = HTML(popup_html)\n",
    "    marker = CircleMarker(\n",
    "        location=(row['Latitude'], row['Longitude']),\n",
    "        radius=marker_radius,\n",
    "        color=border_color,\n",
    "        fill_color=marker_color,\n",
    "        fill_opacity=0.8,\n",
    "        weight=border_width,\n",
    "        popup=popup\n",
    "    )\n",
    "    m.add_layer(marker)\n",
    "\n",
    "# ===== ADD DISCONNECTED SENSORS (SAMPLE) =====\n",
    "print(\"Adding sample of disconnected sensors...\")\n",
    "disconnected_sensors = df[~df['Is_Connected']]\n",
    "if len(disconnected_sensors) > 0:\n",
    "    sample_size = min(200, len(disconnected_sensors))\n",
    "    sample_disconnected = disconnected_sensors.sample(n=sample_size, random_state=42)\n",
    "    for _, row in sample_disconnected.iterrows():\n",
    "        popup_html = f\"\"\"\n",
    "        <div style='font-family: Arial; font-size: 11px;'>\n",
    "            <h4 style='margin: 0 0 8px 0; color: red;'>❌ Disconnected Sensor</h4>\n",
    "            <b>Location:</b><br>\n",
    "            Lon: {row['Longitude']:.6f}<br>\n",
    "            Lat: {row['Latitude']:.6f}<br>\n",
    "            <b>Best Path Loss:</b> {row.get('Best_PathLoss_dB', 'N/A'):.0f}dB<br>\n",
    "            <b>Best Clearance:</b> {row.get('Percent_Clear', 0):.0f}%<br>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        popup = HTML(popup_html)\n",
    "        marker = CircleMarker(\n",
    "            location=(row['Latitude'], row['Longitude']),\n",
    "            radius=2,\n",
    "            color='darkred',\n",
    "            fill_color='red',\n",
    "            fill_opacity=0.5,\n",
    "            weight=1,\n",
    "            popup=popup\n",
    "        )\n",
    "        m.add_layer(marker)\n",
    "\n",
    "# ===== ENHANCED LEGEND =====\n",
    "legend_html = \"\"\"\n",
    "<div style='background: white; padding: 12px; border-radius: 8px; \n",
    "            box-shadow: 0 2px 6px rgba(0,0,0,0.3); font-family: Arial; font-size: 12px; min-width: 200px;'>\n",
    "    <h4 style='margin: 0 0 10px 0; color: #333;'> Network Map Legend</h4>\n",
    "\"\"\"\n",
    "legend_html += \"<b>Gateway Colors:</b><br>\"\n",
    "for idx in sorted(gateway_colors.keys()):\n",
    "    color = gateway_colors[idx]\n",
    "    sensors_count = len(df[(df['Best_Gateway'] == idx) & (df['Is_Connected'])])\n",
    "    legend_html += f\"<span style='color:{color}; font-size: 16px;'>🏗️</span> Gateway {idx} ({sensors_count} sensors)<br>\"\n",
    "\n",
    "legend_html += \"<br><b>Sensor Status:</b><br>\"\n",
    "legend_html += \"<span style='color: #ffff00; font-size: 14px;'></span> Multi-Connected Sensor<br>\"\n",
    "legend_html += \"<span style='color: #00ff00; font-size: 14px;'></span> Single-Connected Sensor<br>\"\n",
    "legend_html += \"<span style='color: red; font-size: 14px;'></span> Disconnected Sensor<br>\"\n",
    "\n",
    "connectivity_pct = len(connected_sensors) / len(df) * 100 if len(df) > 0 else 0\n",
    "multi_pct = multi_connected_count / len(df) * 100 if len(df) > 0 else 0\n",
    "legend_html += f\"\"\"\n",
    "<br><b>Network Statistics:</b><br>\n",
    "Connected: {len(connected_sensors)}/{len(df)} ({connectivity_pct:.1f}%)<br>\n",
    "Multi-connected: {multi_connected_count} ({multi_pct:.1f}%)<br>\n",
    "\"\"\"\n",
    "\n",
    "legend_html += \"</div>\"\n",
    "\n",
    "legend_control = HTML(legend_html)\n",
    "legend_popup = Popup(\n",
    "    location=(center[0] + 0.002, center[1] - 0.002),\n",
    "    child=legend_control,\n",
    "    close_button=False,\n",
    "    auto_close=False,\n",
    "    close_on_escape_key=False\n",
    ")\n",
    "m.add_control(legend_popup)\n",
    "\n",
    "print(f\"\\nVISUALIZATION SUMMARY:\")\n",
    "print(f\"   Gateways displayed: {len(gateways)}\")\n",
    "print(f\"   Connected sensors: {connected_count}\")\n",
    "print(f\"   Multi-connected sensors: {multi_connected_count}\")\n",
    "print(f\"   Disconnected sensors (sample): {min(200, len(disconnected_sensors))}/{len(disconnected_sensors)}\")\n",
    "print(f\"   Overall connectivity: {connectivity_pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nInteractive map created successfully!\")\n",
    "print(f\"   - Click on gateways to see performance stats\")\n",
    "print(f\"   - Click on sensors to see connection details\")\n",
    "print(f\"   - Yellow sensors have multiple gateway options\")\n",
    "\n",
    "# Display the map\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================\n",
    "# PHASE 2: Final Sensor Placement Optimizer (Multi-Objective, Mountain-Aware, Mapping)\n",
    "# With Global & Per-Gateway Assignment Options (MIP + NSGA-III)\n",
    "# Includes Generation Diagnostics and Debugging!\n",
    "# (Updated: remainder-aware per-gateway quotas + cross-gateway non-overlap)\n",
    "# =====================================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from itertools import combinations\n",
    "import pulp\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
    "from pymoo.util.ref_dirs import get_reference_directions\n",
    "from pymoo.optimize import minimize\n",
    "from ipywidgets import IntSlider, Dropdown, FloatSlider, Button, Output, HBox, VBox, SelectMultiple, HTML, Layout\n",
    "from ipyleaflet import Map, CircleMarker, Polyline, GeoJSON, Circle, basemaps\n",
    "\n",
    "# -------- Parameters --------\n",
    "SENSOR_RADIUS = 500  # meters (for non-overlap constraint)\n",
    "min_sensor_separation = SENSOR_RADIUS * 2\n",
    "max_sensors = 30\n",
    "\n",
    "# ---------- Helper to REQUIRE an adopted gateway solution ----------\n",
    "def get_adopted_gateways_or_fail():\n",
    "    \"\"\"\n",
    "    Returns a list of (lon, lat) tuples for the CURRENT adopted gateway solution.\n",
    "    Raises RuntimeError with a clear message if none is adopted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gw_solution = get_current_solution_or_raise()\n",
    "    except RuntimeError as e:\n",
    "        raise RuntimeError(\n",
    "            \"No adopted gateway solution found. In Phase 1, run NSGA-III or MIP and click \"\n",
    "            \"'Adopt Selected Feasible' (or 'Adopt MIP Result') before running Phase 2.\"\n",
    "        ) from e\n",
    "\n",
    "    if not gw_solution:\n",
    "        raise RuntimeError(\"CURRENT_SOLUTION is empty. Adopt a gateway solution in Phase 1 first.\")\n",
    "\n",
    "    gw_sorted = sort_gateways(gw_solution, sort_by=\"lat\")\n",
    "    gateways_local = [tuple(gw['coord']) for gw in gw_sorted]\n",
    "    if len(gateways_local) == 0:\n",
    "        raise RuntimeError(\"Gateway list is empty after sorting; cannot continue.\")\n",
    "    return gateways_local\n",
    "\n",
    "# Try to fetch gateways now (header preview). It's okay if this fails here; we guard inside the run.\n",
    "try:\n",
    "    gateways = get_adopted_gateways_or_fail()\n",
    "except RuntimeError as e:\n",
    "    print(f\"⚠️ {e}\")\n",
    "    gateways = []\n",
    "\n",
    "# -------- UI Controls --------\n",
    "num_sensors_slider = IntSlider(value=12, min=3, max=max_sensors, step=1, description=\"Num Sensors:\")\n",
    "optimization_method = Dropdown(\n",
    "    options=[('Weighted (MIP)', 'mip'), ('Pareto (NSGA-III)', 'nsga3')],\n",
    "    value='mip', description='Method:'\n",
    ")\n",
    "assignment_mode = Dropdown(\n",
    "    options=[('Global', 'global'), ('Per-Gateway', 'partitioned')],\n",
    "    value='global', description='Assignment:'\n",
    ")\n",
    "sensor_objectives = [\n",
    "    ('Solar', 'Solar'),\n",
    "    ('Elevation', 'Elevation'),\n",
    "    ('Multi-Connected', 'Num_Connectable'),\n",
    "    ('PathLoss', 'Best_PathLoss_dB')\n",
    "]\n",
    "obj_select = SelectMultiple(\n",
    "    options=sensor_objectives,\n",
    "    value=('Solar', 'Elevation', 'Num_Connectable', 'Best_PathLoss_dB'),\n",
    "    description='NSGA-III Objectives',\n",
    "    layout=Layout(width='300px', height='110px')\n",
    ")\n",
    "\n",
    "w_coverage = FloatSlider(value=0.3, min=0, max=1, step=0.05, description='Coverage:', style={'description_width': '100px'})\n",
    "w_solar = FloatSlider(value=0.2, min=0, max=1, step=0.05, description='Solar:', style={'description_width': '100px'})\n",
    "w_elevation = FloatSlider(value=0.2, min=0, max=1, step=0.05, description='Elevation:', style={'description_width': '100px'})\n",
    "w_multiconn = FloatSlider(value=0.2, min=0, max=1, step=0.05, description='Multi-Conn:', style={'description_width': '100px'})\n",
    "w_pathloss = FloatSlider(value=0.1, min=0, max=1, step=0.05, description='PathLoss:', style={'description_width': '100px'})\n",
    "\n",
    "def normalize_df_columns(df, cols):\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            vals = df[col].values\n",
    "            min_val = np.nanmin(vals)\n",
    "            max_val = np.nanmax(vals)\n",
    "            if max_val > min_val:\n",
    "                df[f\"{col}_norm\"] = (vals - min_val) / (max_val - min_val)\n",
    "            else:\n",
    "                df[f\"{col}_norm\"] = np.zeros_like(vals)\n",
    "    return df\n",
    "\n",
    "def get_sensor_weights():\n",
    "    return {\n",
    "        'Solar': w_solar.value,\n",
    "        'Elevation': w_elevation.value,\n",
    "        'Num_Connectable': w_multiconn.value,\n",
    "        'Best_PathLoss_dB': w_pathloss.value\n",
    "    }\n",
    "\n",
    "run_btn = Button(description='Run Sensor Optimization', button_style='success')\n",
    "output = Output()\n",
    "\n",
    "# --------- Helper Functions ----------\n",
    "def normalize_col(df, col):\n",
    "    vals = df[col].values\n",
    "    if np.max(vals) > np.min(vals):\n",
    "        return (vals - np.min(vals)) / (np.max(vals) - np.min(vals))\n",
    "    else:\n",
    "        return np.zeros_like(vals)\n",
    "\n",
    "def get_coverage_union(selected_locs, coverage_grid, sensor_radius):\n",
    "    covered = set()\n",
    "    for lon, lat in selected_locs:\n",
    "        for i, (x, y) in enumerate(coverage_grid):\n",
    "            d = geodesic((lat, lon), (y, x)).meters\n",
    "            if d <= sensor_radius:\n",
    "                covered.add(i)\n",
    "    return 100.0 * len(covered) / len(coverage_grid) if coverage_grid else 0.0\n",
    "\n",
    "def plot_selected_sensors_map(aoi_poly, gateways, sensors_df, gateway_colors=None, gateway_col='Best_Gateway'):\n",
    "    m = Map(center=(aoi_poly.centroid.y, aoi_poly.centroid.x), zoom=13, basemap=basemaps.Esri.WorldImagery)\n",
    "    m.add_layer(GeoJSON(data=aoi_poly.__geo_interface__, style={\n",
    "        'color': 'yellow', 'fillOpacity': 0.03, 'weight': 2\n",
    "    }))\n",
    "    # Gateways\n",
    "    colors = ['red', 'green', 'blue', 'purple', 'orange', 'black', 'magenta']\n",
    "    if gateway_colors is None:\n",
    "        gateway_colors = {i: colors[i % len(colors)] for i in range(len(gateways))}\n",
    "    for idx, gw in enumerate(gateways):\n",
    "        lat, lon = gw[1], gw[0]\n",
    "        m.add_layer(CircleMarker(location=(lat, lon), radius=10, color=gateway_colors[idx], fill_color=gateway_colors[idx], fill_opacity=0.8))\n",
    "    # Sensors and lines\n",
    "    for i, row in sensors_df.iterrows():\n",
    "        lat, lon = row['Latitude'], row['Longitude']\n",
    "        gw_idx = int(row[gateway_col]) if gateway_col in row else int(row['Best_Gateway'])\n",
    "        color = gateway_colors[gw_idx]\n",
    "        m.add_layer(CircleMarker(location=(lat, lon), radius=5, color=color, fill_color=color, fill_opacity=0.82))\n",
    "        m.add_layer(Circle(location=(lat, lon), radius=SENSOR_RADIUS, color=\"#aaa\", fill_color=\"#aaa\", fill_opacity=0.12))\n",
    "        gw = gateways[gw_idx]\n",
    "        m.add_layer(Polyline(locations=[(lat, lon), (gw[1], gw[0])], color=color, weight=2, opacity=0.7))\n",
    "    return m\n",
    "\n",
    "def dist_m(p, q):\n",
    "    return geodesic((p[1], p[0]), (q[1], q[0])).meters\n",
    "\n",
    "def ok_vs_global(P, global_list, min_sep):\n",
    "    \"\"\"True if P is at least min_sep from all points in global_list.\"\"\"\n",
    "    return all(dist_m(P, Q) >= min_sep for Q in global_list)\n",
    "\n",
    "def feasible_indices_from_result(res, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Return indices of feasible solutions from a pymoo 'minimize' result.\n",
    "    Uses CV if available; falls back to G if present; otherwise assumes all feasible.\n",
    "    \"\"\"\n",
    "    if hasattr(res, \"CV\") and res.CV is not None:\n",
    "        return np.where(res.CV <= tol)[0]\n",
    "    if hasattr(res, \"G\") and res.G is not None:\n",
    "        G = res.G\n",
    "        if G.ndim == 1:\n",
    "            return np.where(G <= tol)[0]\n",
    "        return np.where(np.all(G <= tol, axis=1))[0]\n",
    "    n = len(res.X) if hasattr(res, \"X\") and res.X is not None else 0\n",
    "    return np.arange(n)\n",
    "\n",
    "# --------- Main Callback: With Debug & Generation Diagnostics ----------\n",
    "def on_sensor_opt_run(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        print(\"=== Phase 2: Sensor Placement Optimization ===\")\n",
    "        N = num_sensors_slider.value\n",
    "        method = optimization_method.value\n",
    "        assign_mode = assignment_mode.value\n",
    "\n",
    "        # === Prepare the candidate DataFrame ===\n",
    "        if 'df' not in globals() or df.empty:\n",
    "            print(\"Sensor candidate DataFrame 'df' is missing. Run the connectivity analysis first.\")\n",
    "            return\n",
    "\n",
    "        cand_df = df[df['Is_Connected']].reset_index(drop=True).copy()\n",
    "\n",
    "        # Get gateway coordinates for assignment from the CURRENT (adopted) solution\n",
    "        try:\n",
    "            gateways = get_adopted_gateways_or_fail()\n",
    "        except RuntimeError as e:\n",
    "            print(f\"❌ {e}\")\n",
    "            return\n",
    "\n",
    "        def assign_to_nearest_gateway(row, gateways):\n",
    "            dists = [geodesic((row['Latitude'], row['Longitude']), (gw[1], gw[0])).meters for gw in gateways]\n",
    "            return int(np.argmin(dists))\n",
    "\n",
    "        cand_df['Nearest_Gateway'] = cand_df.apply(assign_to_nearest_gateway, axis=1, gateways=gateways)\n",
    "\n",
    "        # Coverage grid\n",
    "        from shapely.geometry import Polygon, MultiPolygon\n",
    "        poly = aoi_poly\n",
    "        if not isinstance(poly, Polygon):\n",
    "            if hasattr(poly, 'geoms'):\n",
    "                poly = max(poly.geoms, key=lambda p: p.area)\n",
    "            else:\n",
    "                print(\"AOI geometry is not a Polygon or MultiPolygon.\")\n",
    "                return\n",
    "        coverage_grid = generate_coverage_grid(poly, 60)\n",
    "\n",
    "        # Normalize features\n",
    "        norm_cols = ['Solar', 'Elevation', 'Num_Connectable', 'Best_PathLoss_dB']\n",
    "        cand_df = normalize_df_columns(cand_df, norm_cols)\n",
    "        if len(cand_df) < N:\n",
    "            print(f\"⚠️ Only {len(cand_df)} valid sensor candidates found. Lower 'Num Sensors'.\")\n",
    "            return\n",
    "\n",
    "        # --- GENERATION EVAL: Candidate Pool Stats ---\n",
    "        print(\"========== SANITY CHECK: CANDIDATE GENERATION ==========\")\n",
    "        print(f\"Total candidate sensors: {len(cand_df)}\")\n",
    "        print(f\"Columns: {cand_df.columns.tolist()}\")\n",
    "        print(\"First 3 candidates:\\n\", cand_df[['Longitude', 'Latitude', 'Num_Connectable']].head(3))\n",
    "        multi_conn_count = (cand_df['Num_Connectable'] > 1).sum()\n",
    "        print(f\"Multi-connectable candidates: {multi_conn_count} ({multi_conn_count/len(cand_df)*100:.1f}%)\")\n",
    "        if 'Best_Gateway' in cand_df.columns:\n",
    "            print(\"Candidate count per gateway:\")\n",
    "            print(cand_df['Best_Gateway'].value_counts().sort_index())\n",
    "\n",
    "        # == Gateway data ==\n",
    "        gateway_colors = {i: c for i, c in enumerate(['red','green','blue','purple','orange','black','magenta'])}\n",
    "        num_gateways = len(gateways)\n",
    "        if num_gateways == 0:\n",
    "            print(\"No gateways available. Adopt a solution in Phase 1 and try again.\")\n",
    "            return\n",
    "\n",
    "        # ====== PARTITIONED PER-GATEWAY SENSOR ASSIGNMENT ======\n",
    "        if assign_mode == \"partitioned\":\n",
    "            print(f\"\\n=== Per-Gateway Assignment (non-overlapping across gateways) ===\")\n",
    "            if num_gateways == 1:\n",
    "                print(\"ℹ️ Only one gateway; partitioned mode reduces to global selection for that gateway.\")\n",
    "\n",
    "            # ---------- Quota with remainder ----------\n",
    "            base = N // num_gateways\n",
    "            rem  = N %  num_gateways\n",
    "            sizes = [(g, int((cand_df['Nearest_Gateway'] == g).sum())) for g in range(num_gateways)]\n",
    "            quota = {g: base for g in range(num_gateways)}\n",
    "            for g,_ in sorted(sizes, key=lambda x: x[1], reverse=True)[:rem]:\n",
    "                quota[g] += 1\n",
    "            total_quota = sum(quota.values())\n",
    "            print(f\"Requested N={N}. Quotas by gateway (base+remainder): {quota}  -> total {total_quota}\")\n",
    "\n",
    "            # ---------- weights for scoring ----------\n",
    "            weights = get_sensor_weights()\n",
    "\n",
    "            # ---------- global non-overlap tracking ----------\n",
    "            global_selected_pts = []       # list of (lon, lat)\n",
    "            global_selected_rows = []      # list of DataFrames to concat\n",
    "            unmet = 0                      # how many slots we couldn't fill in pass 1\n",
    "\n",
    "            # ---------- PASS 1: per-gateway selection with global filtering ----------\n",
    "            for gw_idx, gw in enumerate(gateways):\n",
    "                need = quota[gw_idx]\n",
    "                if need <= 0:\n",
    "                    continue\n",
    "                local_cands = cand_df[cand_df['Nearest_Gateway'] == gw_idx].reset_index(drop=True)\n",
    "\n",
    "                # Drop candidates that would overlap already-chosen sensors\n",
    "                if global_selected_pts:\n",
    "                    keep_idx = []\n",
    "                    for i,r in local_cands.iterrows():\n",
    "                        P = (float(r['Longitude']), float(r['Latitude']))\n",
    "                        if ok_vs_global(P, global_selected_pts, min_sensor_separation):\n",
    "                            keep_idx.append(i)\n",
    "                    local_cands = local_cands.loc[keep_idx].reset_index(drop=True)\n",
    "\n",
    "                print(f\"Gateway {gw_idx}: {int((cand_df['Nearest_Gateway']==gw_idx).sum())} local candidates,\"\n",
    "                      f\" {len(local_cands)} remain after cross-gateway non-overlap filter. Selecting {need} sensors.\")\n",
    "                print(\"  Top 3 local candidates:\")\n",
    "                print(local_cands[['Longitude','Latitude','Num_Connectable']].head(3))\n",
    "                local_multi = (local_cands['Num_Connectable'] > 1).sum()\n",
    "                print(f\"  Multi-connectable (local): {local_multi} / {len(local_cands)}\")\n",
    "\n",
    "                if len(local_cands) == 0 or need == 0:\n",
    "                    unmet += need\n",
    "                    continue\n",
    "\n",
    "                # Prepare normalized score\n",
    "                for col in weights:\n",
    "                    if col in local_cands.columns:\n",
    "                        local_cands[f\"{col}_norm\"] = normalize_col(local_cands, col)\n",
    "                local_cands['score'] = sum(local_cands.get(f\"{col}_norm\", 0) * weights[col] for col in weights)\n",
    "                local_cands = local_cands[np.isfinite(local_cands['score'])].copy()\n",
    "                indices = local_cands.index.tolist()\n",
    "\n",
    "                # If fewer remain than needed, we'll take as many as possible and backfill later\n",
    "                target = min(need, len(indices))\n",
    "\n",
    "                # ------ MIP ------\n",
    "                if method == 'mip':\n",
    "                    prob = pulp.LpProblem(f\"SensorPlacement_GW{gw_idx}\", pulp.LpMaximize)\n",
    "                    x = pulp.LpVariable.dicts(\"sensor\", indices, cat='Binary')\n",
    "                    prob += pulp.lpSum([local_cands.loc[i, 'score'] * x[i] for i in indices]), \"Total_Score\"\n",
    "                    prob += pulp.lpSum([x[i] for i in indices]) == target, \"Select_Target\"\n",
    "                    # Non-overlap within this gateway's set\n",
    "                    for i, j in combinations(indices, 2):\n",
    "                        loc_i = (local_cands.loc[i, 'Longitude'], local_cands.loc[i, 'Latitude'])\n",
    "                        loc_j = (local_cands.loc[j, 'Longitude'], local_cands.loc[j, 'Latitude'])\n",
    "                        if geodesic((loc_i[1], loc_i[0]), (loc_j[1], loc_j[0])).meters < min_sensor_separation:\n",
    "                            prob += x[i] + x[j] <= 1, f\"Separation_{i}_{j}\"\n",
    "                    prob.solve()\n",
    "                    if prob.status == pulp.LpStatusOptimal:\n",
    "                        sel = [i for i in indices if x[i].varValue == 1]\n",
    "                        assigned = local_cands.loc[sel].copy()\n",
    "                        assigned['Assigned_Gateway'] = gw_idx\n",
    "                        # append to global selections and block their radius globally\n",
    "                        for _,rr in assigned.iterrows():\n",
    "                            global_selected_pts.append((float(rr['Longitude']), float(rr['Latitude'])))\n",
    "                        global_selected_rows.append(assigned)\n",
    "                        print(f\"  Gateway {gw_idx} selected {len(sel)} sensors.\")\n",
    "                        if len(sel) < need:\n",
    "                            unmet += (need - len(sel))\n",
    "                    else:\n",
    "                        print(f\"❌ MIP Optimization failed for Gateway {gw_idx}. Status: {pulp.LpStatus[prob.status]}\")\n",
    "                        unmet += need\n",
    "\n",
    "                # ------ NSGA-III ------\n",
    "                elif method == 'nsga3':\n",
    "                    selected_obj = list(obj_select.value)\n",
    "                    ref_dirs = get_reference_directions(\"das-dennis\", len(selected_obj), n_partitions=3)\n",
    "                    class LocalSensorPlacementProblem(Problem):\n",
    "                        def __init__(self, candidate_df, n_sensors):\n",
    "                            self.candidate_df = candidate_df.reset_index(drop=True)\n",
    "                            self.n_sensors = n_sensors\n",
    "                            super().__init__(n_var=n_sensors, n_obj=len(selected_obj), n_constr=1,\n",
    "                                             xl=0, xu=len(self.candidate_df)-1, elementwise_evaluation=True)\n",
    "                        def _evaluate(self, x, out, *args, **kwargs):\n",
    "                            Fs, Gs = [], []\n",
    "                            x = np.atleast_2d(x)\n",
    "                            for xi_num, xi in enumerate(x):\n",
    "                                idxs = [int(i) for i in xi]\n",
    "                                sensors = self.candidate_df.iloc[idxs]\n",
    "                                coords = [(row['Longitude'], row['Latitude']) for _, row in sensors.iterrows()]\n",
    "                                F = []\n",
    "                                for obj in selected_obj:\n",
    "                                    norm_obj = obj + \"_norm\"\n",
    "                                    if norm_obj in sensors.columns:\n",
    "                                        if obj == 'Best_PathLoss_dB':\n",
    "                                            F.append(np.mean(sensors[norm_obj]))      # minimize pathloss\n",
    "                                        else:\n",
    "                                            F.append(-np.mean(sensors[norm_obj]))     # maximize others\n",
    "                                    else:\n",
    "                                        F.append(0)\n",
    "                                # within-set separation\n",
    "                                min_dist = float('inf')\n",
    "                                for p1, p2 in combinations(coords, 2):\n",
    "                                    d = geodesic((p1[1], p1[0]), (p2[1], p2[0])).meters\n",
    "                                    if d < min_dist:\n",
    "                                        min_dist = d\n",
    "                                g1 = min_sensor_separation - min_dist\n",
    "                                Fs.append(F)\n",
    "                                Gs.append([g1])\n",
    "                                if xi_num < 3:\n",
    "                                    print(f\"    [DEBUG-GW{gw_idx}] Indiv {xi_num}: idxs={idxs}, F={F}, min_dist={min_dist:.2f}, g1={g1:.2f}\")\n",
    "                            out[\"F\"] = np.array(Fs)\n",
    "                            out[\"G\"] = np.array(Gs)\n",
    "                    problem = LocalSensorPlacementProblem(local_cands, target)\n",
    "                    algorithm = NSGA3(ref_dirs=ref_dirs)\n",
    "                    try:\n",
    "                        res = minimize(problem, algorithm, termination=('n_gen', 100), seed=gw_idx+1, verbose=True)\n",
    "                    except Exception as e:\n",
    "                        print(f\"NSGA-III crashed for Gateway {gw_idx}:\", str(e))\n",
    "                        unmet += need\n",
    "                        continue\n",
    "                    feasible = feasible_indices_from_result(res, tol=1e-6)\n",
    "\n",
    "                    if hasattr(res, \"CV\") and res.CV is not None:\n",
    "                        print(f\"    [DEBUG-GW{gw_idx}] CV stats: min={np.min(res.CV):.3f}, median={np.median(res.CV):.3f}, max={np.max(res.CV):.3f}\")\n",
    "\n",
    "                    if len(feasible) == 0:\n",
    "                        if hasattr(res, \"CV\") and res.CV is not None:\n",
    "                            best_idx = int(np.argmin(res.CV))\n",
    "                            print(f\"No feasible solutions for Gateway {gw_idx}. Taking least-infeasible (CV={res.CV[best_idx]:.3f}).\")\n",
    "                        else:\n",
    "                            best_idx = 0\n",
    "                    else:\n",
    "                        best_idx_local = int(np.argmin(np.linalg.norm(res.F[feasible], axis=1)))\n",
    "                        best_idx = int(feasible[best_idx_local])\n",
    "\n",
    "                    best_X = res.X[best_idx]\n",
    "                    idxs = [int(i) for i in best_X]\n",
    "                    assigned = local_cands.iloc[idxs].copy()\n",
    "                    assigned['Assigned_Gateway'] = gw_idx\n",
    "                    for _,rr in assigned.iterrows():\n",
    "                        global_selected_pts.append((float(rr['Longitude']), float(rr['Latitude'])))\n",
    "                    global_selected_rows.append(assigned)\n",
    "                    print(f\"  Gateway {gw_idx} selected {len(idxs)} sensors.\")\n",
    "                    if len(idxs) < need:\n",
    "                        unmet += (need - len(idxs))\n",
    "                else:\n",
    "                    print(\"Invalid method selected.\")\n",
    "                    return\n",
    "\n",
    "            # ---------- PASS 2: backfill any unmet quota from any remaining candidates ----------\n",
    "            if unmet > 0:\n",
    "                print(f\"\\nBackfilling {unmet} remaining sensors from all gateways without overlap...\")\n",
    "                remaining = cand_df.copy()\n",
    "                if global_selected_pts:\n",
    "                    keep_idx = []\n",
    "                    for i,r in remaining.iterrows():\n",
    "                        P = (float(r['Longitude']), float(r['Latitude']))\n",
    "                        if ok_vs_global(P, global_selected_pts, min_sensor_separation):\n",
    "                            keep_idx.append(i)\n",
    "                    remaining = remaining.loc[keep_idx].copy()\n",
    "                if not remaining.empty:\n",
    "                    for col in get_sensor_weights():\n",
    "                        if col in remaining.columns:\n",
    "                            remaining[f\"{col}_norm\"] = normalize_col(remaining, col)\n",
    "                    remaining['score'] = sum(remaining.get(f\"{col}_norm\", 0) * get_sensor_weights()[col] for col in get_sensor_weights())\n",
    "                    remaining = remaining.sort_values('score', ascending=False)\n",
    "                    rows = []\n",
    "                    for _,r in remaining.iterrows():\n",
    "                        if unmet <= 0:\n",
    "                            break\n",
    "                        P = (float(r['Longitude']), float(r['Latitude']))\n",
    "                        if ok_vs_global(P, global_selected_pts, min_sensor_separation):\n",
    "                            r = r.copy()\n",
    "                            r['Assigned_Gateway'] = int(r.get('Nearest_Gateway', r.get('Best_Gateway', 0)))\n",
    "                            rows.append(r)\n",
    "                            global_selected_pts.append(P)\n",
    "                            unmet -= 1\n",
    "                    if rows:\n",
    "                        global_selected_rows.append(pd.DataFrame(rows))\n",
    "                if unmet > 0:\n",
    "                    print(f\"Could not place {unmet} sensors due to non-overlap/global constraints.\")\n",
    "\n",
    "            # ---------- Final reporting ----------\n",
    "            if global_selected_rows:\n",
    "                selected = pd.concat(global_selected_rows, ignore_index=True)\n",
    "                union_cov = get_coverage_union(selected[['Longitude', 'Latitude']].values, coverage_grid, SENSOR_RADIUS)\n",
    "                print(f\"\\nPartitioned {method.upper()} Solution: {len(selected)} sensors\")\n",
    "                print(f\"  - AOI coverage: {union_cov:.1f}% (union of all sensors)\")\n",
    "                display(selected[['Longitude', 'Latitude', 'Solar', 'Elevation', 'Num_Connectable', 'Best_PathLoss_dB', 'Assigned_Gateway']])\n",
    "                display(plot_selected_sensors_map(aoi_poly, gateways, selected, gateway_colors=gateway_colors, gateway_col='Assigned_Gateway'))\n",
    "            else:\n",
    "                print(\"No sensors selected in partitioned mode.\")\n",
    "\n",
    "        # ====== GLOBAL (NON-PARTITIONED) MODE ======\n",
    "        else:\n",
    "            print(\"\\n=== Global Assignment: All sensors selected from all candidates. ===\")\n",
    "            print(\"Global candidate gateway distribution:\")\n",
    "            print(cand_df['Best_Gateway'].value_counts().sort_index())\n",
    "            print(f\"Multi-connectable sensors (Num_Connectable > 1): {(cand_df['Num_Connectable'] > 1).sum()}\")\n",
    "            weights = get_sensor_weights()\n",
    "            for col in weights:\n",
    "                if col in cand_df.columns:\n",
    "                    cand_df[f\"{col}_norm\"] = normalize_col(cand_df, col)\n",
    "            cand_df['score'] = sum(cand_df.get(f\"{col}_norm\", 0) * weights[col] for col in weights)\n",
    "            cand_df = cand_df[np.isfinite(cand_df['score'])].copy()\n",
    "            indices = cand_df.index.tolist()\n",
    "\n",
    "            if method == 'mip':\n",
    "                print(\"Solving global MIP for best sensor set...\")\n",
    "                prob = pulp.LpProblem(\"SensorPlacement\", pulp.LpMaximize)\n",
    "                x = pulp.LpVariable.dicts(\"sensor\", indices, cat='Binary')\n",
    "                prob += pulp.lpSum([cand_df.loc[i, 'score'] * x[i] for i in indices]), \"Total_Score\"\n",
    "                prob += pulp.lpSum([x[i] for i in indices]) == N, \"Select_N_Sensors\"\n",
    "                # Non-overlap\n",
    "                for i, j in combinations(indices, 2):\n",
    "                    loc_i = (cand_df.loc[i, 'Longitude'], cand_df.loc[i, 'Latitude'])\n",
    "                    loc_j = (cand_df.loc[j, 'Longitude'], cand_df.loc[j, 'Latitude'])\n",
    "                    if geodesic((loc_i[1], loc_i[0]), (loc_j[1], loc_j[0])).meters < min_sensor_separation:\n",
    "                        prob += x[i] + x[j] <= 1, f\"Separation_{i}_{j}\"\n",
    "                prob.solve()\n",
    "                if prob.status == pulp.LpStatusOptimal:\n",
    "                    sel = [i for i in indices if x[i].varValue == 1]\n",
    "                    selected = cand_df.loc[sel]\n",
    "                    union_cov = get_coverage_union(selected[['Longitude', 'Latitude']].values, coverage_grid, SENSOR_RADIUS)\n",
    "                    print(f\"MIP Solution: {N} sensors\")\n",
    "                    print(f\"  - AOI coverage: {union_cov:.1f}% (union of all sensors)\")\n",
    "                    display(selected[['Longitude', 'Latitude', 'Solar', 'Elevation', 'Num_Connectable', 'Best_PathLoss_dB']])\n",
    "                    display(plot_selected_sensors_map(aoi_poly, gateways, selected, gateway_colors=gateway_colors, gateway_col='Best_Gateway'))\n",
    "                else:\n",
    "                    print(\"MIP Optimization failed. Status:\", pulp.LpStatus[prob.status])\n",
    "\n",
    "            elif method == 'nsga3':\n",
    "                print(\"Running global NSGA-III for sensor Pareto optimization...\")\n",
    "                selected_obj = list(obj_select.value)\n",
    "                ref_dirs = get_reference_directions(\"das-dennis\", len(selected_obj), n_partitions=4)\n",
    "                class SensorPlacementProblem(Problem):\n",
    "                    def __init__(self, candidate_df, n_sensors, objectives, coverage_grid, sensor_radius):\n",
    "                        self.candidate_df = candidate_df.reset_index(drop=True)\n",
    "                        self.n_sensors = n_sensors\n",
    "                        self.objectives = objectives\n",
    "                        self.coverage_grid = coverage_grid\n",
    "                        self.sensor_radius = sensor_radius\n",
    "                        super().__init__(n_var=n_sensors, n_obj=len(objectives), n_constr=1, xl=0, xu=len(self.candidate_df)-1, elementwise_evaluation=True)\n",
    "                    def _evaluate(self, x, out, *args, **kwargs):\n",
    "                        Fs, Gs = [], []\n",
    "                        x = np.atleast_2d(x)\n",
    "                        for xi_num, xi in enumerate(x):\n",
    "                            idxs = [int(i) for i in xi]\n",
    "                            sensors = self.candidate_df.iloc[idxs]\n",
    "                            coords = [(row['Longitude'], row['Latitude']) for _, row in sensors.iterrows()]\n",
    "                            F = []\n",
    "                            for obj in self.objectives:\n",
    "                                norm_obj = obj + \"_norm\"\n",
    "                                if norm_obj in sensors.columns:\n",
    "                                    if obj == 'Best_PathLoss_dB':\n",
    "                                        F.append(np.mean(sensors[norm_obj]))  # minimize pathloss\n",
    "                                    else:\n",
    "                                        F.append(-np.mean(sensors[norm_obj])) # maximize all others\n",
    "                                else:\n",
    "                                    F.append(0)\n",
    "                            min_dist = float('inf')\n",
    "                            for p1, p2 in combinations(coords, 2):\n",
    "                                dist = geodesic((p1[1], p1[0]), (p2[1], p2[0])).meters\n",
    "                                if dist < min_dist:\n",
    "                                    min_dist = dist\n",
    "                            g1 = min_sensor_separation - min_dist\n",
    "                            Fs.append(F)\n",
    "                            Gs.append([g1])\n",
    "                            if xi_num < 3:\n",
    "                                print(f\"    [DEBUG-GLOBAL] Indiv {xi_num}: idxs={idxs}, F={F}, min_dist={min_dist:.2f}, g1={g1:.2f}\")\n",
    "                        out[\"F\"] = np.array(Fs)\n",
    "                        out[\"G\"] = np.array(Gs)\n",
    "                problem = SensorPlacementProblem(\n",
    "                    candidate_df=cand_df,\n",
    "                    n_sensors=N,\n",
    "                    objectives=selected_obj,\n",
    "                    coverage_grid=coverage_grid,\n",
    "                    sensor_radius=SENSOR_RADIUS\n",
    "                )\n",
    "                algorithm = NSGA3(ref_dirs=ref_dirs)\n",
    "                try:\n",
    "                    res = minimize(problem, algorithm, termination=('n_gen', 10), seed=1, verbose=True)\n",
    "                except AssertionError as e:\n",
    "                    print(\"NSGA-III crashed:\", str(e))\n",
    "                    print(\"Try lowering n_partitions, reducing objectives, or loosening constraints.\")\n",
    "                    return\n",
    "                print(f\"NSGA-III generations completed. Solution shape F: {getattr(res, 'F', None).shape}\")\n",
    "                feasible = np.where(res.G[:,0] <= 1e-6)[0]\n",
    "                print(f\"Feasible solutions found: {len(feasible)}\")\n",
    "                if len(feasible) == 0:\n",
    "                    print(\"No feasible solutions.\")\n",
    "                    return\n",
    "                best_idx = np.argmin(np.linalg.norm(res.F[feasible], axis=1))\n",
    "                best_X = res.X[feasible][best_idx]\n",
    "                idxs = [int(i) for i in best_X]\n",
    "                selected = cand_df.iloc[idxs]\n",
    "                union_cov = get_coverage_union(selected[['Longitude', 'Latitude']].values, coverage_grid, SENSOR_RADIUS)\n",
    "                print(f\"NSGA-III Solution: {N} sensors\")\n",
    "                print(f\"  - AOI coverage: {union_cov:.1f}% (union of all sensors)\")\n",
    "                display(selected[['Longitude', 'Latitude', 'Solar', 'Elevation', 'Num_Connectable', 'Best_PathLoss_dB']])\n",
    "                display(plot_selected_sensors_map(aoi_poly, gateways, selected, gateway_colors=gateway_colors, gateway_col='Best_Gateway'))\n",
    "            else:\n",
    "                print(\"Invalid method selected.\")\n",
    "    print(\"✅ Phase 2 complete.\")\n",
    "\n",
    "run_btn.on_click(on_sensor_opt_run)\n",
    "\n",
    "ui = VBox([\n",
    "    HBox([num_sensors_slider, optimization_method, assignment_mode, run_btn]),\n",
    "    HBox([w_coverage, w_solar, w_elevation, w_multiconn, w_pathloss]),\n",
    "    HBox([obj_select]),\n",
    "    output\n",
    "])\n",
    "display(HTML(\"<h3>Phase 2: Sensor Multi-Objective Placement Optimization</h3>\"))\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9610ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3D Terrain + Gateways/Sensors + Radius Disks (Plotly, all axes in meters) ---\n",
    "# pip install plotly rasterio shapely geopy pyproj\n",
    "\n",
    "import numpy as np, pandas as pd, rasterio\n",
    "from shapely.geometry import Polygon\n",
    "from pyproj import Transformer, Geod\n",
    "from geopy.distance import distance as geo_distance\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ---------------------------\n",
    "DEM_PATH = \"/Users/chrisjuarez/moo_node/palisadesoutput.dsm.tif\"\n",
    "SENSOR_RADIUS_M = int(globals().get(\"SENSOR_RADIUS\", 500))\n",
    "LINK_HEIGHT_M   = 15\n",
    "MAX_GRID = 600\n",
    "SENSOR_GATEWAY_COL = \"Assigned_Gateway\" if \"Assigned_Gateway\" in globals().get(\"df\", pd.DataFrame()).columns else \"Best_Gateway\"\n",
    "# ---------------------------\n",
    "\n",
    "# Pick the sensors table to show\n",
    "if 'selected' in globals():\n",
    "    sensors_df = selected.copy()\n",
    "else:\n",
    "    sensors_df = df[df['Is_Connected']].copy()\n",
    "    if SENSOR_GATEWAY_COL not in sensors_df.columns:\n",
    "        SENSOR_GATEWAY_COL = 'Best_Gateway'\n",
    "\n",
    "# ---- DEM helpers (meters) ----\n",
    "def open_dem_tools(dem_path):\n",
    "    ds = rasterio.open(dem_path)\n",
    "    to_dem   = Transformer.from_crs(\"EPSG:4326\", ds.crs, always_xy=True)   # lon/lat -> dem(x,y)\n",
    "    to_wgs84 = Transformer.from_crs(ds.crs, \"EPSG:4326\", always_xy=True)   # dem(x,y) -> lon/lat\n",
    "    geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "    def lonlat_to_demxy(lons, lats):\n",
    "        return to_dem.transform(np.asarray(lons), np.asarray(lats))\n",
    "\n",
    "    def sample_elev_lola(lons, lats):\n",
    "        xs, ys = lonlat_to_demxy(lons, lats)\n",
    "        vals = list(ds.sample(zip(xs, ys)))\n",
    "        return np.array([v[0] if len(v) else np.nan for v in vals])\n",
    "\n",
    "    def terrain_surface_for_aoi_xy(aoi, max_grid=600):\n",
    "        if not isinstance(aoi, Polygon) and not hasattr(aoi, \"geoms\"):\n",
    "            raise ValueError(\"AOI must be Polygon or MultiPolygon.\")\n",
    "        if hasattr(aoi, \"geoms\"):\n",
    "            aoi = max(aoi.geoms, key=lambda p: p.area)\n",
    "\n",
    "        # Use lon/lat bounds then map to DEM pixel window\n",
    "        minx, miny, maxx, maxy = aoi.bounds  # lon/lat\n",
    "        col0, row0 = ds.index(minx, maxy)\n",
    "        col1, row1 = ds.index(maxx, miny)\n",
    "        col0, row0 = np.clip(col0, 0, ds.width-1),  np.clip(row0, 0, ds.height-1)\n",
    "        col1, row1 = np.clip(col1, 0, ds.width-1),  np.clip(row1, 0, ds.height-1)\n",
    "        cmin, cmax = sorted([col0, col1]); rmin, rmax = sorted([row0, row1])\n",
    "\n",
    "        width  = cmax - cmin + 1\n",
    "        height = rmax - rmin + 1\n",
    "        stride = int(np.ceil(max(width, height) / max_grid)) if max(width, height) > max_grid else 1\n",
    "\n",
    "        window = rasterio.windows.Window(cmin, rmin, width, height)\n",
    "        Z = ds.read(1, window=window)[::stride, ::stride]\n",
    "\n",
    "        cols = np.arange(cmin, cmax+1, stride)\n",
    "        rows = np.arange(rmin, rmax+1, stride)\n",
    "        xs_idx = cols + 0.5\n",
    "        ys_idx = rows + 0.5\n",
    "        X_map, Y_map = rasterio.transform.xy(ds.transform, ys_idx[:,None], xs_idx[None,:], offset='center')  # DEM CRS\n",
    "        X_map = np.array(X_map); Y_map = np.array(Y_map)\n",
    "        return X_map, Y_map, Z  # meters, meters, meters\n",
    "\n",
    "    def circle_on_terrain_xy(lon, lat, radius_m, n=120):\n",
    "        bearings = np.linspace(0, 360, n, endpoint=False)\n",
    "        pts = [geo_distance(meters=radius_m).destination((lat, lon), b) for b in bearings]\n",
    "        lats = [p.latitude for p in pts] + [pts[0].latitude]\n",
    "        lons = [p.longitude for p in pts] + [pts[0].longitude]\n",
    "        elev = sample_elev_lola(lons, lats)\n",
    "        x_ring, y_ring = lonlat_to_demxy(lons, lats)\n",
    "        xc, yc = lonlat_to_demxy([lon], [lat])\n",
    "        zc = float(sample_elev_lola([lon], [lat])[0])\n",
    "        xs = np.concatenate([xc, x_ring])\n",
    "        ys = np.concatenate([yc, y_ring])\n",
    "        zs = np.concatenate([[zc], elev])\n",
    "        i = []; j = []; k = []\n",
    "        for t in range(1, len(x_ring)):\n",
    "            i += [0]; j += [t]; k += [t+1]\n",
    "        return xs, ys, zs, np.array(i), np.array(j), np.array(k)\n",
    "\n",
    "    def air_path_xy(lon1, lat1, lon2, lat2, n=50, h_above=15):\n",
    "        n = max(2, int(n))\n",
    "        mid = geod.npts(lon1, lat1, lon2, lat2, n-2) if n > 2 else []\n",
    "        lons = [lon1] + [p[0] for p in mid] + [lon2]\n",
    "        lats = [lat1] + [p[1] for p in mid] + [lat2]\n",
    "        ground = sample_elev_lola(lons, lats)\n",
    "        X, Y = lonlat_to_demxy(lons, lats)\n",
    "        return X, Y, ground + h_above\n",
    "\n",
    "    return ds, lonlat_to_demxy, sample_elev_lola, terrain_surface_for_aoi_xy, circle_on_terrain_xy, air_path_xy\n",
    "\n",
    "# --- Build figure in meters ---\n",
    "ds, lonlat_to_demxy, sample_elev_lola, terrain_xy, circle_xy, air_xy = open_dem_tools(DEM_PATH)\n",
    "Xg, Yg, Zg = terrain_xy(aoi_poly, max_grid=MAX_GRID)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Terrain surface (all meters)\n",
    "fig.add_surface(x=Xg, y=Yg, z=Zg, showscale=False, colorscale=\"Earth\", opacity=0.98)\n",
    "\n",
    "# Colors\n",
    "PALETTE = [\"#e41a1c\",\"#377eb8\",\"#4daf4a\",\"#984ea3\",\"#ff7f00\",\"#a65628\",\"#f781bf\",\"#999999\"]\n",
    "gw_colors = {i: PALETTE[i % len(PALETTE)] for i in range(len(gateways))}\n",
    "\n",
    "# Gateways\n",
    "gw_lons = [g[0] for g in gateways]; gw_lats = [g[1] for g in gateways]\n",
    "gw_x, gw_y = lonlat_to_demxy(gw_lons, gw_lats)\n",
    "gw_z = sample_elev_lola(gw_lons, gw_lats)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=gw_x, y=gw_y, z=gw_z+5, mode=\"markers+text\",\n",
    "    marker=dict(size=6, color=[gw_colors[i] for i in range(len(gateways))]),\n",
    "    text=[f\"GW{i}\" for i in range(len(gateways))], textposition=\"top center\",\n",
    "    name=\"Gateways\"\n",
    "))\n",
    "\n",
    "# Sensors\n",
    "sns_lons = sensors_df[\"Longitude\"].to_numpy()\n",
    "sns_lats = sensors_df[\"Latitude\"].to_numpy()\n",
    "sns_x, sns_y = lonlat_to_demxy(sns_lons, sns_lats)\n",
    "sns_z = sample_elev_lola(sns_lons, sns_lats)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=sns_x, y=sns_y, z=sns_z+3, mode=\"markers\",\n",
    "    marker=dict(size=3, color=[gw_colors[int(g)] for g in sensors_df[SENSOR_GATEWAY_COL].to_numpy()]),\n",
    "    name=\"Sensors\"\n",
    "))\n",
    "\n",
    "# Links + radius disks\n",
    "for _, r in sensors_df.iterrows():\n",
    "    lon, lat = float(r[\"Longitude\"]), float(r[\"Latitude\"])\n",
    "    gw_idx = int(r.get(SENSOR_GATEWAY_COL, 0))\n",
    "    if not (0 <= gw_idx < len(gateways)) or np.isnan(lon) or np.isnan(lat):\n",
    "        continue\n",
    "    gw_lon, gw_lat = gateways[gw_idx]\n",
    "\n",
    "    # Air path in meters\n",
    "    ax, ay, az = air_xy(lon, lat, gw_lon, gw_lat, n=50, h_above=LINK_HEIGHT_M)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=ax, y=ay, z=az, mode=\"lines\",\n",
    "        line=dict(width=2, color=gw_colors[gw_idx]), opacity=0.7, showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Draped sensor disk in meters\n",
    "    cx, cy, cz, ii, jj, kk = circle_xy(lon, lat, SENSOR_RADIUS_M, n=80)\n",
    "    fig.add_trace(go.Mesh3d(\n",
    "        x=cx, y=cy, z=cz, i=ii, j=jj, k=kk,\n",
    "        color=gw_colors[gw_idx], opacity=0.15, name=\"Radius\",\n",
    "        hoverinfo=\"skip\", lighting=dict(ambient=0.8, diffuse=0.5)\n",
    "    ))\n",
    "\n",
    "# Layout: all axes share meter units -> aspectmode 'data' is now correct\n",
    "fig.update_layout(\n",
    "    title=\"WSN 3D View — Terrain + Gateways/Sensors + Air Paths + Terrain-draped Radius\",\n",
    "    showlegend=True, legend=dict(x=0.02, y=0.98),\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Easting (m)\", yaxis_title=\"Northing (m)\", zaxis_title=\"Elevation (m)\",\n",
    "        aspectmode=\"data\",\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        zaxis=dict(showgrid=False)\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=40, b=0),\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsn-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
